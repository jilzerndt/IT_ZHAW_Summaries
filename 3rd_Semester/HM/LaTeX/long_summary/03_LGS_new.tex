\section{Numerische Lösung linearer Gleichungssysteme}

\begin{concept}{Permutationsmatrix} $P$ ist eine Matrix, die aus der Einheitsmatrix durch Zeilenvertauschungen entsteht. 
    \vspace{1mm}\\
    \begin{minipage}[t]{0.5\textwidth}
        Für die Vertauschung der $i$-ten und $j$-ten Zeile hat $P_k$ die \textbf{Form}:
        \begin{itemize}
            \item $p_{ii} = p_{jj} = 0$ 
            \item $p_{ij} = p_{ji} = 1$
            \item Sonst gleich wie in $E_n$
        \end{itemize}
    \end{minipage}
    \hspace{3mm}
    \begin{minipage}[t]{0.45\textwidth}
        \vspace{1mm}
        \textbf{Wichtige Eigenschaften}:
        \begin{itemize}
            \item $P^{-1} = P^T = P$
            \item Mehrere Vertauschungen:\\ $P = P_l \cdot ... \cdot P_1$
        \end{itemize}
    \end{minipage}
\end{concept}

\begin{example2}{Zeilenvertauschung} für Matrix A mit Permutationsmatrix $P_1$:
    \vspace{1mm}\\
\begin{minipage}[t]{0.5\textwidth}
    $\underbrace{\begin{psmallmatrix}
    1 & 2 & 3\\
    4 & 5 & 6\\
    7 & 8 & 9
    \end{psmallmatrix}}_{A} \cdot 
    \underbrace{\begin{psmallmatrix}
    0 & 0 & 1\\
    0 & 1 & 0\\
    1 & 0 & 0
    \end{psmallmatrix}}_{P_1} =
    \begin{psmallmatrix}
    7 & 8 & 9\\
    4 & 5 & 6\\
    1 & 2 & 3
    \end{psmallmatrix}$
\end{minipage}
\begin{minipage}[t]{0.45\textwidth}
    \vspace{-2mm}
    $\Rightarrow A \cdot P_1$ bewirkt die Vertauschung von Zeile 1 und 3
\end{minipage}
\end{example2}

\vspace{-1mm}
\subsubsection{Pivotisierung}

\begin{concept}{Spaltenpivotisierung}\\
Strategie zur numerischen Stabilisierung des Gauss-Algorithmus durch Auswahl des betragsmäßig größten Elements als Pivotelement.

Vor jedem Eliminationsschritt in Spalte $i$:
\begin{itemize}
    \item Suche $k$ mit $|a_{ki}| = \max\{|a_{ji}| \mid j = i,\ldots,n\}$
    \item Falls $a_{ki} \neq 0$: Vertausche Zeilen $i$ und $k$
    \item Falls $a_{ki} = 0$: Matrix ist singulär
\end{itemize}
\end{concept}

\begin{KR}{Gauss-Algorithmus mit Pivotisierung}\\
\textbf{1. Elimination (Vorwärts)}:
\begin{itemize}
    \item Für $i=1,\ldots,n-1$:
    \begin{itemize}
    \item Finde $k \geq i$ mit $|a_{ki}| = \max\{|a_{ji}| \mid j = i,\ldots,n\}$
    \item Falls $a_{ki} = 0$: Stop (Matrix singulär)
    \item Vertausche Zeilen $i$ und $k$
    \item Für $j=i+1,\ldots,n$:
    \begin{itemize}
    \item $z_j := z_j - \frac{a_{ji}}{a_{ii}}z_i$
    \end{itemize}
    \end{itemize}
\end{itemize}
\vspace{-2mm}
\resizebox{\columnwidth}{!}{
\textbf{2. Rückwärtseinsetzen}:
$x_i = \frac{b_i - \sum_{j=i+1}^n a_{ij}x_j}{a_{ii}}, \quad i=n,n-1,\ldots,1$
}
\end{KR}


\begin{example2}{Gauss mit Pivotisierung}
$A = \begin{psmallmatrix}
0 & 1 & 1\\
2 & 4 & -2\\
0 & 3 & 15
\end{psmallmatrix}, \quad b = \begin{psmallmatrix}
4\\
2\\
36
\end{psmallmatrix}$
\vspace{2mm}\\
\begin{minipage}[t]{0.5\textwidth}
    \textbf{Eliminationsschritte: }
    \vspace{2mm}\\
    $\begin{psmallmatrix}
    2 & 4 & -2 & | & 2\\
    0 & 3 & 15 & | & 36\\
    0 & 1 & 1 & | & 4
    \end{psmallmatrix}
    \Rightarrow
    \begin{psmallmatrix}
    2 & 4 & -2 & | & 2\\
    0 & 3 & 15 & | & 36\\
    0 & 0 & -2 & | & -8
    \end{psmallmatrix}$
\end{minipage}
\begin{minipage}[t]{0.45\textwidth}
    \textbf{Rückwärtseinsetzen: }
    \vspace{1mm}\\
$
\begin{array}{lrl}
    x_3 &= \frac{-8}{-2} = 4\\
    x_2 &= \frac{36 - 15(4)}{3} = 1\\
    x_1 &= \frac{2 - 4(4) + 2}{2} = -6
\end{array}
$
\end{minipage}
\end{example2}

\begin{concept}{Vorteile der Permutationsmatrix}
    \begin{itemize}
        \item Exakte Nachverfolgung aller Zeilenvertauschungen
        \item Einfache Rückführung auf ursprüngliche Reihenfolge durch $P^{-1}$
        \item Kompakte Darstellung mehrerer Vertauschungen
        \item Numerisch stabile Implementierung der Pivotisierung
    \end{itemize}
\end{concept}

\begin{KR}{Zeilenvertauschungen verfolgen}
\begin{enumerate}
    \item Initialisiere $P = I_n$
    \item Für jede Vertauschung von Zeile $i$ und $j$:
    \begin{itemize}
        \item Erstelle $P_k$ durch Vertauschen von Zeilen $i,j$ in $I_n$
        \item Aktualisiere $P = P_k \cdot P$
        \item Wende Vertauschung auf Matrix an: $A := P_kA$
    \end{itemize}
    \item Bei der LR-Zerlegung mit Pivotisierung:
    \begin{itemize}
        \item $PA = LR$ 
        \item Löse $Ly = Pb$ und $Rx = y$
    \end{itemize}
\end{enumerate}
\end{KR}

\begin{examplecode}{Gauss-Elimination mit Pivotisierung}
\begin{lstlisting}[language=Python, style=basesmol]
def gauss_elimination(A, b):
    n = len(A)
    # Erweiterte Matrix erstellen
    M = [[A[i][j] for j in range(n)] + [b[i]] for i in range(n)]

    # Vorwaertselimination
    for i in range(n):
        pivot = M[i][i]
        if abs(pivot) < 1e-10:
            continue
        for j in range(i+1, n):
            factor = M[j][i] / pivot
            for k in range(i, n+1):
                M[j][k] -= factor * M[i][k]

    # Rueckwaertssubstitution
    x = [0] * n
    for i in range(n-1, -1, -1):
        if abs(M[i][i]) < 1e-10:
            x[i] = 1  # Freie Variable
            continue
        sum_val = sum(M[i][j] * x[j] for j in range(i+1, n))
        x[i] = (M[i][n] - sum_val) / M[i][i]
    
    return x
\end{lstlisting}    
\end{examplecode}





\begin{examplecode}{LR-Zerlegung Implementation}
\begin{lstlisting}[language=Python, style=basesmol]
def lr_decomposition(A):
    n = len(A)
    # Kopiere A um Original nicht zu veraendern
    R = [[A[i][j] for j in range(n)] for i in range(n)]
    L = [[1.0 if i == j else 0.0 for j in range(n)] for i in range(n)]
    P = [[1.0 if i == j else 0.0 for j in range(n)] for i in range(n)]
    
    for k in range(n-1):
        # Pivotisierung
        pivot = k
        for i in range(k+1, n):
            if abs(R[i][k]) > abs(R[pivot][k]):
                pivot = i
        if abs(R[pivot][k]) < 1e-10:  # Numerische Null
            raise ValueError("Matrix ist (fast) singulaer")
        # Zeilenvertauschung falls noetig
        if pivot != k:
            R[k], R[pivot] = R[pivot], R[k]
            # L und P anpassen fuer Zeilen < k
            for j in range(k):
                L[k][j], L[pivot][j] = L[pivot][j], L[k][j]
            P[k], P[pivot] = P[pivot], P[k]

        # Elimination
        for i in range(k+1, n):
            factor = R[i][k] / R[k][k]
            L[i][k] = factor
            for j in range(k, n):
                R[i][j] -= factor * R[k][j]
               
    return P, L, R
\end{lstlisting}
\end{examplecode}

\subsection{Matrix-Zerlegungen}

\begin{definition}{Dreieckszerlegung}
Eine Matrix $A \in \mathbb{R}^{n\times n}$ kann zerlegt werden in:
\vspace{1mm}\\
\begin{minipage}[t]{0.5\textwidth}
    \textbf{Untere Dreiecksmatrix L:}\\
    $l_{ij} = 0$ für $j > i$\\
    Diagonale normiert ($l_{ii}=1$)
\end{minipage}
\hspace{3mm}
\begin{minipage}[t]{0.45\textwidth}
    \textbf{Obere Dreiecksmatrix R:}\\
    $r_{ij} = 0$ für $i > j$\\
    Diagonalelemente $\neq 0$
\end{minipage}
\end{definition}


\subsubsection{LR-Zerlegung}

\begin{theorem}{LR-Zerlegung}\\
Jede reguläre Matrix $A$, für die der Gauss-Algorithmus ohne Zeilenvertauschungen durchführbar ist, lässt sich zerlegen in:
$A = LR$
wobei $L$ eine normierte untere und $R$ eine obere Dreiecksmatrix ist.
\end{theorem}

\begin{KR}{Berechnung der LR-Zerlegung}\\
So berechnen Sie die LR-Zerlegung:
\begin{enumerate}
    \item Führen Sie Gauss-Elimination durch
    \item $R$ ist die resultierende obere Dreiecksmatrix
    \item Die Eliminationsfaktoren $-\frac{a_{ji}}{a_{ii}}$ bilden $L$
    \item Lösen Sie dann nacheinander:
        \begin{itemize}
            \item $Ly = b$ (Vorwärtseinsetzen)
            \item $Rx = y$ (Rückwärtseinsetzen)
        \end{itemize}
\end{enumerate}
\end{KR}

\begin{example2}[breakable]{LR-Zerlegung}
    %TODO: check if this is correct and/or relevant - either correct or replace with better example
$A = \begin{psmallmatrix}
-1 & 1 & 1\\
1 & -3 & -2\\
5 & 1 & 4
\end{psmallmatrix}, \quad b = \begin{psmallmatrix}
0\\
5\\
3
\end{psmallmatrix}$

\paragraph{Schritt 1: Erste Spalte}
Max. Element in 1. Spalte: $|a_{31}| = 5$, also Z1 und Z3 tauschen:
$$P_1 = \begin{psmallmatrix}
0 & 0 & 1\\
0 & 1 & 0\\
1 & 0 & 0
\end{psmallmatrix}, \quad A^{(1)} = \begin{psmallmatrix}
5 & 1 & 4\\
1 & -3 & -2\\
-1 & 1 & 1
\end{psmallmatrix}$$
Berechne Eliminationsfaktoren:
$l_{21} = \frac{1}{5}, \quad l_{31} = -\frac{1}{5}$
\vspace{2mm}\\
Nach Elimination:
$A^{(2)} = \begin{psmallmatrix}
5 & 1 & 4\\
0 & -3.2 & -2.8\\
0 & 1.2 & 1.8
\end{psmallmatrix}$

\paragraph{Schritt 2: Zweite Spalte}
Max. Element in 2. Spalte unter Diagonale: $|-3.2| > |1.2|$, \\ keine Vertauschung nötig.
\vspace{2mm}\\
Berechne Eliminationsfaktor:
$l_{32} = -\frac{1.2}{-3.2} = \frac{3}{8}$
\vspace{2mm}\\
Nach Elimination:
$R = \begin{psmallmatrix}
5 & 1 & 4\\
0 & -3.2 & -2.8\\
0 & 0 & 2.85
\end{psmallmatrix}$

\paragraph{Endergebnis}
Die LR-Zerlegung mit $PA = LR$ ist:
\vspace{2mm}\\
$P = P_1 = \begin{psmallmatrix}
0 & 0 & 1\\
0 & 1 & 0\\
1 & 0 & 0
\end{psmallmatrix}$, 
$L = \begin{psmallmatrix}
1 & 0 & 0\\
\frac{1}{5} & 1 & 0\\
-\frac{1}{5} & \frac{3}{8} & 1
\end{psmallmatrix}, 
R = \begin{psmallmatrix}
5 & 1 & 4\\
0 & -3.2 & -2.8\\
0 & 0 & 2.85
\end{psmallmatrix}$

\paragraph{Lösung des Systems}
\begin{enumerate}
    \item $Pb = \begin{psmallmatrix} 3\\ 5\\ 0 \end{psmallmatrix}$
    \item Löse $Ly = Pb$ durch Vorwärtseinsetzen:
    $y = \begin{psmallmatrix} 3\\ 4.4\\ 2.85 \end{psmallmatrix}$
    \item Löse $Rx = y$ durch Rückwärtseinsetzen:
    $x = \begin{psmallmatrix} 1\\ -1\\ 1 \end{psmallmatrix}$
\end{enumerate}

\paragraph{Probe}
$$Ax = \begin{psmallmatrix}
-1 & 1 & 1\\
1 & -3 & -2\\
5 & 1 & 4
\end{psmallmatrix} \begin{psmallmatrix} 1\\ -1\\ 1 \end{psmallmatrix} = \begin{psmallmatrix} 0\\ 5\\ 3 \end{psmallmatrix} = b$$
\end{example2}

\columnbreak

\subsubsection{QR-Zerlegung}

\begin{concept}{QR-Zerlegung}\\
Eine orthogonale Matrix $Q \in \mathbb{R}^{n\times n}$ erfüllt: $Q^T Q = QQ^T = I_n$
\vspace{1mm}\\
Die QR-Zerlegung einer Matrix $A$ ist: $A = QR$
\vspace{1mm}\\
wobei $Q$ orthogonal und $R$ eine obere Dreiecksmatrix ist.
\end{concept}

\begin{definition}{Householder-Transformation}\\
Eine Householder-Matrix hat die Form:
$H = I_n - 2uu^T$

mit $u \in \mathbb{R}^n$, $\|u\| = 1$. Es gilt:
\begin{itemize}
    \item $H$ ist orthogonal ($H^T = H^{-1}$) und symmetrisch ($H^T = H$)
    \item $H^2 = I_n$
\end{itemize}
\end{definition}

\begin{KR}{QR-Zerlegung mit Householder}
\begin{enumerate}
    \item Initialisierung: $R := A$, $Q := I_n$
    \item Für $i = 1,\ldots,n-1$:
        \begin{itemize}
            \item Bilde Vektor $v_i$ aus i-ter Spalte von $R$ ab Position $i$
            \item $w_i := v_i + \text{sign}(v_{i1})\|v_i\|e_1$
            \item $u_i := w_i/\|w_i\|$
            \item $H_i := I_{n-i+1} - 2u_iu_i^T$
            \item Erweitere $H_i$ zu $Q_i$ durch $I_{i-1}$ links oben
            \item $R := Q_iR$ und $Q := QQ_i^T$
        \end{itemize}
\end{enumerate}
\end{KR}

\begin{example2}[breakable]{QR-Zerlegung mit Householder}
    %TODO: check if this is correct and/or relevant - either correct or replace with better example
$A = \begin{psmallmatrix}
2 & 5 & -1\\
-1 & -4 & 2\\
0 & 2 & 1
\end{psmallmatrix}$

\paragraph{Schritt 1: Erste Spalte}
Erste Spalte $a_1$ und Einheitsvektor $e_1$:
$a_1 = \begin{psmallmatrix} 2\\ -1\\ 0 \end{psmallmatrix}, \quad e_1 = \begin{psmallmatrix} 1\\ 0\\ 0 \end{psmallmatrix}$

Householder-Vektor für erste Spalte:
\vspace{1mm}
\begin{enumerate}
    \item Berechne Norm: $|a_1| = \sqrt{2^2 + (-1)^2 + 0^2} = \sqrt{5}$
    \vspace{1mm}
    \item Bestimme Vorzeichen: $\text{sign}(a_{11}) = \text{sign}(2) = 1$
         \begin{itemize}
              \item Wähle positives Vorzeichen, da erstes Element positiv
              \item Dies maximiert die erste Komponente von $v_1$
              \item Verhindert Auslöschung bei der Subtraktion
         \end{itemize}
         \vspace{1mm}
    \item $v_1 = a_1 + \text{sign}(a_{11})|a_1|e_1 = \begin{psmallmatrix} 2\\ -1\\ 0 \end{psmallmatrix} + \sqrt{5}\begin{psmallmatrix} 1\\ 0\\ 0 \end{psmallmatrix} = \begin{psmallmatrix} 2 + \sqrt{5}\\ -1\\ 0 \end{psmallmatrix}$
    \vspace{1mm}
    \item Normiere $v_1$: $|v_1| = \sqrt{(2 + \sqrt{5})^2 + 1} \Rightarrow
            u_1 = \frac{v_1}{|v_1|} = \begin{psmallmatrix} 0.91\\ -0.41\\ 0 \end{psmallmatrix}$
\end{enumerate}
\vspace{1mm}
Householder-Matrix berechnen:
$H_1 = I - 2u_1u_1^T = \begin{psmallmatrix} 
-0.67 & -0.75 & 0\\
-0.75 & 0.67 & 0\\
0 & 0 & 1
\end{psmallmatrix}$
A nach 1. Transformation:
$A^{(1)} = H_1A = \begin{psmallmatrix}
-\sqrt{5} & -6.71 & 0.45\\
0 & -0.89 & 1.79\\
0 & 2.00 & 1.00
\end{psmallmatrix}$
\paragraph{Schritt 2: Zweite Spalte}
Untermatrix für zweite Transformation:
$A_2 = \begin{psmallmatrix} -0.89 & 1.79\\ 2.00 & 1.00 \end{psmallmatrix}$

Householder-Vektor für zweite Spalte:
\vspace{1mm}
\begin{enumerate}
    \item $|a_2| = \sqrt{(-0.89)^2 + 2^2} = 2.19$
    \vspace{1mm}
    \item $\text{sign}(a_{22}) = \text{sign}(-0.89) = -1$ (da erstes Element negativ)
    \vspace{1mm}
    \item $v_2 = \begin{psmallmatrix} -0.89\\ 2.00 \end{psmallmatrix} - 2.19\begin{psmallmatrix} 1\\ 0 \end{psmallmatrix} = \begin{psmallmatrix} -3.09\\ 2.00 \end{psmallmatrix}$
    \vspace{1mm}
    \item $u_2 = \frac{v_2}{|v_2|} = \begin{psmallmatrix} -0.84\\ 0.54 \end{psmallmatrix}$
\end{enumerate}
\vspace{1mm}
Erweiterte Householder-Matrix: %TODO: nicer formatting!
$Q_2 = \begin{psmallmatrix}
1 & 0 & 0\\
0 & -0.41 & -0.91\\
0 & -0.91 & 0.41
\end{psmallmatrix}$

nach 2. Transformation:
$R = Q_2A^{(1)} = \begin{psmallmatrix}
-\sqrt{5} & -6.71 & 0.45\\
0 & -2.19 & 1.34\\
0 & 0 & -1.79
\end{psmallmatrix}$

\paragraph{Endergebnis}
Die QR-Zerlegung $A = QR$ ist:

$Q = H_1^TQ_2^T = \begin{psmallmatrix}
-0.89 & -0.45 & 0\\
0.45 & -0.89 & 0\\
0 & 0 & 1
\end{psmallmatrix},
R = \begin{psmallmatrix}
-\sqrt{5} & -6.71 & 0.45\\
0 & -2.19 & 1.34\\
0 & 0 & -1.79
\end{psmallmatrix}$

\paragraph{Probe}
\begin{enumerate}
    \item $QR = A$ (bis auf Rundungsfehler)
    \item $Q^TQ = QQ^T = I$ (Orthogonalität)
    \item $R$ ist obere Dreiecksmatrix
\end{enumerate}

\paragraph{Wichtige Beobachtungen}
\small
\begin{itemize}
    \item Vorzeichenwahl bei $v_k$ ist entscheidend für numerische Stabilität
    \item Ein falsches Vorzeichen kann zu Auslöschung führen
    \item Betrag der Diagonalelemente in $R$ = Norm transformierter Spalten
    \item $Q$ ist orthogonal: Spaltenvektoren sind orthonormal
\end{itemize}
\end{example2}

\begin{examplecode}{QR-Zerlegung Implementation}
\begin{lstlisting}[language=Python, style=basesmol]
def qr_decomposition(A):
    m = len(A)
    n = len(A[0])
    # Kopiere A nach R (deep copy)
    R = [[A[i][j] for j in range(n)] for i in range(m)]
    # Initialisiere Q als Einheitsmatrix
    Q = [[1.0 if i == j else 0.0 for j in range(m)] 
         for i in range(m)]
    
    def vector_norm(v): # Norm eines Vektors
        return (sum(x*x for x in v)) ** 0.5
    
    def matrix_mult(A, B): # Matrixmultiplikation
        m, n = len(A), len(B[0])
        p = len(B)
        C = [[0.0] * n for _ in range(m)]

        for i in range(m):
            for j in range(n):
                C[i][j] = sum(A[i][k] * B[k][j] 
                             for k in range(p))

        return C
    
    def householder_reflection(x):
        n = len(x)
        v = [xi for xi in x]  # Kopiere x

        # Berechne Norm des Teilvektors
        sigma = sum(v[i]*v[i] for i in range(1, n))
        if sigma == 0 and x[0] >= 0:
            beta = 0
        elif sigma == 0 and x[0] < 0:
            beta = -2
        else:
            mu = (x[0]*x[0] + sigma)**0.5
            if x[0] <= 0:
                v[0] = x[0] - mu
            else:
                v[0] = -sigma/(x[0] + mu)

            beta = 2*v[0]*v[0]/(sigma + v[0]*v[0])

            # Normiere v
            temp = v[0]
            for i in range(n):
                v[i] /= temp

        return v, beta
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{QR-Zerlegung Implementation (Fortsetzung)}
\begin{lstlisting}[language=Python, style=basesmol]
    # Hauptschleife der QR-Zerlegung
    for k in range(n):
        # Extrahiere k-te Spalte ab k-ter Zeile
        x = [R[i][k] for i in range(k, m)]
        if len(x) > 1:  # wenn noch Untermatrix existiert
            # Berechne Householder-Transformation
            v, beta = householder_reflection(x)
            # Wende Householder auf R an
            for j in range(k, n):
                # Berechne w = beta * (v^T * R_j)
                w = beta * sum(v[i-k]*R[i][j] 
                             for i in range(k, m))
                # Update R
                for i in range(k, m):
                    R[i][j] -= v[i-k] * w
            # Update Q
            for j in range(m):
                w = beta * sum(v[i-k]*Q[j][i+k] 
                             for i in range(len(v)))
                for i in range(len(v)):
                    Q[j][k+i] -= v[i] * w
    # Transponiere Q am Ende
    Q = [[Q[j][i] for j in range(m)] for i in range(m)]
    
    return Q, R # Q (orthogonal) und R (obere Dreiecksmatrix)

# Beispiel fuer Verwendung
def solve_qr(A, b): # Loest Ax = b mittels QR-Zerlegung
    Q, R = qr_decomposition(A)
    # Berechne Q^T * b
    y = [sum(Q[i][j] * b[j] 
             for j in range(len(b))) 
         for i in range(len(b))]
    # Rueckwaertseinsetzen
    n = len(R)
    x = [0] * n
    for i in range(n-1, -1, -1):
        s = sum(R[i][j] * x[j] for j in range(i+1, n))
        if abs(R[i][i]) < 1e-10:
            raise ValueError("Matrix (fast) singulaer")
        x[i] = (y[i] - s) / R[i][i]
    return x
\end{lstlisting}
\end{examplecode}

\begin{KR}{QR-Zerlegung - Praktisches Vorgehen}
\begin{enumerate}
    \item Vorbereitungen
    \begin{itemize}
        \item Matrix A kopieren für R
        \item Q als Einheitsmatrix initialisieren
        \item Householder-Vektoren speichern
    \end{itemize}

    \item Für jede Spalte k = 1,...,n-1:
    \begin{itemize}
        \item Untervektor $v_k$ aus k-ter Spalte extrahieren
        \item Householder-Vektor berechnen:
            \begin{itemize}
                \item $w_k = v_k + \text{sign}(v_{k1})\|v_k\|e_1$
                \item $u_k = \frac{w_k}{\|w_k\|}$
            \end{itemize}
        \item Householder-Matrix auf Untermatrix anwenden:
            \begin{itemize}
                \item $H_k = I - 2u_ku_k^T$
                \item $R_{k:n,k:n} = H_k \cdot R_{k:n,k:n}$
            \end{itemize}
        \item Q aktualisieren: $Q = Q \cdot H_k^T$
    \end{itemize}

    \item System lösen durch
    \begin{itemize}
        \item $y = Q^Tb$ berechnen
        \item Rückwärtseinsetzen: $Rx = y$
    \end{itemize}
\end{enumerate}
\end{KR}




\subsection{Fehleranalyse}

\begin{definition}{Matrix- und Vektornormen}\\
Eine Vektornorm $\|\cdot\|$ erfüllt für alle $x,y \in \mathbb{R}^n, \lambda \in \mathbb{R}$:
\begin{itemize}
    \item $\|x\| \geq 0$ und $\|x\| = 0 \Leftrightarrow x = 0$
    \item $\|\lambda x\| = |\lambda| \cdot \|x\|$
    \item $\|x + y\| \leq \|x\| + \|y\|$ (Dreiecksungleichung)
\end{itemize}
\end{definition}

\begin{concept}{Wichtige Normen}

\textbf{1-Norm:}
        $\|x\|_1 = \sum_{i=1}^n |x_i|,
        \|A\|_1 = \max_j \sum_{i=1}^n |a_{ij}|$

\textbf{2-Norm:}
        $\|x\|_2 = \sqrt{\sum_{i=1}^n x_i^2}, 
        \|A\|_2 = \sqrt{\rho(A^TA)}$

$\infty$\textbf{-Norm:}
        $\|x\|_\infty = \max_i |x_i|, 
        \|A\|_\infty = \max_i \sum_{j=1}^n |a_{ij}|$
\end{concept}

\begin{theorem}{Fehlerabschätzung für LGS}\\
Sei $\|\cdot\|$ eine Norm, $A \in \mathbb{R}^{n\times n}$ regulär und $Ax = b$, $A\tilde{x} = \tilde{b}$
\vspace{1mm}\\
\begin{minipage}[t]{0.47\textwidth}
    \textbf{Absoluter Fehler:}
    \begin{center}
        $\|x - \tilde{x}\| \leq \|A^{-1}\| \cdot \|b - \tilde{b}\|$
    \end{center}
\end{minipage}
\hspace{2mm}
\begin{minipage}[t]{0.47\textwidth}
    \textbf{Relativer Fehler:}
    \begin{center}
        $\frac{\|x - \tilde{x}\|}{\|x\|} \leq \text{cond}(A) \cdot \frac{\|b - \tilde{b}\|}{\|b\|}$
    \end{center}
\end{minipage}
\vspace{1mm}\\
Mit der Konditionszahl $\text{cond}(A) = \|A\| \cdot \|A^{-1}\|$
\end{theorem}

\begin{concept}{Konditionierung}\\
Die Konditionszahl beschreibt die numerische Stabilität eines LGS:
\begin{itemize}
    \item $\text{cond}(A) \approx 1$: gut konditioniert
    \item $\text{cond}(A) \gg 1$: schlecht konditioniert
    \item $\text{cond}(A) \to \infty$: singulär
\end{itemize}
\end{concept}

\begin{example2}{Konditionierung}
$A = \begin{psmallmatrix}
1 & 1\\
1 & 1.01
\end{psmallmatrix}, b = \begin{psmallmatrix}
2\\
2.01
\end{psmallmatrix}$\\
Konditionszahl:
$\text{cond}(A) = \|A\| \cdot \|A^{-1}\| \approx 400$
\paragraph{Fehlerabschätzung}
$\text{Absoluter Fehler: }\|x - \tilde{x}\| \leq 400 \cdot 0.01 = 4$ \\
$\text{Relativer Fehler: }\frac{\|x - \tilde{x}\|}{\|x\|} \leq 400 \cdot \frac{0.01}{2} = 2$
\end{example2}

\begin{examplecode}{Analyse der Genauigkeit einer Näherungslösung}
\begin{lstlisting}[language=Python, style=basesmol]
def error_analysis(A, x, b, x_approx):
    n = len(A)
    # Residuum berechnen
    r = [b[i] - sum(A[i][j] * x_approx[j] 
                   for j in range(n)) 
         for i in range(n)]
    res_norm = max(abs(ri) for ri in r)
    # Relativer Fehler (falls exakte Loesung bekannt)
    if x is not None:
        rel_error = max(abs(x[i] - x_approx[i]) 
                       for i in range(n)) / \
                   max(abs(x[i]) for i in range(n))
    else:
        rel_error = None
    # Absoluter Fehler (falls exakte Loesung bekannt)
    if x is not None:
        abs_error = max(abs(x[i] - x_approx[i]) 
                       for i in range(n))
    else:
        abs_error = None
    
    return {
        'residual_norm': res_norm,
        'relative_error': rel_error,
        'residual': r
    }
\end{lstlisting}
\end{examplecode}

\subsubsection{Iterative Verfahren}

\begin{definition}{Zerlegung der Systemmatrix} $A$ zerlegt in: $A = L + D + R$
\begin{itemize}
    \item $L$: streng untere Dreiecksmatrix
    \item $D$: Diagonalmatrix
    \item $R$: streng obere Dreiecksmatrix
\end{itemize}
\end{definition}

\begin{concept}{Jacobi-Verfahren}
Gesamtschrittverfahren mit der Iteration:
\vspace{-1mm}\\
$$x^{(k+1)} = -D^{-1}(L + R)x^{(k)} + D^{-1}b$$
\vspace{-1mm}
Komponentenweise:
$x_i^{(k+1)} = \frac{1}{a_{ii}}\left(b_i - \sum_{j=1,j\neq i}^n a_{ij}x_j^{(k)}\right)$
\end{concept}

\begin{concept}{Gauss-Seidel-Verfahren}
Einzelschrittverfahren mit der Iteration:
\vspace{-1mm}\\
$$x^{(k+1)} = -(D+L)^{-1}Rx^{(k)} + (D+L)^{-1}b$$
Komponentenweise:\\
$x_i^{(k+1)} = \frac{1}{a_{ii}}\left(b_i - \sum_{j=1}^{i-1} a_{ij}x_j^{(k+1)} - \sum_{j=i+1}^n a_{ij}x_j^{(k)}\right)$

\end{concept}

\begin{theorem}{Konvergenzkriterien}
Ein iteratives Verfahren konvergiert, wenn:
\begin{enumerate}
    \item Die Matrix $A$ diagonaldominant ist:\\
    $|a_{ii}| > \sum_{j\neq i} |a_{ij}|$ für alle $i$
    \item Der Spektralradius der Iterationsmatrix kleiner 1 ist:\\
    $\rho(B) < 1$ mit $B$ als jeweilige Iterationsmatrix
\end{enumerate}
\end{theorem}





\begin{example2}{Konvergenzverhalten}
$\begin{psmallmatrix}
4 & 1 & 0\\
1 & 4 & 1\\
0 & 1 & 4
\end{psmallmatrix}
\begin{psmallmatrix}
x_1\\
x_2\\
x_3
\end{psmallmatrix} =
\begin{psmallmatrix}
1\\
2\\
3
\end{psmallmatrix}$
\vspace{1mm}\\
Die Matrix ist diagonaldominant:
$|a_{ii}| = 4 > 1 = \sum_{j\neq i} |a_{ij}|$
\vspace{1mm}\\
\begin{tabular}{c|cc|cc}
k & \multicolumn{2}{c|}{Residuum} & \multicolumn{2}{c}{Rel. Fehler}\\
& Jacobi & G-S & Jacobi & G-S\\
\hline
0 & 3.74 & 3.74 & - & -\\
1 & 0.94 & 0.47 & 0.935 & 0.468\\
2 & 0.23 & 0.06 & 0.246 & 0.125\\
3 & 0.06 & 0.01 & 0.065 & 0.017\\
4 & 0.01 & 0.001 & 0.016 & 0.002
\end{tabular}

\paragraph{Beobachtungen:}
\begin{itemize}
    \item Gauss-Seidel konvergiert etwa doppelt so schnell wie Jacobi
    \item Das Residuum fällt linear (geometrische Folge)
    \item Die Konvergenz ist gleichmäßig (keine Oszillationen)
\end{itemize}
\end{example2}

\begin{KR}{Vergleich Lösungsverfahren}
$A = \begin{psmallmatrix}
1 & 2 & 0\\
2 & 1 & 2\\
0 & 2 & 1
\end{psmallmatrix}, \quad b = \begin{psmallmatrix}
1\\
2\\
3
\end{psmallmatrix}$

\paragraph{1. Systemanalyse}
\begin{itemize}
    \item Matrix ist symmetrisch
    \item Nicht streng diagonaldominant
    \item $\text{cond}_\infty(A) \approx 12.5$
\end{itemize}

\paragraph{2. Verschiedene Lösungsansätze}
\begin{center}
\begin{tabular}{l|ccc}
Verfahren & Iterationen & Residuum & Zeit\\
\hline
LR mit Pivot & 1 & $2.2\cdot10^{-16}$ & 1.0\\
QR & 1 & $2.2\cdot10^{-16}$ & 2.3\\
Jacobi & 12 & $1.0\cdot10^{-6}$ & 1.8\\
Gauss-Seidel & 7 & $1.0\cdot10^{-6}$ & 1.4\\
\end{tabular}
\end{center}

\paragraph{3. Interpretation}
\begin{itemize}
    \item Direkte Verfahren erreichen höhere Genauigkeit
    \item Iterative Verfahren brauchen mehrere Schritte
\end{itemize}
\end{KR}

\begin{KR}{Implementation iterativer Verfahren}
\begin{enumerate}
    \item Wählen Sie Startvektor $x^{(0)}$
    \item Wählen Sie Abbruchkriterien:
        \begin{itemize}
            \item Maximale Iterationszahl $k_{max}$
            \item Toleranz $\epsilon$ für Änderung $\|x^{(k+1)} - x^{(k)}\|$
            \item Toleranz für Residuum $\|Ax^{(k)} - b\|$
        \end{itemize}
    \item Führen Sie Iteration durch bis Kriterien erfüllt
\end{enumerate}
\end{KR}

\begin{examplecode}{Jacobi-Verfahren Implementation}
\begin{lstlisting}[language=Python, style=basesmol]
def jacobi_method(A, b, x0, tol=1e-6, max_iter=100):

    n = len(A)
    x = x0.copy()
    x_new = [0.0] * n
    
    for iter in range(max_iter):

        # Jacobi-Iteration
        for i in range(n):
            sum1 = sum(A[i][j] * x[j] for j in range(i))
            sum2 = sum(A[i][j] * x[j] for j in range(i+1, n))
            x_new[i] = (b[i] - sum1 - sum2) / A[i][i]
            
        # Konvergenzpruefung
        diff = max(abs(x_new[i] - x[i]) for i in range(n))

        if diff < tol:
            return x_new, iter + 1

        x = x_new.copy()
        
    raise ValueError(f"Keine Konvergenz nach {max_iter} Iterationen")
\end{lstlisting}
\end{examplecode}



\begin{examplecode}{Gauss-Seidel-Verfahren Implementation}
\begin{lstlisting}[language=Python, style=basesmol]
def gauss_seidel_method(A, b, x0, tol=1e-6, max_iter=100):

    n = len(A)
    x = x0.copy()
    
    for iter in range(max_iter):
        x_old = x.copy()

        # Gauss-Seidel-Iteration
        for i in range(n):
            sum1 = sum(A[i][j] * x[j] for j in range(i))
            sum2 = sum(A[i][j] * x_old[j] for j in range(i+1, n))
            x[i] = (b[i] - sum1 - sum2) / A[i][i]
            
        # Konvergenzpruefung
        diff = max(abs(x[i] - x_old[i]) for i in range(n))

        if diff < tol:
            return x, iter + 1
            
    raise ValueError(f"Keine Konvergenz nach {max_iter} Iterationen")
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{Analyse von LGS auf numerische Stabilität}
\begin{lstlisting}[language=Python, style=basesmol]
def analyze_matrix(A, b):
    n = len(A)
    # 1. Grundlegende Eigenschaften
    diag_dom = is_diagonally_dominant(A)
    scaling = max(abs(A[i][j]) for i in range(n) 
                 for j in range(n))
    # 2. Konditionszahl schaetzen 
    def matrix_norm_inf(M):
        return max(sum(abs(M[i][j]) for j in range(len(M))) 
                  for i in range(len(M)))

    def inverse_power_iteration(M, max_iter=100):
        x = [1.0] * n
        for _ in range(max_iter):
            y = solve_triangular(M, x)
            norm = max(abs(yi) for yi in y)
            x = [yi/norm for yi in y]
        return 1.0/norm

    norm_A = matrix_norm_inf(A)
    try:
        norm_Ainv = inverse_power_iteration(A)
        cond = norm_A * norm_Ainv
    except:
        cond = float('inf')
    # 3. Analyse der Diagonalelemente
    min_diag = min(abs(A[i][i]) for i in range(n))
    max_offdiag = max(abs(A[i][j]) for i in range(n) 
                     for j in range(n) if i != j)
    # 4. Empfehlungen generieren
    recommendations = []
    if not diag_dom:
        recommendations.append(
            "Matrix nicht diagonaldominant - "
            "Iterative Verfahren koennten divergieren")
    if cond > 1e4:
        recommendations.append(
            f"Hohe Konditionszahl ({cond:.1e}) - "
            "Ergebnisse koennten ungenau sein")
    if min_diag < max_offdiag/100:
        recommendations.append(
            "Kleine Diagonalelemente - "
            "Pivotisierung empfohlen")
    if scaling > 1e8:
        recommendations.append(
            "Grosse Zahlenunterschiede - "
            "Skalierung empfohlen")
    return {
        "recommandations": recommendations, 
        "results": cond, diag_dom, scaling, min_diag, max_offdiag
    }
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{Hilfsfunktion für Optimiere iterative Verfahren}
\begin{lstlisting}[language=Python, style=basesmol]
def is_diagonally_dominant(A): # Matrix diagonaldominant?
    n = len(A)
    for i in range(n):
        if abs(A[i][i]) <= sum(abs(A[i][j]) for j in range(n) if j != i):
            return False
    return True
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{Optimierte iterative Verfahren Implementation}
    \begin{itemize}
        \item Optimierte Version mit Konvergenzanalyse
        \item Löst $Ax = b$ mit verschiedenen iterativen Verfahren
        \item \texttt{method}: 'jacobi' oder 'gauss-seidel'
        \item \texttt{omega}: Relaxationsparameter (1.0 = Standard)
    \end{itemize}
\begin{lstlisting}[language=Python, style=basesmol]
def iterative_solver(A, b, method='gauss_seidel', tol=1e-6, max_iter=100, omega=1.0):

    n = len(A)
    x = [0.0] * n  # Startvektor
    D = [[A[i][j] if i == j else 0 for j in range(n)] 
         for i in range(n)]  # Diagonalmatrix
    L = [[A[i][j] if i > j else 0 for j in range(n)] 
         for i in range(n)]  # Untere Dreiecksmatrix
    U = [[A[i][j] if i < j else 0 for j in range(n)] 
         for i in range(n)]  # Obere Dreiecksmatrix
    
    # Konvergenzcheck
    if not is_diagonally_dominant(A):
        print("Warnung: Matrix nicht diagonaldominant")
    
    iterations = []
    residuals = []
    
    for iter in range(max_iter):
        x_old = x.copy()
        if method == 'jacobi':
            for i in range(n):
                sum_term = sum(A[i][j] * x_old[j] 
                             for j in range(n) if j != i)
                x[i] = (1-omega) * x_old[i] + \
                       (omega/A[i][i]) * (b[i] - sum_term)
        else:  # gauss_seidel
            for i in range(n):
                sum1 = sum(A[i][j] * x[j] for j in range(i))
                sum2 = sum(A[i][j] * x_old[j] 
                          for j in range(i+1, n))
                x[i] = (1-omega) * x_old[i] + \ (omega/A[i][i]) * (b[i] - sum1 - sum2)

        # Berechne Residuum und relative Aenderung
        res = max(abs(sum(A[i][j] * x[j] for j in range(n)) - b[i]) for i in range(n))
        diff = max(abs(x[i] - x_old[i]) for i in range(n))
        
        iterations.append(x.copy())
        residuals.append(res)
        
        if diff < tol:
            return {
                'solution': x,
                'iterations': iterations,
                'residuals': residuals,
                'iteration_count': iter + 1
            }
            
    raise ValueError(f"Keine Konvergenz nach {max_iter} " + 
                    f"Iterationen\nLetztes Residuum: {res}")
\end{lstlisting}
\end{examplecode}







