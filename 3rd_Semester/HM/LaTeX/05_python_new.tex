\section{Python Implementationen}

\subsubsection{Hilfsfunktionen}

\begin{examplecode}{Matrixoperationen}
\begin{lstlisting}[language=Python, style=basesmol]
def matrix_vector_mult(A, v): # Matrix-Vektor Mult.
    n = len(A)
    result = [0] * n
    for i in range(n):
        result[i] = sum(A[i][j] * v[j] for j in range(n))
    return result

def matrix_mult(A, B): # Matrix-Matrix Multiplikation
    m, n = len(A), len(B[0])
    p = len(B)
    C = [[0.0] * n for _ in range(m)]
    for i in range(m):
        for j in range(n):
            C[i][j] = sum(A[i][k] * B[k][j] for k in range(p))
    return C

def transpose(A): # Matrix transponieren
    n = len(A)
    return [[A[j][i] for j in range(n)] for i in range(n)]

def vector_norm(v): # Euklidische Norm eines Vektors
    return sum(x*x for x in v) ** 0.5

def normalize_vector(v): # Vektor auf L. 1 normieren
    norm = vector_norm(v)
    return [x/norm for x in v] if norm > 0 else v

def copy_matrix(A): # Tiefe Kopie einer Matrix
    return [[A[i][j] for j in range(len(A[0]))] for i in range(len(A))]
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{is\_diagonally\_dominant} Diagonaldominanz prüfen
\begin{lstlisting}[language=Python, style=basesmol]
def is_diagonally_dominant(A):
    n = len(A)
    for i in range(n):
        if abs(A[i][i]) <= sum(abs(A[i][j]) for j in range(n) if j != i):
            return False
    return True
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{convergence\_check}Konvergenzkriterien
\begin{lstlisting}[language=Python, style=basesmol]
def convergence_check(x_new, x_old, f_new, f_old, tol=1e-6):
    # Absoluter Fehler im Funktionswert
    if abs(f_new) < tol:
        return True, "Funktionswert < tol"
    # Relative Aenderung der x-Werte 
    if abs(x_new - x_old) < tol * (1 + abs(x_new)):
        return True, "Relative Aenderung < tol"
    # Relative Aenderung der Funktionswerte
    if abs(f_new - f_old) < tol * (1 + abs(f_new)):
        return True, "Funktionsaenderung < tol"
    # Divergenzcheck
    if abs(f_new) > 2 * abs(f_old):
        return False, "Divergenz detektiert"
        
    return False, "Noch nicht konvergiert"
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{error\_estimate} Fehlerabschätzung durch Vorzeichenwechsel
\begin{lstlisting}[language=Python, style=basesmol]
def error_estimate(f, x, eps=1e-5):
    fx_left = f(x - eps)
    fx_right = f(x + eps)
    
    if fx_left * fx_right < 0:
        return eps  # Nullstelle liegt in (x-eps, x+eps)
    return None
\end{lstlisting}
\end{examplecode}

\subsection{Numerische Lösung von Nullstellenproblemen}

\begin{examplecode}{root\_finder\_with\_error}
    Nullstellensuche mit Fehlerabschaetzung
\begin{lstlisting}[language=Python, style=basesmol]
def root_finder_with_error(f, x0, tol=1e-6, max_iter=100):
    x_old = x0
    f_old = f(x_old)
    
    for i in range(max_iter):
        # Iterationsschritt (hier Newton als Beispiel)
        x_new = x_old - f_old/derivative(f, x_old)
        f_new = f(x_new)
        
        # Pruefe Konvergenzkriterien
        converged, reason = convergence_check(
            x_new, x_old, f_new, f_old, tol)
            
        if converged:
            # Schaetze finalen Fehler
            error = error_estimate(f, x_new, tol)
            return {
                'root': x_new,
                'iterations': i+1,
                'error_bound': error,
                'convergence_reason': reason
            }
            
        x_old, f_old = x_new, f_new
        
    raise ValueError(f"Keine Konvergenz nach {max_iter} Iterationen")
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{fixed\_point\_it} Fixpunktiteration
\begin{lstlisting}[language=Python, style=basesmol]
def fixed_point_it(f, x0, tol=1e-6, max_it=100):
    x = x0
    for i in range(max_it):
        x_new = f(x)
        if abs(x_new - x) < tol:
            return x_new, i+1
        x = x_new
    raise ValueError("Keine Konvergenz")

# Optimierte Version mit Fehlerschaetzung
def fixed_point_it_opt(f, x0, tol=1e-6, max_it=100):
    x = x0
    alpha = None  # Schaetzung fuer Lipschitz-Konstante
    for i in range(max_iter):
        x_new = f(x)
        dx = abs(x_new - x)
        # Lipschitz-Konstante schaetzen
        if i > 0 and dx > 0:
            alpha_new = dx / dx_old
            if alpha is None or alpha_new > alpha:
                alpha = alpha_new
        # A-posteriori Fehlerabschaetzung
        if alpha is not None and alpha < 1:
            error = alpha * dx / (1 - alpha)
            if error < tol:
                return x_new, i+1
        x = x_new
        dx_old = dx
    raise ValueError("Keine Konvergenz")
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{newton} Newton-Verfahren mit Konvergenzprüfung
\begin{lstlisting}[language=Python, style=basesmol]
def newton(f, df, x0, tol=1e-6, max_iter=100):
    x = x0
    fx = f(x)
    
    for i in range(max_iter):
        dfx = df(x)
        if abs(dfx) < 1e-10:
            raise ValueError("Ableitung nahe Null")
            
        dx = fx/dfx
        x_new = x - dx
        fx_new = f(x_new)
        
        # Konvergenzpruefung
        converged, reason = convergence_check(
            x_new, x, fx_new, fx, tol)
        if converged:
            return {
                'root': x_new,
                'iterations': i+1,
                'residual': abs(fx_new),
                'convergence_reason': reason
            }
            
        if abs(fx_new) >= abs(fx):
            raise ValueError("Divergenz detektiert")
            
        x, fx = x_new, fx_new
        
    raise ValueError("Keine Konvergenz")
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{secant} Sekantenverfahren mit Konvergenzprüfung
\begin{lstlisting}[language=Python, style=basesmol]
def secant(f, x0, x1, tol=1e-6, max_iter=100):
    fx0 = f(x0)
    fx1 = f(x1)
    
    # Stelle mit kleinerem f-Wert als x1
    if abs(fx0) < abs(fx1):
        x0, x1 = x1, x0
        fx0, fx1 = fx1, fx0
    
    for i in range(max_iter):
        if abs(fx1) < tol:
            return x1, i+1 
        if fx1 == fx0:
            raise ValueError("Division durch Null")
        # Sekanten-Schritt
        d = fx1 * (x1 - x0)/(fx1 - fx0)
        x2 = x1 - d
        
        # Konvergenzpruefungen
        if abs(d) < tol * (1 + abs(x1)): # Relative Aenderung
            return {
                'root': x2,
                'iterations': i+1,
                'residual': abs(f(x2))
            }
        fx2 = f(x2)
        if abs(fx2) >= abs(fx1): # Divergenzcheck
            if i == 0:
                raise ValueError("Schlechte Startwerte")
            return {
                'root': x1,
                'iterations': i+1,
                'residual': abs(fx1)
            }
            
        x0, x1 = x1, x2
        fx0, fx1 = fx1, fx2
        
    raise ValueError("Keine Konvergenz")
\end{lstlisting}
\end{examplecode}

\begin{KR}{Nullstellenverfahren - Praktisches Vorgehen}
\begin{enumerate}
    \item Voraussetzungen prüfen:
    \begin{itemize}
        \item Existiert Nullstelle? (z.B. Vorzeichenwechsel)
        \item Sind Startwerte geeignet?
        \item Ist Funktion ausreichend glatt? (für Newton)
    \end{itemize}
    
    \item Verfahren wählen:
    \begin{itemize}
        \item Newton: Wenn Ableitung verfügbar und Startwert nahe Lösung
        \item Sekanten: Wenn keine Ableitung aber zwei Startwerte nahe Lösung
        \item Fixpunkt: Wenn Funktion kontraktiv
    \end{itemize}
    
    \item Implementierung:
    \begin{itemize}
        \item Konvergenzkriterien definieren
        \item Maximale Iterationszahl festlegen
        \item Fehlerabschätzung einbauen
        \item Divergenzschutz implementieren
    \end{itemize}
    
    \item Auswertung:
    \begin{itemize}
        \item Konvergenzverhalten prüfen
        \item Fehler abschätzen
        \item Ergebnis validieren
    \end{itemize}
\end{enumerate}
\end{KR}

\begin{examplecode}{root\_finder\_with\_error}
    Nullstellensuche mit Fehlerabschaetzung
\begin{lstlisting}[language=Python, style=basesmol]
def root_finder_with_error(f, x0, tol=1e-6, max_iter=100):
    x_old = x0
    f_old = f(x_old)
    
    for i in range(max_iter):
        # Iterationsschritt (hier Newton als Beispiel)
        x_new = x_old - f_old/derivative(f, x_old)
        f_new = f(x_new)
        
        # Pruefe Konvergenzkriterien
        converged, reason = convergence_criteria(
            x_new, x_old, f_new, f_old, tol)
            
        if converged:
            # Schaetze finalen Fehler
            error = error_estimate(f, x_new, tol)
            return {
                'root': x_new,
                'iterations': i+1,
                'error_bound': error,
                'convergence_reason': reason
            }
      
        x_old, f_old = x_new, f_new
        
    raise ValueError(f"Keine Konvergenz nach {max_iter} Iterationen")
    # Returns: Dictionary mit Ergebnissen
\end{lstlisting}
\end{examplecode}

\subsubsection{Numerische Lösung linearer Gleichungssysteme}

\begin{examplecode}{Erweiterte Gauss-Elimination}
\begin{lstlisting}[language=Python, style=basesmol]
def gauss_elimination(A, b, tol=1e-10):
    """Gauss-Elimination mit Behandlung freier Variablen
    
    Returns: Dictionary mit
        'solution': Basisloesung
        'free_vars': Liste der freien Variablen
        'general_solution': Lambda-Funktion fuer allg. Loesung
        'rank': Rang der Matrix
        'consistent': System loesbar
    """
    n = len(A)
    # Erweiterte Matrix erstellen
    M = copy_matrix(A)
    b = b.copy()
    
    # Speichere Zeilenoperationen fuer Rueckwaertsphase
    row_ops = []
    # Markiere freie Variablen
    free_vars = []
    rank = 0
    
    # Vorwaertselimination mit Pivotisierung
    for i in range(n):
        # Finde maximales Element in Spalte i
        pivot_row = i
        for j in range(i+1, n):
            if abs(M[j][i]) > abs(M[pivot_row][i]):
                pivot_row = j
                
        # Zeilen tauschen falls noetig
        if pivot_row != i:
            M[i], M[pivot_row] = M[pivot_row], M[i]
            b[i], b[pivot_row] = b[pivot_row], b[i]
            
        # Pruefe auf freie Variable
        if abs(M[i][i]) < tol:
            free_vars.append(i)
            continue
            
        rank += 1
        # Speichere Operationen
        row_ops.append((i, [(j, -M[j][i]/M[i][i]) 
                           for j in range(i+1, n)]))
                           
        # Elimination durchfuehren
        for j in range(i+1, n):
            factor = M[j][i] / M[i][i]
            for k in range(i, n):
                M[j][k] -= factor * M[i][k]
            b[j] -= factor * b[i]
    
    # Pruefe Loesbarkeit
    consistent = True
    for i in range(rank, n):
        if abs(b[i]) > tol:
            consistent = False
            break
            
    if not consistent:
        return {
            'solution': None,
            'free_vars': [],
            'general_solution': None,
            'rank': rank,
            'consistent': False
        }
    
    # Berechne Basisloesung
    x = [0] * n
    # Rueckwaertssubstitution
    for i in range(n-1, -1, -1):
        if i not in free_vars:
            sum_val = sum(M[i][j] * x[j] 
                         for j in range(i+1, n))
            x[i] = (b[i] - sum_val) / M[i][i]
    
    # Erstelle Funktion fuer allgemeine Loesung
    def general_solution(*params):
        if len(params) != len(free_vars):
            raise ValueError(
                f"Benoetigt {len(free_vars)} Parameter")
        solution = x.copy()
        for var, param in zip(free_vars, params):
            solution[var] = param
            # Update abhaengige Variablen
            for op in row_ops:
                row, factors = op
                if row < var:
                    continue
                solution[row] -= param * sum(
                    f * solution[j] 
                    for j, f in factors if j > var)
        return solution
    
    return {
        'solution': x,
        'free_vars': free_vars,
        'general_solution': general_solution,
        'rank': rank,
        'consistent': True,
        'matrix': M
    }

# Beispielnutzung:
"""
A = [
    [1, 2, 1],
    [2, 4, 2],
    [3, 6, 3]
]
b = [2, 4, 6]

result = gauss_elimination(A, b)
if result['consistent']:
    print(f"Basisloesung: {result['solution']}")
    print(f"Freie Variablen: {result['free_vars']}")
    if result['free_vars']:
        # Erzeuge spezielle Loesung
        print("Spezielle Loesung mit t=1:")
        print(result['general_solution'](1))
else:
    print("System nicht loesbar")
"""
\end{lstlisting}
\end{examplecode}

\begin{KR}{Umgang mit Systemen mit freien Variablen}
\begin{enumerate}
    \item Vorgehensweise
    \begin{itemize}
        \item Matrix auf Stufenform bringen
        \item Freie Variablen identifizieren (Nullspalten)
        \item Basislösung berechnen
        \item Allgemeine Lösung parametrisch aufstellen
    \end{itemize}
    
    \item Interpretation
    \begin{itemize}
        \item Rang der Matrix bestimmen
        \item Lösbarkeit prüfen
        \item Dimension des Lösungsraums bestimmen
        \item Spezielle Lösungen generieren
    \end{itemize}
    
    \item Sonderfälle beachten
    \begin{itemize}
        \item Unlösbare Systeme erkennen
        \item Abhängige Gleichungen identifizieren
        \item Numerische Genauigkeit berücksichtigen
    \end{itemize}
\end{enumerate}
\end{KR}

\begin{examplecode}{gauss\_elimination} Gauss-Elimination mit Spaltenpivotisierung
\begin{lstlisting}[language=Python, style=basesmol]
def gauss_elimination(A, b, tol=1e-10):
    n = len(A)
    M = copy_matrix(A) # Tiefe Kopie von A und b
    x = [0] * n
    b = b.copy()

    # Vorwaertselimination mit Pivotisierung
    for i in range(n):
        # Pivotisierung
        pivot_row = i
        for j in range(i+1, n):
            if abs(M[j][i]) > abs(M[pivot_row][i]):
                pivot_row = j
        if pivot_row != i:
            M[i], M[pivot_row] = M[pivot_row], M[i]
            b[i], b[pivot_row] = b[pivot_row], b[i]
        # Pruefe auf singulaere Matrix
        if abs(M[i][i]) < tol:
            raise ValueError("Matrix (fast) singulaer")
        # Elimination
        for j in range(i+1, n):
            factor = M[j][i] / M[i][i]
            for k in range(i, n):
                M[j][k] -= factor * M[i][k]
            b[j] -= factor * b[i]
    # Rueckwaertssubstitution
    for i in range(n-1, -1, -1):
        x[i] = (b[i] - sum(M[i][j] * x[j] 
                for j in range(i+1, n))) / M[i][i]
    return {
        'solution': x,
        'matrix': M,
        'condition': estimate_condition(A)
    }
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{Gauss-Elimination mit Pivotisierung}
\begin{lstlisting}[language=Python, style=basesmol]
def gauss_elimination(A, b):
    n = len(A)
    # Erweiterte Matrix erstellen
    M = [[A[i][j] for j in range(n)] + [b[i]] for i in range(n)]

    # Vorwaertselimination
    for i in range(n):
        pivot = M[i][i]
        if abs(pivot) < 1e-10:
            continue
        for j in range(i+1, n):
            factor = M[j][i] / pivot
            for k in range(i, n+1):
                M[j][k] -= factor * M[i][k]

    # Rueckwaertssubstitution
    x = [0] * n
    for i in range(n-1, -1, -1):
        if abs(M[i][i]) < 1e-10:
            x[i] = 1  # Freie Variable
            continue
        sum_val = sum(M[i][j] * x[j] for j in range(i+1, n))
        x[i] = (M[i][n] - sum_val) / M[i][i]
    
    return x
\end{lstlisting}    
\end{examplecode}

\begin{examplecode}{lr\_decomposition} LR-Zerlegung mit Zeilenvertauschung
\begin{lstlisting}[language=Python, style=basesmol]
def lr_decomposition(A, tol=1e-10):
    n = len(A)
    # Initialisiere L, R und P
    R = copy_matrix(A)
    L = [[1.0 if i == j else 0.0 for j in range(n)] 
         for i in range(n)]
    P = [[1.0 if i == j else 0.0 for j in range(n)] 
         for i in range(n)]
    
    for k in range(n-1):
        # Pivotisierung
        pivot = k
        for i in range(k+1, n):
            if abs(R[i][k]) > abs(R[pivot][k]):
                pivot = i

        if abs(R[pivot][k]) < tol:
            raise ValueError("Matrix (fast) singulaer")

        # Zeilenvertauschung falls noetig
        if pivot != k:
            R[k], R[pivot] = R[pivot], R[k]
            for j in range(k):
                L[k][j], L[pivot][j] = L[pivot][j], L[k][j]
            P[k], P[pivot] = P[pivot], P[k]

        # Elimination
        for i in range(k+1, n):
            factor = R[i][k] / R[k][k]
            L[i][k] = factor
            for j in range(k, n):
                R[i][j] -= factor * R[k][j]
    
    return {
        'L': L,
        'R': R,
        'P': P
    }
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{solve\_lr} LR-Zerlegung lösen
\begin{lstlisting}[language=Python, style=basesmol]
def solve_lr(L, R, P, b):
    n = len(L)
    # Pb berechnen
    pb = matrix_vector_mult(P, b)
    
    # Vorwaertseinsetzen Ly = Pb
    y = [0] * n
    for i in range(n):
        y[i] = pb[i] - sum(L[i][j] * y[j] for j in range(i))

    # Rueckwaertseinsetzen Rx = y
    x = [0] * n
    for i in range(n-1, -1, -1):
        x[i] = (y[i] - sum(R[i][j] * x[j] 
                for j in range(i+1, n))) / R[i][i]
                
    return x
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{LR-Zerlegung Implementation}
\begin{lstlisting}[language=Python, style=basesmol]
def lr_decomposition(A):
    n = len(A)
    # Kopiere A um Original nicht zu veraendern
    R = [[A[i][j] for j in range(n)] for i in range(n)]
    L = [[1.0 if i == j else 0.0 for j in range(n)] for i in range(n)]
    P = [[1.0 if i == j else 0.0 for j in range(n)] for i in range(n)]
    
    for k in range(n-1):
        # Pivotisierung
        pivot = k
        for i in range(k+1, n):
            if abs(R[i][k]) > abs(R[pivot][k]):
                pivot = i
        if abs(R[pivot][k]) < 1e-10:  # Numerische Null
            raise ValueError("Matrix ist (fast) singulaer")
        # Zeilenvertauschung falls noetig
        if pivot != k:
            R[k], R[pivot] = R[pivot], R[k]
            # L und P anpassen fuer Zeilen < k
            for j in range(k):
                L[k][j], L[pivot][j] = L[pivot][j], L[k][j]
            P[k], P[pivot] = P[pivot], P[k]

        # Elimination
        for i in range(k+1, n):
            factor = R[i][k] / R[k][k]
            L[i][k] = factor
            for j in range(k, n):
                R[i][j] -= factor * R[k][j]
               
    return P, L, R
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{QR-Zerlegung}
\begin{lstlisting}[language=Python, style=basesmol]
def householder_vector(x):
    """Berechnet Householder-Vektor zu x"""
    n = len(x)
    v = x.copy()
    sigma = sum(v[i]*v[i] for i in range(1, n))
    
    if sigma == 0 and x[0] >= 0:
        return [0] * n, 0
    elif sigma == 0 and x[0] < 0:
        return [2] + [0]*(n-1), -2
        
    mu = (x[0]*x[0] + sigma)**0.5
    if x[0] <= 0:
        v[0] = x[0] - mu
    else:
        v[0] = -sigma/(x[0] + mu)
        
    beta = 2*v[0]*v[0]/(sigma + v[0]*v[0])
    return normalize_vector(v), beta

def qr_decomposition(A):
    """QR-Zerlegung mittels Householder-Transformationen"""
    m = len(A)
    n = len(A[0])
    R = copy_matrix(A)
    Q = [[1.0 if i == j else 0.0 for j in range(m)] 
         for i in range(m)]
    
    for k in range(min(m-1, n)):
        # Extrahiere k-te Spalte ab k-ter Zeile
        x = [R[i][k] for i in range(k, m)]
        
        # Berechne Householder-Transformation
        v, beta = householder_vector(x)
        
        # Wende Householder auf R an
        for j in range(k, n):
            # w = beta * (v^T * R_j)
            w = beta * sum(v[i-k]*R[i][j] 
                         for i in range(k, m))
            # Update R
            for i in range(k, m):
                R[i][j] -= v[i-k] * w
                
        # Update Q
        for j in range(m):
            w = beta * sum(v[i-k]*Q[j][i+k] 
                         for i in range(len(v)))
            for i in range(len(v)):
                Q[j][k+i] -= v[i] * w
                
    # Transponiere Q am Ende
    Q = transpose(Q)
    
    return {
        'Q': Q,
        'R': R
    }

def solve_qr(Q, R, b):
    """Loest QRx = b"""
    # Berechne Q^T * b
    y = matrix_vector_mult(transpose(Q), b)
    
    # Rueckwaertseinsetzen
    n = len(R)
    x = [0] * n
    for i in range(n-1, -1, -1):
        x[i] = (y[i] - sum(R[i][j] * x[j] 
                for j in range(i+1, n))) / R[i][i]
    return x
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{QR-Zerlegung Implementation}
\begin{lstlisting}[language=Python, style=basesmol]
def qr_decomposition(A):
    m = len(A)
    n = len(A[0])
    # Kopiere A nach R (deep copy)
    R = [[A[i][j] for j in range(n)] for i in range(m)]
    # Initialisiere Q als Einheitsmatrix
    Q = [[1.0 if i == j else 0.0 for j in range(m)] 
         for i in range(m)]
    
    def vector_norm(v): # Norm eines Vektors
        return (sum(x*x for x in v)) ** 0.5
    
    def matrix_mult(A, B): # Matrixmultiplikation
        m, n = len(A), len(B[0])
        p = len(B)
        C = [[0.0] * n for _ in range(m)]

        for i in range(m):
            for j in range(n):
                C[i][j] = sum(A[i][k] * B[k][j] 
                             for k in range(p))

        return C
    
    def householder_reflection(x):
        n = len(x)
        v = [xi for xi in x]  # Kopiere x

        # Berechne Norm des Teilvektors
        sigma = sum(v[i]*v[i] for i in range(1, n))
        if sigma == 0 and x[0] >= 0:
            beta = 0
        elif sigma == 0 and x[0] < 0:
            beta = -2
        else:
            mu = (x[0]*x[0] + sigma)**0.5
            if x[0] <= 0:
                v[0] = x[0] - mu
            else:
                v[0] = -sigma/(x[0] + mu)

            beta = 2*v[0]*v[0]/(sigma + v[0]*v[0])

            # Normiere v
            temp = v[0]
            for i in range(n):
                v[i] /= temp

        return v, beta
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{QR-Zerlegung Implementation (Fortsetzung)}
\begin{lstlisting}[language=Python, style=basesmol]
    # Hauptschleife der QR-Zerlegung
    for k in range(n):
        # Extrahiere k-te Spalte ab k-ter Zeile
        x = [R[i][k] for i in range(k, m)]
        if len(x) > 1:  # wenn noch Untermatrix existiert
            # Berechne Householder-Transformation
            v, beta = householder_reflection(x)
            # Wende Householder auf R an
            for j in range(k, n):
                # Berechne w = beta * (v^T * R_j)
                w = beta * sum(v[i-k]*R[i][j] 
                             for i in range(k, m))
                # Update R
                for i in range(k, m):
                    R[i][j] -= v[i-k] * w
            # Update Q
            for j in range(m):
                w = beta * sum(v[i-k]*Q[j][i+k] 
                             for i in range(len(v)))
                for i in range(len(v)):
                    Q[j][k+i] -= v[i] * w
    # Transponiere Q am Ende
    Q = [[Q[j][i] for j in range(m)] for i in range(m)]
    
    return Q, R # Q (orthogonal) und R (obere Dreiecksmatrix)

# Beispiel fuer Verwendung
def solve_qr(A, b): # Loest Ax = b mittels QR-Zerlegung
    Q, R = qr_decomposition(A)
    # Berechne Q^T * b
    y = [sum(Q[i][j] * b[j] 
             for j in range(len(b))) 
         for i in range(len(b))]
    # Rueckwaertseinsetzen
    n = len(R)
    x = [0] * n
    for i in range(n-1, -1, -1):
        s = sum(R[i][j] * x[j] for j in range(i+1, n))
        if abs(R[i][i]) < 1e-10:
            raise ValueError("Matrix (fast) singulaer")
        x[i] = (y[i] - s) / R[i][i]
    return x
\end{lstlisting}
\end{examplecode}

\begin{KR}{QR-Zerlegung - Praktisches Vorgehen}
\begin{enumerate}
    \item Vorbereitungen
    \begin{itemize}
        \item Matrix A kopieren für R
        \item Q als Einheitsmatrix initialisieren
        \item Householder-Vektoren speichern
    \end{itemize}

    \item Für jede Spalte k = 1,...,n-1:
    \begin{itemize}
        \item Untervektor $v_k$ aus k-ter Spalte extrahieren
        \item Householder-Vektor berechnen:
            \begin{itemize}
                \item $w_k = v_k + \text{sign}(v_{k1})\|v_k\|e_1$
                \item $u_k = \frac{w_k}{\|w_k\|}$
            \end{itemize}
        \item Householder-Matrix auf Untermatrix anwenden:
            \begin{itemize}
                \item $H_k = I - 2u_ku_k^T$
                \item $R_{k:n,k:n} = H_k \cdot R_{k:n,k:n}$
            \end{itemize}
        \item Q aktualisieren: $Q = Q \cdot H_k^T$
    \end{itemize}

    \item System lösen durch
    \begin{itemize}
        \item $y = Q^Tb$ berechnen
        \item Rückwärtseinsetzen: $Rx = y$
    \end{itemize}
\end{enumerate}
\end{KR}

\begin{KR}{Zerlegungsverfahren - Vergleich und Anwendung}
\begin{enumerate}
    \item LR-Zerlegung
    \begin{itemize}
        \item Vorteil: Effizient für mehrere rechte Seiten
        \item Nachteil: Numerisch weniger stabil
        \item Aufwand: $\frac{2}{3}n^3$ Operationen
    \end{itemize}
    
    \item QR-Zerlegung
    \begin{itemize}
        \item Vorteil: Numerisch stabiler
        \item Nachteil: Höherer Rechenaufwand
        \item Aufwand: $\frac{4}{3}n^3$ Operationen
    \end{itemize}
    
    \item Wann welches Verfahren?
    \begin{itemize}
        \item LR: Für gut konditionierte Systeme
        \item QR: Für schlecht konditionierte Systeme
        \item Gauss: Wenn nur eine Lösung benötigt wird
    \end{itemize}
\end{enumerate}
\end{KR}

\subsection{Iterative Löser für lineare Gleichungssysteme}

\begin{examplecode}{Analyse der Genauigkeit einer Näherungslösung}
\begin{lstlisting}[language=Python, style=basesmol]
def error_analysis(A, x, b, x_approx):
    n = len(A)
    # Residuum berechnen
    r = [b[i] - sum(A[i][j] * x_approx[j] 
                   for j in range(n)) 
         for i in range(n)]
    res_norm = max(abs(ri) for ri in r)
    # Relativer Fehler (falls exakte Loesung bekannt)
    if x is not None:
        rel_error = max(abs(x[i] - x_approx[i]) 
                       for i in range(n)) / \
                   max(abs(x[i]) for i in range(n))
    else:
        rel_error = None
    # Absoluter Fehler (falls exakte Loesung bekannt)
    if x is not None:
        abs_error = max(abs(x[i] - x_approx[i]) 
                       for i in range(n))
    else:
        abs_error = None
    
    return {
        'residual_norm': res_norm,
        'relative_error': rel_error,
        'residual': r
    }
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{Jacobi-Verfahren}
\begin{lstlisting}[language=Python, style=basesmol]
def jacobi_method(A, b, tol=1e-6, max_iter=100):
    """Jacobi-Iterationsverfahren"""
    n = len(A)
    
    # Pruefe Diagonaldominanz
    if not is_diagonally_dominant(A):
        print("Warnung: Matrix nicht diagonaldominant")
    
    # Initialisiere mit Nullvektor
    x = [0.0] * n
    iterations = []
    residuals = []
    
    for iter in range(max_iter):
        x_new = [0.0] * n
        # Jacobi-Iteration
        for i in range(n):
            sum_term = sum(A[i][j] * x[j] 
                         for j in range(n) if j != i)
            x_new[i] = (b[i] - sum_term) / A[i][i]
            
        # Berechne Residuum
        res = max(abs(sum(A[i][j] * x_new[j] 
                 for j in range(n)) - b[i]) 
                 for i in range(n))
                 
        # Konvergenzcheck
        diff = max(abs(x_new[i] - x[i]) for i in range(n))
        
        iterations.append(x_new.copy())
        residuals.append(res)
        
        if diff < tol:
            return {
                'solution': x_new,
                'iterations': iterations,
                'residuals': residuals,
                'iteration_count': iter + 1
            }
            
        x = x_new.copy()
        
    raise ValueError(f"Keine Konvergenz nach {max_iter} "
                    f"Iterationen\nLetztes Residuum: {res}")
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{Jacobi-Verfahren Implementation}
\begin{lstlisting}[language=Python, style=basesmol]
def jacobi_method(A, b, x0, tol=1e-6, max_iter=100):

    n = len(A)
    x = x0.copy()
    x_new = [0.0] * n
    
    for iter in range(max_iter):

        # Jacobi-Iteration
        for i in range(n):
            sum1 = sum(A[i][j] * x[j] for j in range(i))
            sum2 = sum(A[i][j] * x[j] for j in range(i+1, n))
            x_new[i] = (b[i] - sum1 - sum2) / A[i][i]
            
        # Konvergenzpruefung
        diff = max(abs(x_new[i] - x[i]) for i in range(n))

        if diff < tol:
            return x_new, iter + 1

        x = x_new.copy()
        
    raise ValueError(f"Keine Konvergenz nach {max_iter} Iterationen")
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{Gauss-Seidel-Verfahren}
\begin{lstlisting}[language=Python, style=basesmol]
def gauss_seidel_method(A, b, tol=1e-6, max_iter=100):
    """Gauss-Seidel-Iterationsverfahren"""
    n = len(A)
    
    # Pruefe Diagonaldominanz
    if not is_diagonally_dominant(A):
        print("Warnung: Matrix nicht diagonaldominant")
    
    x = [0.0] * n
    iterations = []
    residuals = []
    
    for iter in range(max_iter):
        x_old = x.copy()
        
        # Gauss-Seidel-Iteration
        for i in range(n):
            sum1 = sum(A[i][j] * x[j] for j in range(i))
            sum2 = sum(A[i][j] * x_old[j] 
                      for j in range(i+1, n))
            x[i] = (b[i] - sum1 - sum2) / A[i][i]
            
        # Berechne Residuum und relative Aenderung
        res = max(abs(sum(A[i][j] * x[j] 
                 for j in range(n)) - b[i]) 
                 for i in range(n))
        diff = max(abs(x[i] - x_old[i]) for i in range(n))
        
        iterations.append(x.copy())
        residuals.append(res)
        
        if diff < tol:
            return {
                'solution': x,
                'iterations': iterations,
                'residuals': residuals,
                'iteration_count': iter + 1
            }
            
    raise ValueError(f"Keine Konvergenz nach {max_iter} "
                    f"Iterationen\nLetztes Residuum: {res}")
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{Gauss-Seidel-Verfahren Implementation}
\begin{lstlisting}[language=Python, style=basesmol]
def gauss_seidel_method(A, b, x0, tol=1e-6, max_iter=100):

    n = len(A)
    x = x0.copy()
    
    for iter in range(max_iter):
        x_old = x.copy()

        # Gauss-Seidel-Iteration
        for i in range(n):
            sum1 = sum(A[i][j] * x[j] for j in range(i))
            sum2 = sum(A[i][j] * x_old[j] for j in range(i+1, n))
            x[i] = (b[i] - sum1 - sum2) / A[i][i]
            
        # Konvergenzpruefung
        diff = max(abs(x[i] - x_old[i]) for i in range(n))

        if diff < tol:
            return x, iter + 1
            
    raise ValueError(f"Keine Konvergenz nach {max_iter} Iterationen")
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{Analyse von LGS auf numerische Stabilität}
\begin{lstlisting}[language=Python, style=basesmol]
def analyze_matrix(A, b):
    n = len(A)
    # 1. Grundlegende Eigenschaften
    diag_dom = is_diagonally_dominant(A)
    scaling = max(abs(A[i][j]) for i in range(n) 
                 for j in range(n))
    # 2. Konditionszahl schaetzen 
    def matrix_norm_inf(M):
        return max(sum(abs(M[i][j]) for j in range(len(M))) 
                  for i in range(len(M)))

    def inverse_power_iteration(M, max_iter=100):
        x = [1.0] * n
        for _ in range(max_iter):
            y = solve_triangular(M, x)
            norm = max(abs(yi) for yi in y)
            x = [yi/norm for yi in y]
        return 1.0/norm

    norm_A = matrix_norm_inf(A)
    try:
        norm_Ainv = inverse_power_iteration(A)
        cond = norm_A * norm_Ainv
    except:
        cond = float('inf')
    # 3. Analyse der Diagonalelemente
    min_diag = min(abs(A[i][i]) for i in range(n))
    max_offdiag = max(abs(A[i][j]) for i in range(n) 
                     for j in range(n) if i != j)
    # 4. Empfehlungen generieren
    recommendations = []
    if not diag_dom:
        recommendations.append(
            "Matrix nicht diagonaldominant - "
            "Iterative Verfahren koennten divergieren")
    if cond > 1e4:
        recommendations.append(
            f"Hohe Konditionszahl ({cond:.1e}) - "
            "Ergebnisse koennten ungenau sein")
    if min_diag < max_offdiag/100:
        recommendations.append(
            "Kleine Diagonalelemente - "
            "Pivotisierung empfohlen")
    if scaling > 1e8:
        recommendations.append(
            "Grosse Zahlenunterschiede - "
            "Skalierung empfohlen")
    return {
        "recommandations": recommendations, 
        "results": cond, diag_dom, scaling, min_diag, max_offdiag
    }
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{SOR-Verfahren (Relaxationsverfahren)}
\begin{lstlisting}[language=Python, style=basesmol]
def sor_method(A, b, omega=1.5, tol=1e-6, max_iter=100):
    """Successive Over-Relaxation Verfahren"""
    n = len(A)
    x = [0.0] * n
    iterations = []
    residuals = []
    
    for iter in range(max_iter):
        x_old = x.copy()
        
        for i in range(n):
            sum1 = sum(A[i][j] * x[j] for j in range(i))
            sum2 = sum(A[i][j] * x_old[j] 
                      for j in range(i+1, n))
            
            x_new = (b[i] - sum1 - sum2) / A[i][i]
            # Relaxation
            x[i] = (1 - omega) * x_old[i] + omega * x_new
            
        res = max(abs(sum(A[i][j] * x[j] 
                 for j in range(n)) - b[i]) 
                 for i in range(n))
        diff = max(abs(x[i] - x_old[i]) for i in range(n))
        
        iterations.append(x.copy())
        residuals.append(res)
        
        if diff < tol:
            return {
                'solution': x,
                'iterations': iterations,
                'residuals': residuals,
                'iteration_count': iter + 1
            }
            
    raise ValueError(f"Keine Konvergenz nach {max_iter} "
                    f"Iterationen\nLetztes Residuum: {res}")
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{Konvergenzanalyse}
\begin{lstlisting}[language=Python, style=basesmol]
def analyze_convergence(method_name, iterations, residuals):
    """Analysiert Konvergenzverhalten eines iterativen Verfahrens"""
    n = len(residuals)
    if n < 2:
        return {
            'method': method_name,
            'converged': False,
            'reason': 'Zu wenige Iterationen'
        }
        
    # Schaetze Konvergenzrate
    rates = [abs(residuals[i]/residuals[i-1]) 
             for i in range(1, n)]
    avg_rate = sum(rates) / len(rates)
    
    # Schaetze asymptotische Konvergenzrate
    asymp_rate = rates[-1] if rates else None
    
    # Berechne empirische Konvergenzordnung
    if n > 2:
        q = [abs(log(residuals[i+1]/residuals[i]) / 
                 log(residuals[i]/residuals[i-1])) 
             for i in range(n-2)]
        avg_order = sum(q) / len(q) if q else None
    else:
        avg_order = None
        
    return {
        'method': method_name,
        'converged': residuals[-1] < residuals[0],
        'iterations': n,
        'final_residual': residuals[-1],
        'avg_rate': avg_rate,
        'asymp_rate': asymp_rate,
        'conv_order': avg_order
    }
\end{lstlisting}
\end{examplecode}

\begin{KR}{Iterative Verfahren - Praktisches Vorgehen}
\begin{enumerate}
    \item Vorbereitung
    \begin{itemize}
        \item Matrix auf Diagonaldominanz prüfen
        \item Geeignete Startlösung wählen
        \item Konvergenzkriterien festlegen
    \end{itemize}
    
    \item Verfahrenswahl
    \begin{itemize}
        \item Jacobi: Einfach zu parallelisieren
        \item Gauss-Seidel: Schnellere Konvergenz
        \item SOR: Bei bekanntem optimalem $\omega$
    \end{itemize}
    
    \item Durchführung
    \begin{itemize}
        \item Residuen überwachen
        \item Konvergenzrate beobachten
        \item Abbruchkriterien prüfen
    \end{itemize}
    
    \item Nachbereitung
    \begin{itemize}
        \item Qualität der Lösung prüfen
        \item Konvergenzverhalten analysieren
        \item Verfahren ggf. anpassen
    \end{itemize}
\end{enumerate}
\end{KR}

\begin{KR}{Implementation iterativer Verfahren}
\begin{enumerate}
    \item Wählen Sie Startvektor $x^{(0)}$
    \item Wählen Sie Abbruchkriterien:
        \begin{itemize}
            \item Maximale Iterationszahl $k_{max}$
            \item Toleranz $\epsilon$ für Änderung $\|x^{(k+1)} - x^{(k)}\|$
            \item Toleranz für Residuum $\|Ax^{(k)} - b\|$
        \end{itemize}
    \item Führen Sie Iteration durch bis Kriterien erfüllt
\end{enumerate}
\end{KR}

\begin{examplecode}{Hilfsfunktion für Optimiere iterative Verfahren}
\begin{lstlisting}[language=Python, style=basesmol]
def is_diagonally_dominant(A): # Matrix diagonaldominant?
    n = len(A)
    for i in range(n):
        if abs(A[i][i]) <= sum(abs(A[i][j]) for j in range(n) if j != i):
            return False
    return True
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{Optimierte iterative Verfahren Implementation}
    \begin{itemize}
        \item Optimierte Version mit Konvergenzanalyse
        \item Löst $Ax = b$ mit verschiedenen iterativen Verfahren
        \item \texttt{method}: 'jacobi' oder 'gauss-seidel'
        \item \texttt{omega}: Relaxationsparameter (1.0 = Standard)
    \end{itemize}
\begin{lstlisting}[language=Python, style=basesmol]
def iterative_solver(A, b, method='gauss_seidel', tol=1e-6, max_iter=100, omega=1.0):

    n = len(A)
    x = [0.0] * n  # Startvektor
    D = [[A[i][j] if i == j else 0 for j in range(n)] 
         for i in range(n)]  # Diagonalmatrix
    L = [[A[i][j] if i > j else 0 for j in range(n)] 
         for i in range(n)]  # Untere Dreiecksmatrix
    U = [[A[i][j] if i < j else 0 for j in range(n)] 
         for i in range(n)]  # Obere Dreiecksmatrix
    
    # Konvergenzcheck
    if not is_diagonally_dominant(A):
        print("Warnung: Matrix nicht diagonaldominant")
    
    iterations = []
    residuals = []
    
    for iter in range(max_iter):
        x_old = x.copy()
        if method == 'jacobi':
            for i in range(n):
                sum_term = sum(A[i][j] * x_old[j] 
                             for j in range(n) if j != i)
                x[i] = (1-omega) * x_old[i] + \
                       (omega/A[i][i]) * (b[i] - sum_term)
        else:  # gauss_seidel
            for i in range(n):
                sum1 = sum(A[i][j] * x[j] for j in range(i))
                sum2 = sum(A[i][j] * x_old[j] 
                          for j in range(i+1, n))
                x[i] = (1-omega) * x_old[i] + \ (omega/A[i][i]) * (b[i] - sum1 - sum2)

        # Berechne Residuum und relative Aenderung
        res = max(abs(sum(A[i][j] * x[j] for j in range(n)) - b[i]) for i in range(n))
        diff = max(abs(x[i] - x_old[i]) for i in range(n))
        
        iterations.append(x.copy())
        residuals.append(res)
        
        if diff < tol:
            return {
                'solution': x,
                'iterations': iterations,
                'residuals': residuals,
                'iteration_count': iter + 1
            }
            
    raise ValueError(f"Keine Konvergenz nach {max_iter} " + 
                    f"Iterationen\nLetztes Residuum: {res}")
\end{lstlisting}
\end{examplecode}

\subsection{Eigenwerte und Eigenvektoren}

\begin{examplecode}{Komplexe Zahlen in Python}
\begin{lstlisting}[language=Python, style=basesmol]
def complex_operations(z1, z2):
    """Grundlegende Operationen mit komplexen Zahlen."""
    # Basisfunktionen
    def to_polar(z):
        r = (z.real**2 + z.imag**2)**0.5
        phi = math.atan2(z.imag, z.real)
        return r, phi
    
    def from_polar(r, phi):
        return r * (math.cos(phi) + 1j*math.sin(phi))
    
    try:
        # Addition und Subtraktion
        z_add = z1 + z2
        z_sub = z1 - z2
        
        # Multiplikation und Division
        z_mul = z1 * z2
        z_div = z1 / z2 if z2 != 0 else None
        
        # Polarform
        r1, phi1 = to_polar(z1)
        r2, phi2 = to_polar(z2)
        
        # Exponentialform
        z1_exp = from_polar(r1, phi1)
        z2_exp = from_polar(r2, phi2)
        
        return {
            'addition': z_add,
            'subtraktion': z_sub,
            'multiplikation': z_mul,
            'division': z_div,
            'polar_z1': (r1, phi1),
            'polar_z2': (r2, phi2)
        }
        
    except Exception as e:
        print(f"Fehler bei Berechnung: {e}")
        return None

# Beispiel
z1 = 3 - 11j
z2 = 2 + 5j
results = complex_operations(z1, z2)
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{Determinante}
\begin{lstlisting}[language=Python, style=basesmol]
def det_2x2(matrix):
    return matrix[0][0]*matrix[1][1] - matrix[0][1]*matrix[1][0]

def det_3x3(matrix):
    det = 0
    # Entwicklung nach erster Zeile
    for i in range(3):
        minor = []
        for j in range(1,3):
            row = []
            for k in range(3):
                if k != i:
                    row.append(matrix[j][k])
            minor.append(row)
        det += ((-1)**i) * matrix[0][i] * det_2x2(minor)
    return det
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{Basisoperationen}
\begin{lstlisting}[language=Python, style=basesmol]
def characteristic_polynomial(A):
    """Charakteristisches Polynom einer 2x2 oder 3x3 Matrix"""
    n = len(A)
    if n == 2:
        a, b = A[0][0], A[0][1]
        c, d = A[1][0], A[1][1]
        # det(A - lambda*I) = lambda^2 - tr(A)*lambda + det(A)
        return [1, -(a + d), a*d - b*c]
    elif n == 3:
        # Hier nur Koeffizienten, keine Polynomauswertung
        trace = sum(A[i][i] for i in range(3))
        det = (A[0][0]*A[1][1]*A[2][2] + A[0][1]*A[1][2]*A[2][0] + 
               A[0][2]*A[1][0]*A[2][1] - A[0][2]*A[1][1]*A[2][0] - 
               A[0][1]*A[1][0]*A[2][2] - A[0][0]*A[1][2]*A[2][1])
        return [1, -trace, None, det]  # Mittlerer Koeff. kompliziert
    else:
        raise ValueError("Nur fuer 2x2 oder 3x3 Matrizen")

def find_eigenvalues_2x2(A, tol=1e-10):
    """Eigenwerte einer 2x2 Matrix"""
    coeff = characteristic_polynomial(A)
    # Quadratische Formel
    p, q = -coeff[1], coeff[2]
    disc = p*p/4 - q
    if abs(disc) < tol:  # Doppelte Eigenwerte
        return [-p/2, -p/2]
    elif disc > 0:  # Reelle Eigenwerte
        root = disc**0.5
        return [-p/2 + root, -p/2 - root]
    else:  # Komplexe Eigenwerte
        root = (-disc)**0.5
        return [-p/2 + 1j*root, -p/2 - 1j*root]

def find_eigenvector(A, eigenval, tol=1e-10):
    """Eigenvektor zu gegebenem Eigenwert"""
    n = len(A)
    # A - lambda*I
    M = [[A[i][j] - (eigenval if i==j else 0) 
          for j in range(n)] for i in range(n)]
    
    # Loese homogenes System (A - lambda*I)x = 0
    # Nehme eine Komponente als 1 an
    for i in range(n):
        if abs(M[i][i]) > tol:
            vec = [0] * n
            vec[i] = 1
            for j in range(n):
                if j != i:
                    s = sum(-M[j][k]*vec[k] for k in range(n) if k != j)
                    if abs(M[j][j]) > tol:
                        vec[j] = s/M[j][j]
            return normalize_vector(vec)
            
    raise ValueError("Kein Eigenvektor gefunden")
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{Charakteristisches Polynom Koeffizienten berechnen}
\begin{lstlisting}[language=Python, style=basesmol]
def char_poly_coeff(matrix):
    n = len(matrix)
    coeffs = [0] * (n+1)
    # Lambda^n Koeffizient
    coeffs[n] = (-1)**n
    # Spur (Lambda^(n-1) Koeffizient)
    trace = sum(matrix[i][i] for i in range(n))
    coeffs[n-1] = (-1)**(n-1) * trace
    # Determinante (konstanter Term)
    coeffs[0] = det_3x3(matrix)
    
    return coeffs

# Beispielmatrix
A = [[2, 1, 0],
     [1, 2, 1],
     [0, 1, 2]]

# Charakteristisches Polynom berechnen
poly = char_poly_coeff(A)
print("Charakteristisches Polynom:")
print(f"p(lambda) = lambda^3 {poly[2]:+}lambda^2 {poly[1]:+}lambda {poly[0]:+}")
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{Eigenvektoren berechnen} \textcolor{pink}{\texttt{use Gauss from previous example}} 
\begin{lstlisting}[language=Python, style=basesmol]
def find_eigenvector(A, eigenvalue):
    n = len(A)
    # A - lambda*I
    A_lambda = [[A[i][j] - (eigenvalue if i==j else 0) 
                for j in range(n)] for i in range(n)]
    
    # Loese (A - lambda*I)x = 0
    b = [0] * n
    return gauss_elimination(A_lambda, b)

# Eigenvektoren fuer lambda = 1,2,3 berechnen
eigenvalues = [1, 2, 3]
for ev in eigenvalues:
    vec = find_eigenvector(A, ev)
    print(f"Eigenvektor fuer lambda={ev}:", vec)
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{Vektoriteration und inverse Iteration}
\begin{lstlisting}[language=Python, style=basesmol]
def power_iteration(A, tol=1e-10, max_iter=100):
    """Von-Mises-Iteration fuer groessten Eigenwert"""
    n = len(A)
    # Starte mit Einheitsvektor
    v = normalize_vector([1] + [0]*(n-1))
    lambda_old = 0
    
    for _ in range(max_iter):
        # Matrix-Vektor-Multiplikation
        w = matrix_vector_mult(A, v)
        # Normiere neuen Vektor
        v = normalize_vector(w)
        
        # Rayleigh-Quotient
        lambda_k = sum(v[i] * A[i][j] * v[j] 
                      for i in range(n) 
                      for j in range(n))
        
        if abs(lambda_k - lambda_old) < tol:
            return {
                'eigenvalue': lambda_k,
                'eigenvector': v
            }
            
        lambda_old = lambda_k
        
    raise ValueError("Keine Konvergenz")

def inverse_iteration(A, mu, tol=1e-10, max_iter=100):
    """Inverse Iteration fuer Eigenwert nahe mu"""
    n = len(A)
    # Starte mit Einheitsvektor
    v = normalize_vector([1] + [0]*(n-1))
    lambda_old = 0
    
    # (A - mu*I) berechnen
    M = [[A[i][j] - (mu if i==j else 0) 
          for j in range(n)] for i in range(n)]
    
    for _ in range(max_iter):
        # Loese (A - mu*I)w = v
        w = gauss_elimination(M, v)['solution']
        # Normiere neuen Vektor
        v = normalize_vector(w)
        
        # Rayleigh-Quotient
        lambda_k = sum(v[i] * A[i][j] * v[j] 
                      for i in range(n) 
                      for j in range(n))
        
        if abs(lambda_k - lambda_old) < tol:
            return {
                'eigenvalue': lambda_k,
                'eigenvector': v
            }
            
        lambda_old = lambda_k
        
    raise ValueError("Keine Konvergenz")
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{Von-Mises-Iteration}
\begin{lstlisting}[language=Python, style=basesmol]
def matrix_vector_mult(A, v):
    n = len(A)
    result = [0] * n
    for i in range(n):
        for j in range(n):
            result[i] += A[i][j] * v[j]
    return result

def vector_norm(v):
    return sum(x*x for x in v) ** 0.5

def normalize_vector(v):
    norm = vector_norm(v)
    return [x/norm for x in v]

def power_iteration(A, tol=1e-10, max_iter=100):
    n = len(A)
    # Startvektor
    v = normalize_vector([1] + [0]*(n-1))
    
    for _ in range(max_iter):
        # Matrix-Vektor-Multiplikation
        w = matrix_vector_mult(A, v)
        # Normierung
        v_new = normalize_vector(w)
        
        # Rayleigh-Quotient
        lambda_k = sum(v_new[i] * A[i][j] * v_new[j] 
                      for i in range(n) 
                      for j in range(n))
        
        # Konvergenzpruefung
        if vector_norm([v_new[i]-v[i] for i in range(n)]) < tol:
            return lambda_k, v_new
            
        v = v_new
    return lambda_k, v
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{QR-Iteration}
\begin{lstlisting}[language=Python, style=basesmol]
def qr_algorithm(A, tol=1e-10, max_iter=100):
    """QR-Algorithmus fuer alle Eigenwerte"""
    n = len(A)
    A_k = copy_matrix(A)
    
    for k in range(max_iter):
        # QR-Zerlegung
        qr = qr_decomposition(A_k)
        Q, R = qr['Q'], qr['R']
        
        # Neue Iteration A_(k+1) = RQ
        A_k = matrix_mult(R, Q)
        
        # Pruefe ob Diagonalelemente konvergiert sind
        if all(abs(A_k[i][j]) < tol 
               for i in range(1, n) 
               for j in range(i)):
            return {
                'eigenvalues': [A_k[i][i] for i in range(n)],
                'iterations': k+1,
                'final_matrix': A_k
            }
    
    raise ValueError("Keine Konvergenz")

def deflation(A, eigenval, eigenvec):
    """Deflation nach Hotelling"""
    n = len(A)
    v = normalize_vector(eigenvec)
    
    # Berechne A - lambda*vv^T
    vvt = [[v[i]*v[j] for j in range(n)] for i in range(n)]
    return [[A[i][j] - eigenval*vvt[i][j] 
             for j in range(n)] for i in range(n)]
\end{lstlisting}
\end{examplecode}

\begin{examplecode}{QR-Verfahren}
\begin{lstlisting}[language=Python, style=basesmol]
def matmul(A, B):
    n = len(A)
    C = [[0.0] * n for _ in range(n)]
    for i in range(n):
        for j in range(n):
            C[i][j] = sum(A[i][k] * B[k][j] 
                     for k in range(n))
    return C

def transpose(A):
    n = len(A)
    return [[A[j][i] for j in range(n)] 
            for i in range(n)]

def householder(x):
    n = len(x)
    # Norm berechnen
    s = sum(x[i]**2 for i in range(1, n))
    v = [0.0] * n
    if s == 0:
        return v
    
    v[0] = x[0]
    norm_x = (x[0]**2 + s)**0.5
    if x[0] <= 0:
        v[0] = x[0] - norm_x
    else:
        v[0] = -s/(x[0] + norm_x)
    
    for i in range(1, n):
        v[i] = x[i]
    
    return normalize_vector(v)

def qr_algorithm(A, tol=1e-10, max_iter=100):
    n = len(A)
    A_k = [row[:] for row in A]  # Kopiere A
    
    for k in range(max_iter):
        # QR-Zerlegung mit Householder
        Q = [[1.0 if i==j else 0.0 
              for j in range(n)] 
              for i in range(n)]
        R = [row[:] for row in A_k]
        
        for j in range(n-1):
            v = householder([R[i][j] 
                 for i in range(j, n)])
            # Householder-Transformation anwenden
            
        # Neue Iteration A_(k+1) = RQ
        A_k = matmul(R, Q)
        
        # Konvergenztest
        if max(abs(A_k[i][j]) 
               for i in range(1, n) 
               for j in range(i)) < tol:
            break
    
    return [A_k[i][i] for i in range(n)]
\end{lstlisting}
\end{examplecode}

\begin{KR}{Eigenwertberechnung - Praktisches Vorgehen}
\begin{enumerate}
    \item Voranalyse
    \begin{itemize}
        \item Matrix auf spezielle Struktur prüfen (symmetrisch, etc.)
        \item Grobe Eigenwertabschätzung durch Gerschgorin-Kreise
        \item Kondition der Matrix prüfen
    \end{itemize}
    
    \item Verfahrenswahl
    \begin{itemize}
        \item QR: Für alle Eigenwerte
        \item Vektoriteration: Für größten Eigenwert
        \item Inverse Iteration: Für bekannte Näherung
    \end{itemize}
    
    \item Durchführung
    \begin{itemize}
        \item Geeignete Toleranz wählen
        \item Konvergenz überwachen
        \item Bei Bedarf Shifts einsetzen
    \end{itemize}
    
    \item Validation
    \begin{itemize}
        \item Residuen prüfen: $(A-\lambda I)v$
        \item Orthogonalität der Eigenvektoren testen
        \item Ergebnisse physikalisch interpretieren
    \end{itemize}
\end{enumerate}
\end{KR}