\section{Rechnerarithmetik}

\subsection{Zahlendarstellung}

\begin{definition}{Maschinenzahlen}
Eine maschinendarstellbare Zahl zur Basis $B$ ist ein Element der Menge:
$$M = \{x \in \mathbb{R} \mid x = \pm 0.m_1m_2m_3\ldots m_n \cdot B^{\pm e_1e_2\ldots e_l}\} \cup \{0\}$$

Mit:
\begin{itemize}
    \item $m_1 \neq 0$ (Normalisierungsbedingung) 
    \item $m_i, e_i \in \{0,1,\ldots,B-1\}$ für $i \neq 0$
    \item $B \in \mathbb{N}, B > 1$ (Basis)
\end{itemize}
\end{definition}

\begin{formula}{Zahlenwert}
Der Wert $\hat{\omega}$ einer Maschinenzahl berechnet sich durch:
$$\hat{\omega} = \sum_{i=1}^n m_i B^{\hat{e}-i}, \quad \text{mit} \quad \hat{e} = \sum_{i=1}^l e_i B^{l-i}$$
\end{formula}

\begin{example2}{Werteberechnung}Berechnung einer vierstelligen Zahl zur Basis 4:
$$\underbrace{0.3211}_{n=4} \cdot \underbrace{4^{12}}_{l=2}$$
\begin{enumerate}
    \item Exponent: $\hat{e} = 1 \cdot 4^1 + 2 \cdot 4^0 = 6$
    \item Wert: $\hat{\omega} = 3 \cdot 4^5 + 2 \cdot 4^4 + 1 \cdot 4^3 + 1 \cdot 4^2 = 3664$
\end{enumerate}
\end{example2}

\begin{concept}{IEEE-754 Standard}\\
Der IEEE-754 Standard definiert zwei wichtige Gleitpunktformate:
\paragraph{Single Precision (32 Bit)}
\begin{itemize}
    \item Vorzeichen (V): 1 Bit
    \item Exponent (E): 8 Bit (Bias 127)
    \item Mantisse (M): 23 Bit + 1 hidden bit
\end{itemize}
\paragraph{Double Precision (64 Bit)}
\begin{itemize}
    \item Vorzeichen (V): 1 Bit
    \item Exponent (E): 11 Bit (Bias 1023)
    \item Mantisse (M): 52 Bit + 1 hidden bit
\end{itemize}
\end{concept}

\begin{theorem}{Darstellungsbereich}
Für jedes Gleitpunktsystem existieren:
\begin{itemize}
    \item Grösste darstellbare Zahl: \large{$x_{\text{max}} = (1-B^{-n}) \cdot B^{e_{\text{max}}}$}
    \item \normalsize{Kleinste darstellbare positive Zahl:} \large{$x_{\text{min}} = B^{e_{\text{min}}-1}$}
\end{itemize}
\end{theorem}

\subsection{Approximations- und Rundungsfehler}

\begin{definition}{Fehlerarten}
Sei $\tilde{x}$ eine Näherung des exakten Wertes $x$:
\vspace{1mm}\\
\begin{minipage}[t]{0.35\textwidth}
    \textbf{Absoluter Fehler:}  $$\left|\tilde{x}-x\right|$$
\end{minipage}
\hspace{3mm}
\begin{minipage}[t]{0.5\textwidth}
    \textbf{Relativer Fehler:}  $$\left|\frac{\tilde{x}-x}{x}\right| \text{ bzw. } \frac{|\tilde{x}-x|}{|x|} \text{ für } x \neq 0$$
\end{minipage}
\end{definition}

\begin{lemma}{Maschinengenauigkeit} 
    eps ist die kleinste positive Zahl, für die gilt:
    \vspace{1mm}\\
\begin{minipage}[t]{0.45\textwidth}
    \textbf{Allgemein:}  $$\text{eps} := \frac{B}{2} \cdot B^{-n}$$
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
    \textbf{Dezimal:}  $$\text{eps}_{10} := 5 \cdot 10^{-n}$$
\end{minipage}

Sie begrenzt den maximalen relativen Rundungsfehler:
$$\left|\frac{rd(x)-x}{x}\right| \leq \text{eps}$$
\end{lemma}

\begin{corollary}{Rundungseigenschaften}
Für alle $x \in \mathbb{R}$ mit $|x| \geq x_{\text{min}}$ gilt:
\vspace{1mm}\\
\begin{minipage}[t]{0.45\textwidth}
    \textbf{Absoluter Fehler:}  $$|rd(x) - x| \leq \frac{B}{2} \cdot B^{e-n-1}$$
\end{minipage}
\hspace{3mm}
\begin{minipage}[t]{0.35\textwidth}
    \textbf{Relativer Fehler:}  $$\left|\frac{rd(x)-x}{x}\right| \leq \text{eps}$$
\end{minipage}
\end{corollary}

\subsection{Fehlerfortpflanzung}

\begin{concept}{Konditionierung}\\
Die Konditionszahl $K$ beschreibt die relative Fehlervergrösserung bei Funktionsauswertungen:
$$K := \frac{|f'(x)| \cdot |x|}{|f(x)|}$$

\paragraph{Interpretation}
\begin{itemize}
    \item $K \leq 1$: gut konditioniert
    \item $K > 1$: schlecht konditioniert
    \item $K \gg 1$: sehr schlecht konditioniert
\end{itemize}
\end{concept}

\begin{theorem}{Fehlerfortpflanzung}\\
Für eine differenzierbare Funktion $f$ gilt näherungsweise:
\vspace{1mm}\\
\begin{minipage}[t]{0.47\textwidth}
    \textbf{Absoluter Fehler:}  $$|f(\tilde{x})-f(x)| \approx |f'(x)| \cdot |\tilde{x}-x|$$
\end{minipage}
\hspace{2mm}
\begin{minipage}[t]{0.43\textwidth}
    \textbf{Relativer Fehler:}  $$\frac{|f(\tilde{x})-f(x)|}{|f(x)|} \approx K \cdot \frac{|\tilde{x}-x|}{|x|}$$
\end{minipage}
\end{theorem}

\begin{KR}{Fehleranalyse einer Funktion}\\
So analysieren Sie die Fehlerfortpflanzung einer Funktion:
\begin{enumerate}
    \item Berechnen Sie $f'(x)$
    \item Bestimmen Sie die Konditionszahl $K$
    \item Schätzen Sie den absoluten Fehler ab
    \item Schätzen Sie den relativen Fehler ab
    \item Beurteilen Sie die Konditionierung anhand von $K$
\end{enumerate}

$$
\begin{aligned}
\underbrace{|f(\tilde{x})-f(x)|}_{\text {absoluter Fehler von } f(x)} & \approx\left|f^{\prime}(x)\right| \cdot \underbrace{|\tilde{x}-x|}_{\text {absoluter Fehler von } x} \\
\underbrace{\frac{|f(\tilde{x})-f(x)|}{|f(x)|}}_{\text {relativer Fehler von } f(x)} & \approx \underbrace{\frac{\left|f^{\prime}(x)\right| \cdot|x|}{|f(x)|}}_{\text {Konditionszahl } K} . \quad \underbrace{\frac{|\tilde{x}-x|}{|x|}}_{\text { relativer Fehler von } x }
\end{aligned}
$$
\end{KR}

\raggedcolumns

\begin{example2}{Fehleranalyse}Beispiel: Fehleranalyse von $f(x)=\sin(x)$
\begin{enumerate}
    \item $f'(x) = \cos(x)$
    \item $K = \frac{|x\cos(x)|}{|\sin(x)|}$
    \item Für $x \to 0$: $K \to 1$ (gut konditioniert)
    \item Für $x \to \pi$: $K \to \infty$ (schlecht konditioniert)
    \item Der absolute Fehler wird nicht vergrössert, da $|\cos(x)| \leq 1$
\end{enumerate}
\end{example2}

\begin{remark2}{Auslöschung}Besonders problematisch: Auslöschung\\
Bei der Subtraktion fast gleich großer Zahlen können signifikante Stellen verloren gehen. Beispiel:
\begin{itemize}
    \item $1.234567 - 1.234566 = 0.000001$
    \item Aus 7 signifikanten Stellen wird 1 signifikante Stelle
\end{itemize}
\end{remark2}

\subsection{Praktische Fehlerquellen}

\begin{concept}{Kritische Operationen}\\
Die häufigsten Quellen für numerische Fehler sind:
\begin{itemize}
    \item Auslöschung bei Subtraktion ähnlich großer Zahlen
    \item Überlauf (overflow) bei zu großen Zahlen
    \item Unterlauf (underflow) bei zu kleinen Zahlen
    \item Verlust signifikanter Stellen durch Rundung
\end{itemize}
\end{concept}

\begin{example2}{Auslöschung} bei der Berechnung von $\sqrt{x^2 + 1} - 1$:\\
Für kleine $x$ führt die direkte Berechnung zu Auslöschung:
\begin{itemize}
    \item Für $x = 10^{-8}$:
    \item $\sqrt{10^{-16} + 1} - 1 \approx 1.000000000 - 1 = 0$
    \item Korrekte Lösung durch Umformung:
    \item $\sqrt{x^2 + 1} - 1 = \frac{x^2}{\sqrt{x^2 + 1} + 1}$
\end{itemize}
\end{example2}

\begin{KR}{Vermeidung von Auslöschung}\\
So vermeiden Sie Auslöschungseffekte:
\begin{enumerate}
    \item Identifizieren Sie Subtraktionen ähnlich großer Zahlen
    \item Suchen Sie nach algebraischen Umformungen
    \item Prüfen Sie alternative Berechnungswege
    \item Verwenden Sie Taylorentwicklungen für kleine Werte
\end{enumerate}
\end{KR}

\subsection{Analyse von Algorithmen}

\begin{theorem}{Fehlerakkumulation}\\
Bei $n$ aufeinanderfolgenden Operationen mit relativen Fehlern $\leq \varepsilon$ gilt für den Gesamtfehler:
\begin{itemize}
    \item Best case: $\mathcal{O}(n\varepsilon)$ bei gleichverteilten Fehlern
    \item Worst case: $\mathcal{O}(2^n\varepsilon)$ bei systematischen Fehlern
\end{itemize}
\end{theorem}

\begin{concept}{Numerische Stabilität}\\
Ein Algorithmus heißt numerisch stabil, wenn:
\begin{itemize}
    \item Kleine Eingabefehler zu kleinen Ausgabefehlern führen
    \item Rundungsfehler sich nicht übermäßig akkumulieren
    \item Die Konditionszahl des Problems nicht künstlich verschlechtert wird
\end{itemize}
\end{concept}

\begin{example2}{Instabilität}Instabiles Verhalten bei rekursiver Berechnung:\\
Berechnung der Fibonacci-Zahlen:
\begin{lstlisting}[language=Python, style=basesmol]
def fib(n):
    if n <= 1:
        return n
    return fib(n-1) + fib(n-2)
\end{lstlisting}
Problem: Exponentielles Wachstum der Operationen und Fehlerfortpflanzung.
\end{example2}

\begin{KR}{Stabilitätsanalyse}\\
Schritte zur Analyse der numerischen Stabilität:
\begin{enumerate}
    \item Bestimmen Sie kritische Operationen
    \item Schätzen Sie Rundungsfehler pro Operation ab
    \item Analysieren Sie die Fehlerfortpflanzung
    \item Berechnen Sie die worst-case Fehlerschranke
    \item Vergleichen Sie alternative Implementierungen
\end{enumerate}
\end{KR}

\subsection{Praktische Implementierungen}

\begin{definition}{Implementierungsgenauigkeit}\\
Die Implementierungsgenauigkeit eines Algorithmus beschreibt:
\begin{itemize}
    \item Relative Genauigkeit der Ausgabe
    \item Maximale Anzahl korrekter Dezimalstellen
    \item Stabilität gegenüber Eingabefehlern
\end{itemize}
\end{definition}

\begin{KR}{Robuste Implementierung}\\
So implementieren Sie numerisch robuste Algorithmen:
\begin{enumerate}
    \item Verwenden Sie stabile Grundoperationen
    \item Vermeiden Sie Differenzen ähnlich großer Zahlen
    \item Prüfen Sie auf Über- und Unterlauf
    \item Implementieren Sie Fehlerkontrollen
    \item Dokumentieren Sie numerische Einschränkungen
\end{enumerate}
\end{KR}

\begin{example2}{Robuste Implementation} Beispiel: Quadratische Gleichung
\begin{lstlisting}[language=Python, style=basesmol]
def quadratic_stable(a, b, c):
    # ax^2 + bx + c = 0
    if a == 0:
        return [-c/b] if b != 0 else []
        
    # Calculate discriminant
    disc = b*b - 4*a*c
    if disc < 0:
        return []
        
    # Choose numerically stable formula
    if b >= 0:
        q = -0.5*(b + sqrt(disc))
    else:
        q = -0.5*(b - sqrt(disc))
        
    x1 = q/a
    x2 = c/(q)
    return sorted([x1, x2])
\end{lstlisting}
\end{example2}

\begin{remark2}{Numerische Bibliotheken} Verwendung spezialisierter Bibliotheken\\
Für kritische numerische Berechnungen:
\begin{itemize}
    \item NumPy: Optimierte Array-Operationen
    \item SciPy: Wissenschaftliches Rechnen
    \item Mpmath: Beliebige Präzision
    \item Decimal: Dezimalarithmetik
\end{itemize}
\end{remark2}

\begin{example2}{Bibliotheksverwendung} Beispiel: Präzise Berechnung mit Decimal\\
\begin{lstlisting}[language=Python, style=basesmol]
from decimal import Decimal, getcontext

# Set precision
getcontext().prec = 40

# Precise calculation
x = Decimal('1.0') / Decimal('7.0')
print(x)  # 0.1428571428571428571428571428571428571428
\end{lstlisting}
\end{example2}