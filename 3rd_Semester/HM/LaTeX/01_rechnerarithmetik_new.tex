\section{Rechnerarithmetik}

\subsection{Zahlendarstellung}

\begin{definition}{Maschinenzahlen}
Eine maschinendarstellbare Zahl zur Basis $B$ ist ein Element der Menge:
\vspace{-2mm}\\
$$M = \{x \in \mathbb{R} \mid x = \pm 0.m_1m_2m_3\ldots m_n \cdot B^{\pm e_1e_2\ldots e_l}\} \cup \{0\}$$
\vspace{-2mm}
\begin{itemize}
    \item $m_1 \neq 0$ (Normalisierungsbedingung) 
    \item $m_i, e_i \in \{0,1,\ldots,B-1\}$ für $i \neq 0$
    \item $B \in \mathbb{N}, B > 1$ (Basis)
\end{itemize}
\end{definition}

\begin{formula}{Zahlenwert $\hat{\omega}$}
$ = \sum_{i=1}^n m_i B^{\hat{e}-i}, \quad \text{mit} \quad \hat{e} = \sum_{i=1}^l e_i B^{l-i}$
\end{formula}

\begin{KR}{Werteberechnung einer Maschinenzahl} 
\begin{enumerate}
    \item Normalisierung überprüfen: $m_1 \neq 0$ (für $x \neq 0$)
    \begin{itemize}
        \item Sonst: Mantisse verschieben und Exponent anpassen
    \end{itemize}
    \item Exponent berechnen: $\hat{e} = \sum_{i=1}^l e_i B^{l-i}$ 
    \begin{itemize}
        \item Von links nach rechts: Stelle $\cdot$ Basis hochgestellt zur Position
    \end{itemize}
    
    \item Wert berechnen: $\hat{\omega} = \sum_{i=1}^n m_i B^{\hat{e}-i}$
    \begin{itemize}
        \item Mantissenstellen $\cdot$ Basis hochgestellt zu (Exponent - Position)
    \end{itemize}
    \item Vorzeichen berücksichtigen
\end{enumerate}
\end{KR}

\begin{example2}{Werteberechnung} Berechnung einer vierstelligen Zahl zur Basis 4:
    \vspace{-2mm}\\
    \begin{minipage}{0.3\textwidth}
        $$\underbrace{0.3211}_{n=4} \cdot \underbrace{4^{12}}_{l=2}$$
    \end{minipage}
    \begin{minipage}[t]{0.65\textwidth}
        Exponent: $\hat{e} = 1 \cdot 4^1 + 2 \cdot 4^0 = 6$ \vspace{1mm}\\
        Wert: $\hat{\omega} = 3 \cdot 4^3 + 2 \cdot 4^2 + 1 \cdot 4^1 + 1 \cdot 4^0 = 57$
    \end{minipage}
\end{example2}



\begin{concept}{IEEE-754 Standard} definiert zwei wichtige Gleitpunktformate:
\vspace{1mm}\\
\begin{minipage}[t]{0.5\textwidth}
    \textbf{Single Precision} (32 Bit)\\
    Vorzeichen(V): 1 Bit\\
    Exponent(E): 8 Bit (Bias 127)\\
    Mantisse(M): \\ 23 Bit + 1 hidden bit
\end{minipage}
\begin{minipage}[t]{0.48\textwidth}
    \textbf{Double Precision} (64 Bit)\\
    Vorzeichen(V): 1 Bit\\
    Exponent(E): 11 Bit (Bias 1023)\\
    Mantisse(M): \\ 52 Bit + 1 hidden bit
\end{minipage}
\end{concept}

\begin{theorem}{Darstellungsbereich}
Für jedes Gleitpunktsystem existieren:
\begin{itemize}
    \item Grösste darstellbare Zahl: \large{$x_{\text{max}} = (1-B^{-n}) \cdot B^{e_{\text{max}}}$}
    \item \normalsize{Kleinste darstellbare positive Zahl:} \large{$x_{\text{min}} = B^{e_{\text{min}}-1}$}
\end{itemize}
\end{theorem}

\subsection{Approximations- und Rundungsfehler}

\begin{definition}{Fehlerarten}
Sei $\tilde{x}$ eine Näherung des exakten Wertes $x$:
\vspace{1mm}\\
\begin{minipage}[t]{0.45\textwidth}
    \textbf{Absoluter Fehler:} 
    \begin{center} $\left|\tilde{x}-x\right|$ \end{center}
\end{minipage}
\hspace{3mm}
\begin{minipage}[t]{0.5\textwidth}
    \textbf{Relativer Fehler:} 
    \begin{center} $\left|\frac{\tilde{x}-x}{x}\right| \text{ bzw. } \frac{|\tilde{x}-x|}{|x|} \text{ für } x \neq 0$ \end{center}
\end{minipage}
\end{definition}

\begin{lemma}{Maschinengenauigkeit} 
    eps ist die kleinste positive Zahl, für die gilt:
    \vspace{-3mm}\\
\begin{minipage}[b]{0.45\textwidth}
    \textbf{Allgemein:}  $\text{eps} := \frac{B}{2} \cdot B^{-n}$
\end{minipage}
\hspace{6mm}
\begin{minipage}[b]{0.45\textwidth}
    \textbf{Dezimal:}  $\text{eps}_{10} := 5 \cdot 10^{-n}$
\end{minipage}

\begin{minipage}[t]{0.6\textwidth}
    Sie begrenzt den\\ maximalen relativen Rundungsfehler:
\end{minipage}
\begin{minipage}{0.35\textwidth}
    \vspace{1mm}
    $\left|\frac{rd(x)-x}{x}\right| \leq \text{eps}$
\end{minipage}
\end{lemma}

\begin{corollary}{Rundungseigenschaften}
Für alle $x \in \mathbb{R}$ mit $|x| \geq x_{\text{min}}$ gilt:
\vspace{1mm}\\
\begin{minipage}[t]{0.45\textwidth}
    \textbf{Absoluter Fehler:}  
    \begin{center} $|rd(x) - x| \leq \frac{B}{2} \cdot B^{e-n-1}$ \end{center}
\end{minipage}
\hspace{3mm}
\begin{minipage}[t]{0.35\textwidth}
    \textbf{Relativer Fehler:}  
    \begin{center} $\left|\frac{rd(x)-x}{x}\right| \leq \text{eps}$ \end{center}
\end{minipage}
\end{corollary}

\subsubsection{Fehlerfortpflanzung}

\begin{concept}{Konditionierung}
    Die Konditionszahl $K$ beschreibt die relative Fehlervergrösserung bei Funktionsauswertungen:
    \vspace{1mm}\\
\begin{minipage}{0.3\textwidth}
    \vspace{-2mm}
    $$K := \frac{|f'(x)| \cdot |x|}{|f(x)|}$$
\end{minipage}
\hspace{2mm}
\begin{minipage}{0.6\textwidth}
\begin{itemize}
    \item $K \leq 1$: gut konditioniert
    \item $K > 1$: schlecht konditioniert
    \item $K \gg 1$: sehr schlecht konditioniert
\end{itemize}
\end{minipage}
\end{concept}

\begin{theorem}{Fehlerfortpflanzung}
Für $f$ (differenzierbar) gilt näherungsweise:
\vspace{1mm}\\
\begin{minipage}[t]{0.47\textwidth}
    \textbf{Absoluter Fehler:}  
    \vspace{-2mm}\\
    $$|f(\tilde{x})-f(x)| \approx |f'(x)| \cdot |\tilde{x}-x|$$
\end{minipage}
\hspace{3mm}
\begin{minipage}[t]{0.43\textwidth}
    \textbf{Relativer Fehler:}  
    \vspace{-2mm}\\
    $$\frac{|f(\tilde{x})-f(x)|}{|f(x)|} \approx K \cdot \frac{|\tilde{x}-x|}{|x|}$$
\end{minipage}
\end{theorem}

\begin{KR}{Analyse der Fehlerfortpflanzung einer Funktion}
\begin{enumerate}
    \item Berechnen Sie $f'(x)$
    \item Bestimmen Sie die Konditionszahl $K$
    \item Schätzen Sie den absoluten Fehler ab
    \item Schätzen Sie den relativen Fehler ab
    \item Beurteilen Sie die Konditionierung anhand von $K$
\end{enumerate}
\vspace{1mm}
$$
\begin{aligned}
\underbrace{|f(\tilde{x})-f(x)|}_{\text {absoluter Fehler von } f(x)} & \approx\left|f^{\prime}(x)\right| \cdot \underbrace{|\tilde{x}-x|}_{\text {absoluter Fehler von } x} \\
\underbrace{\frac{|f(\tilde{x})-f(x)|}{|f(x)|}}_{\text {relativer Fehler von } f(x)} & \approx \underbrace{\frac{\left|f^{\prime}(x)\right| \cdot|x|}{|f(x)|}}_{\text {Konditionszahl } K} . \quad \underbrace{\frac{|\tilde{x}-x|}{|x|}}_{\text { relativer Fehler von } x }
\end{aligned}
$$
\end{KR}

\raggedcolumns

\begin{example2}{Fehleranalyse}Beispiel: Fehleranalyse von $f(x)=\sin(x)$
\begin{enumerate}
    \item $f'(x) = \cos(x)$
    \item $K = \frac{|x\cos(x)|}{|\sin(x)|}$
    \item Für $x \to 0$: $K \to 1$ (gut konditioniert)
    \item Für $x \to \pi$: $K \to \infty$ (schlecht konditioniert)
    \item Für $x = 0$: $\lim_{x \to 0} K = 1$ (gut konditioniert)
    \item Der absolute Fehler wird nicht vergrössert, da $|\cos(x)| \leq 1$
\end{enumerate}
\end{example2}

\subsubsection{Praktische Fehlerquellen der Numerik}

\begin{concept}{Kritische Operationen} häufigste Fehlerquellen:
\begin{itemize}
    \item Auslöschung bei Subtraktion ähnlich großer Zahlen
    \item Überlauf (overflow) bei zu großen Zahlen
    \item Unterlauf (underflow) bei zu kleinen Zahlen
    \item Verlust signifikanter Stellen durch Rundung
\end{itemize}
\end{concept}

\begin{KR}{Vermeidung von Auslöschung}
\begin{enumerate}
    \item Identifizieren Sie Subtraktionen ähnlich großer Zahlen
    \item Suchen Sie nach algebraischen Umformungen
    \item Prüfen Sie alternative Berechnungswege
    \item Verwenden Sie Taylorentwicklungen für kleine Werte
\end{enumerate}
\end{KR}

\begin{example2}{Auslöschung} Kritische Berechnungen für kleine x (Auslöschung):
\begin{enumerate}
    \item $\sqrt{1 + x^2} - 1$: \textbf{Besser}: $\frac{x^2}{\sqrt{1 + x^2} + 1}$
    \item $1 - \cos(x)$: \textbf{Besser}: $2\sin^2(x/2)$
\end{enumerate}
\end{example2}

\begin{remark2}{Auslöschung}
    Bei der Subtraktion fast gleich großer Zahlen können signifikante Stellen verloren gehen. Beispiel:
    \begin{itemize}
        \item $1.234567 - 1.234566 = 0.000001$
        \item Aus 7 signifikanten Stellen wird 1 signifikante Stelle
    \end{itemize}
\end{remark2}

\subsubsection{Analyse von Algorithmen}

\begin{formula}{Fehlerakkumulation}
Bei $n$ aufeinanderfolgenden Operationen mit relativen Fehlern $\leq \varepsilon$ gilt für den Gesamtfehler:
\begin{itemize}
    \item Best case: $\mathcal{O}(n\varepsilon)$ bei gleichverteilten Fehlern
    \item Worst case: $\mathcal{O}(2^n\varepsilon)$ bei systematischen Fehlern
\end{itemize}
\end{formula}

\begin{concept}{Numerische Stabilität eines Algorithmus}
\begin{itemize}
    \item Kleine Eingabefehler führen zu kleinen Ausgabefehlern
    \item Rundungsfehler akkumulieren sich nicht übermäßig 
    \item Konditionszahl des Problems wird nicht künstlich verschlechtert
\end{itemize}
\end{concept}

\begin{examplecode}{Numerische Stabilität} Fibonacci-Zahlen:
\begin{lstlisting}[language=Python, style=basesmol]
def fib_unstable(n): # Instabile rekursive Version
    if n <= 1:
        return n
    return fib_unstable(n-1) + fib_unstable(n-2)

def fib_stable(n): # Stabile iterative Version
    if n <= 1:
        return n
    a, b = 0, 1
    for _ in range(2, n + 1):
        a, b = b, a + b
    return b
\end{lstlisting}
\end{examplecode}

\begin{KR}{Stabilitätsanalyse}
Schritte zur Analyse der numerischen Stabilität:
\begin{enumerate}
    \item Bestimmen Sie kritische Operationen
    \item Schätzen Sie Rundungsfehler pro Operation ab
    \item Analysieren Sie die Fehlerfortpflanzung
    \item Berechnen Sie die worst-case Fehlerschranke
    \item Vergleichen Sie alternative Implementierungen
\end{enumerate}
\end{KR}

\begin{definition}{Implementierungsgenauigkeit eines Algorithmus}
\begin{itemize}
    \item Relative Genauigkeit der Ausgabe
    \item Maximale Anzahl korrekter Dezimalstellen
    \item Stabilität gegenüber Eingabefehlern
\end{itemize}
\end{definition}

\begin{KR}{Robuste Implementierung von Algorithmen}
\begin{enumerate}
    \item Verwenden Sie stabile Grundoperationen
    \item Vermeiden Sie Differenzen ähnlich großer Zahlen
    \item Prüfen Sie auf Über- und Unterlauf
    \item Implementieren Sie Fehlerkontrollen
    \item Dokumentieren Sie numerische Einschränkungen
\end{enumerate}
\end{KR}

\begin{examplecode}{Robuste Implementation} Quadratische Gleichung:
\begin{lstlisting}[language=Python, style=basesmol]
# Numerisch stabile Implementation
def solve_quadratic_stable(a, b, c):
    if a == 0:
        return [-c/b] if b != 0 else []
    d = b**2 - 4*a*c
    if d < 0:
        return []
    if b >= 0:
        q = -0.5*(b + d**0.5)
    else:
        q = -0.5*(b - d**0.5)
    x1 = q/a
    x2 = c/q
    return sorted([x1, x2])
\end{lstlisting}
\end{examplecode}
