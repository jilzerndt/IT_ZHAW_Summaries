\section{Rechnerarithmetik}

\subsection{Zahlendarstellung}

\begin{definition}{Maschinenzahlen}
Eine maschinendarstellbare Zahl zur Basis $B$ ist ein Element der Menge:
\vspace{-2mm}\\
$$M = \{x \in \mathbb{R} \mid x = \pm 0.m_1m_2m_3\ldots m_n \cdot B^{\pm e_1e_2\ldots e_l}\} \cup \{0\}$$
\vspace{-2mm}
\begin{itemize}
    \item $m_1 \neq 0$ (Normalisierungsbedingung) 
    \item $m_i, e_i \in \{0,1,\ldots,B-1\}$ für $i \neq 0$
    \item $B \in \mathbb{N}, B > 1$ (Basis)
\end{itemize}
\end{definition}

\begin{formula}{Zahlenwert $\hat{\omega}$}
$ = \sum_{i=1}^n m_i B^{\hat{e}-i}, \quad \text{mit} \quad \hat{e} = \sum_{i=1}^l e_i B^{l-i}$
\end{formula}

\begin{KR}{Werteberechnung einer Maschinenzahl} 
\begin{enumerate}
    \item Normalisierung überprüfen: $m_1 \neq 0$ (für $x \neq 0$)
    \begin{itemize}
        \item Sonst: Mantisse verschieben und Exponent anpassen
    \end{itemize}
    \item Exponent berechnen: $\hat{e} = \sum_{i=1}^l e_i B^{l-i}$ 
    \begin{itemize}
        \item Von links nach rechts: Stelle $\cdot$ Basis hochgestellt zur Position
    \end{itemize}
    
    \item Wert berechnen: $\hat{\omega} = \sum_{i=1}^n m_i B^{\hat{e}-i}$
    \begin{itemize}
        \item Mantissenstellen $\cdot$ Basis hochgestellt zu (Exponent - Position)
    \end{itemize}
    \item Vorzeichen berücksichtigen
\end{enumerate}
\end{KR}

\begin{example2}{Werteberechnung} Berechnung einer vierstelligen Zahl zur Basis 4:
    \vspace{-2mm}\\
    \begin{minipage}{0.3\textwidth}
        $$\underbrace{0.3211}_{n=4} \cdot \underbrace{4^{12}}_{l=2}$$
    \end{minipage}
    \begin{minipage}[t]{0.65\textwidth}
        Exponent: $\hat{e} = 1 \cdot 4^1 + 2 \cdot 4^0 = 6$ \vspace{1mm}\\
        Wert: $\hat{\omega} = 3 \cdot 4^5 + 2 \cdot 4^4 + 1 \cdot 4^3 + 1 \cdot 4^2 = 3664$
    \end{minipage}
\end{example2}



\begin{concept}{IEEE-754 Standard} definiert zwei wichtige Gleitpunktformate:
\vspace{1mm}\\
\begin{minipage}[t]{0.5\textwidth}
    \textbf{Single Precision} (32 Bit)\\
    Vorzeichen(V): 1 Bit\\
    Exponent(E): 8 Bit (Bias 127)\\
    Mantisse(M): \\ 23 Bit + 1 hidden bit
\end{minipage}
\begin{minipage}[t]{0.48\textwidth}
    \textbf{Double Precision} (64 Bit)\\
    Vorzeichen(V): 1 Bit\\
    Exponent(E): 11 Bit (Bias 1023)\\
    Mantisse(M): \\ 52 Bit + 1 hidden bit
\end{minipage}
\end{concept}

\begin{example2}{IEEE-754 Details}
IEEE-754 Standard definiert zwei wichtige Eigenschaften:
\begin{itemize}
    \item \textbf{Overflow}: Zahlen außerhalb $[-x_{max}, x_{max}]$ führen zum Abbruch mit \texttt{inf}
    \item \textbf{Underflow}: Zahlen in $[-x_{min}, x_{min}]$ werden zu 0 gerundet
\end{itemize}

\paragraph{Bias-Werte:}
\begin{itemize}
    \item Single Precision: Bias = 127 ($e_{stored} = e_{actual} + 127$)
    \item Double Precision: Bias = 1023 ($e_{stored} = e_{actual} + 1023$)
\end{itemize}

\paragraph{Praktisches Beispiel: Ariane 5}
Am 4. Juni 1996 explodierte die Ariane 5 Rakete aufgrund eines Überlaufs:
\begin{itemize}
    \item Horizontale Geschwindigkeit zu groß für 16-bit Integer
    \item Überlauf bei Konvertierung von 64-bit Float zu 16-bit Integer
    \item Verlust von etwa 500 Millionen Dollar
\end{itemize}
\end{example2}

\begin{theorem}{Darstellungsbereich}
Für jedes Gleitpunktsystem existieren:
\begin{itemize}
    \item Grösste darstellbare Zahl: \large{$x_{\text{max}} = (1-B^{-n}) \cdot B^{e_{\text{max}}}$}
    \item \normalsize{Kleinste darstellbare positive Zahl:} \large{$x_{\text{min}} = B^{e_{\text{min}}-1}$}
\end{itemize}
\end{theorem}

\begin{KR}{Maschinenzahlen analysieren}
\begin{enumerate}
    \item Anzahl Maschinenzahlen bestimmen:
    \begin{itemize}
        \item Basis $B$ identifizieren 
        \item Mantissenlänge $n$ bestimmen
        \item Exponentenlänge $l$ bestimmen
        \item Berechnen: $2 \cdot (B-1) \cdot B^{n-1} \cdot (B^l-1)$
    \end{itemize}
    \item Darstellungsbereich bestimmen:
    \begin{itemize}
        \item Größte Zahl: $x_{max} = (1-B^{-n})B^{e_{max}}$
        \item Kleinste positive Zahl: $x_{min} = B^{e_{min}-1}$
    \end{itemize}
    \item Maschinengenauigkeit berechnen:
    \begin{itemize}
        \item Allgemein: $eps = \frac{B}{2}B^{-n}$
        \item Dezimal: $eps = 5 \cdot 10^{-n}$
    \end{itemize}
\end{enumerate}
\end{KR}

\begin{example2}{Maschinenzahlen analysieren}
Gegeben: 15-stellige Gleitpunktzahlen mit 5-stelligem Exponenten im Dualsystem.

\paragraph{Lösung:}
\begin{enumerate}
    \item Basis $B=2$, $n=15$, $l=5$
    \item Anzahl verschiedener Zahlen:
    \begin{itemize}
        \item Pro Stelle: $B-1=1$ mögliche Ziffern
        \item Mantisse: $(B-1)B^{n-1} = 2^{14}$ Kombinationen
        \item Exponent: $B^l = 2^5 = 32$ Kombinationen
        \item Mit Vorzeichen: $2 \cdot 2^{14} \cdot 31 = 1\,015\,808$ Zahlen
    \end{itemize}
    \item Maschinengenauigkeit:
    $eps = \frac{2}{2}2^{-15} = 2^{-15} \approx 3.052 \cdot 10^{-5}$
\end{enumerate}
\end{example2}

\begin{KR}{Vergleich von Zahlensystemen}
\begin{enumerate}
    \item Bestimmen Sie für beide Systeme die Maschinengenauigkeit:
    \begin{itemize}
        \item System 1: $eps_1 = \frac{B_1}{2}B_1^{-n_1}$ 
        \item System 2: $eps_2 = \frac{B_2}{2}B_2^{-n_2}$
    \end{itemize}
    \item Vergleichen Sie die Werte:
    \begin{itemize}
        \item Kleinere eps bedeutet höhere Genauigkeit
        \item Bei etwa gleicher eps: System mit kleinerer Basis ist genauer
    \end{itemize}
    \item Überprüfen Sie auch den Wertebereich bei Bedarf
\end{enumerate}
\end{KR}

\begin{example2}{Systemvergleich}
Vergleich zweier Systeme:
\begin{itemize}
    \item System 1: 46 Binärstellen ($B=2, n=46$)
    \item System 2: 14 Dezimalstellen ($B=10, n=14$)
\end{itemize}
\paragraph{Lösung:}
\begin{enumerate}
    \item Maschinengenauigkeit:
    \begin{itemize}
        \item System 1: $eps_1 = 2^{-46} \approx 1.4 \cdot 10^{-14}$
        \item System 2: $eps_2 = 5 \cdot 10^{-14}$
    \end{itemize}
    \item $eps_1 < eps_2$ → System 1 rechnet genauer
\end{enumerate}
\end{example2}

\begin{KR}{Fehlertypen identifizieren und vermeiden}
\begin{enumerate}
    \item Identifizieren Sie potentielle Fehlerquellen:
    \begin{itemize}
        \item Auslöschung (Subtraktion ähnlicher Zahlen)
        \item Überlauf (Zahlen > $x_{max}$)
        \item Unterlauf (Zahlen < $x_{min}$)
        \item Rundungsfehler (Abschneiden von Stellen)
    \end{itemize}
    \item Wählen Sie geeignete Gegenmaßnahmen:
    \begin{itemize}
        \item Umformen von Formeln
        \item Normalisieren von Zahlen
        \item Skalieren von Wertebereichen
        \item Vermeiden kritischer Operationen
    \end{itemize}
    \item Validieren Sie das numerische Ergebnis:
    \begin{itemize}
        \item Plausibilitätsprüfung
        \item Fehlerabschätzung
        \item Vergleich verschiedener Berechnungswege
    \end{itemize}
\end{enumerate}
\end{KR}

\begin{example2}{Komplexe Fehlerfortpflanzung}
Gegeben sei $f(x) = \ln(1+x) - \sqrt{1+x^2}$ für $x \approx 0$
\paragraph{Analyse:}
\begin{enumerate}
    \item Kritische Operationen:
    \begin{itemize}
        \item $\ln(1+x)$ für $x \approx 0$ (Auslöschung)
        \item $\sqrt{1+x^2}-1$ für $x \approx 0$ (Auslöschung)
    \end{itemize}
    \item Bessere Berechnung:
    \begin{itemize}
        \item $\ln(1+x) \approx x - \frac{x^2}{2}$ für kleine $x$
        \item $\sqrt{1+x^2}-1 = \frac{x^2}{\sqrt{1+x^2}+1}$
    \end{itemize}
    \item Umgeformte Funktion vermeidet Auslöschung
\end{enumerate}
\end{example2}

\subsection{Approximations- und Rundungsfehler}

\begin{definition}{Fehlerarten}
Sei $\tilde{x}$ eine Näherung des exakten Wertes $x$:
\vspace{1mm}\\
\begin{minipage}[t]{0.45\textwidth}
    \textbf{Absoluter Fehler:} 
    \begin{center} $\left|\tilde{x}-x\right|$ \end{center}
\end{minipage}
\hspace{3mm}
\begin{minipage}[t]{0.5\textwidth}
    \textbf{Relativer Fehler:} 
    \begin{center} $\left|\frac{\tilde{x}-x}{x}\right| \text{ bzw. } \frac{|\tilde{x}-x|}{|x|} \text{ für } x \neq 0$ \end{center}
\end{minipage}
\end{definition}

\begin{KR}{Fehlertypen unterscheiden und behandeln}
\begin{enumerate}
    \item Unterscheidung der Fehlerarten:
    \begin{itemize}
        \item Absoluter Fehler bei Größenordnung wichtig 
        \item Relativer Fehler bei Genauigkeit wichtig
        \item Bei sehr kleinen/großen Zahlen relativen Fehler verwenden
    \end{itemize}
    
    \item Behandlung kritischer Fälle:
    \begin{itemize}
        \item Overflow: Skalierung der Werte
        \item Underflow: Alternative Berechnungsformeln
        \item Auslöschung: Mathematische Umformungen
    \end{itemize}
    
    \item Praktische Prüfung:
    \begin{itemize}
        \item Plausibilitätskontrolle der Ergebnisse
        \item Verschiedene Berechnungswege vergleichen
        \item Fehlerabschätzungen durchführen
    \end{itemize}
\end{enumerate}
\end{KR}

\begin{lemma}{Maschinengenauigkeit} 
    eps ist die kleinste positive Zahl, für die gilt:
    \vspace{-3mm}\\
\begin{minipage}[b]{0.45\textwidth}
    \textbf{Allgemein:}  $\text{eps} := \frac{B}{2} \cdot B^{-n}$
\end{minipage}
\hspace{6mm}
\begin{minipage}[b]{0.45\textwidth}
    \textbf{Dezimal:}  $\text{eps}_{10} := 5 \cdot 10^{-n}$
\end{minipage}

\begin{minipage}[t]{0.6\textwidth}
    Sie begrenzt den\\ maximalen relativen Rundungsfehler:
\end{minipage}
\begin{minipage}{0.35\textwidth}
    \vspace{1mm}
    $\left|\frac{rd(x)-x}{x}\right| \leq \text{eps}$
\end{minipage}
\end{lemma}

\begin{corollary}{Rundungseigenschaften}
Für alle $x \in \mathbb{R}$ mit $|x| \geq x_{\text{min}}$ gilt:
\vspace{1mm}\\
\begin{minipage}[t]{0.45\textwidth}
    \textbf{Absoluter Fehler:}  
    \begin{center} $|rd(x) - x| \leq \frac{B}{2} \cdot B^{e-n-1}$ \end{center}
\end{minipage}
\hspace{3mm}
\begin{minipage}[t]{0.35\textwidth}
    \textbf{Relativer Fehler:}  
    \begin{center} $\left|\frac{rd(x)-x}{x}\right| \leq \text{eps}$ \end{center}
\end{minipage}
\end{corollary}

\subsubsection{Fehlerfortpflanzung}

\begin{concept}{Konditionierung}
    Die Konditionszahl $K$ beschreibt die relative Fehlervergrösserung bei Funktionsauswertungen:
    \vspace{1mm}\\
\begin{minipage}{0.3\textwidth}
    \vspace{-2mm}
    $$K := \frac{|f'(x)| \cdot |x|}{|f(x)|}$$
\end{minipage}
\hspace{2mm}
\begin{minipage}{0.6\textwidth}
\begin{itemize}
    \item $K \leq 1$: gut konditioniert
    \item $K > 1$: schlecht konditioniert
    \item $K \gg 1$: sehr schlecht konditioniert
\end{itemize}
\end{minipage}
\end{concept}

\begin{example2}{Konditionierung berechnen}
Für $f(x) = \sqrt{1+x^2}$ und $x_0 = 10^{-8}$:

\paragraph{Lösung:}
\begin{enumerate}
    \item $f'(x) = \frac{x}{\sqrt{1+x^2}}$
    \item $K = \frac{|x \cdot x|}{|\sqrt{1+x^2} \cdot (1+x^2)|} = \frac{x^2}{(1+x^2)^{3/2}}$
    \item Für $x_0 = 10^{-8}$:
    \begin{itemize}
        \item $K(10^{-8}) \approx 10^{-16}$ (gut konditioniert)
        \item Relativer Fehler wird um Faktor $10^{-16}$ verkleinert
    \end{itemize}
\end{enumerate}
\end{example2}

\begin{example2}{Wilson-Polynom}
Betrachten Sie das Wilson-Polynom:
$$P(x) = \prod_{k=1}^{20} (x-k)$$

\paragraph{Originalform:}
\begin{itemize}
    \item Nullstellen: $x_k = k$ für $k = 1,\ldots,20$
    \item Koeffizient von $x^{19}$: $-210$
\end{itemize}

\paragraph{Gestörte Form:}
\begin{itemize}
    \item Änderung des $x^{19}$-Koeffizienten um $2^{-23}$
    \item Neue Nullstellen teilweise komplex
    \item Beispiel für extreme Konditionierung
\end{itemize}

\paragraph{Konsequenz:}
\begin{itemize}
    \item Kleine Störungen → große Auswirkungen
    \item Numerisch instabil
    \item Alternative Darstellung nötig
\end{itemize}
\end{example2}

\begin{theorem}{Fehlerfortpflanzung}
Für $f$ (differenzierbar) gilt näherungsweise:
\vspace{1mm}\\
\begin{minipage}[t]{0.47\textwidth}
    \textbf{Absoluter Fehler:}  
    \vspace{-2mm}\\
    $$|f(\tilde{x})-f(x)| \approx |f'(x)| \cdot |\tilde{x}-x|$$
\end{minipage}
\hspace{3mm}
\begin{minipage}[t]{0.43\textwidth}
    \textbf{Relativer Fehler:}  
    \vspace{-2mm}\\
    $$\frac{|f(\tilde{x})-f(x)|}{|f(x)|} \approx K \cdot \frac{|\tilde{x}-x|}{|x|}$$
\end{minipage}
\end{theorem}

\begin{KR}{Analyse der Fehlerfortpflanzung einer Funktion}
\begin{enumerate}
    \item Berechnen Sie $f'(x)$
    \item Bestimmen Sie die Konditionszahl $K$
    \item Schätzen Sie den absoluten Fehler ab
    \item Schätzen Sie den relativen Fehler ab
    \item Beurteilen Sie die Konditionierung anhand von $K$
\end{enumerate}
\vspace{1mm}
$$
\begin{aligned}
\underbrace{|f(\tilde{x})-f(x)|}_{\text {absoluter Fehler von } f(x)} & \approx\left|f^{\prime}(x)\right| \cdot \underbrace{|\tilde{x}-x|}_{\text {absoluter Fehler von } x} \\
\underbrace{\frac{|f(\tilde{x})-f(x)|}{|f(x)|}}_{\text {relativer Fehler von } f(x)} & \approx \underbrace{\frac{\left|f^{\prime}(x)\right| \cdot|x|}{|f(x)|}}_{\text {Konditionszahl } K} . \quad \underbrace{\frac{|\tilde{x}-x|}{|x|}}_{\text { relativer Fehler von } x }
\end{aligned}
$$
\end{KR}

\raggedcolumns

\begin{example2}{Fehleranalyse}Beispiel: Fehleranalyse von $f(x)=\sin(x)$
\begin{enumerate}
    \item $f'(x) = \cos(x)$
    \item $K = \frac{|x\cos(x)|}{|\sin(x)|}$
    \item Für $x \to 0$: $K \to 1$ (gut konditioniert)
    \item Für $x \to \pi$: $K \to \infty$ (schlecht konditioniert)
    \item Für $x = 0$: $\lim_{x \to 0} K = 1$ (gut konditioniert)
    \item Der absolute Fehler wird nicht vergrössert, da $|\cos(x)| \leq 1$
\end{enumerate}
\end{example2}

\subsubsection{Praktische Fehlerquellen der Numerik}

\begin{concept}{Kritische Operationen} häufigste Fehlerquellen:
\begin{itemize}
    \item Auslöschung bei Subtraktion ähnlich großer Zahlen
    \item Überlauf (overflow) bei zu großen Zahlen
    \item Unterlauf (underflow) bei zu kleinen Zahlen
    \item Verlust signifikanter Stellen durch Rundung
\end{itemize}
\end{concept}

\begin{KR}{Vermeidung von Auslöschung}
\begin{enumerate}
    \item Identifizieren Sie Subtraktionen ähnlich großer Zahlen
    \item Suchen Sie nach algebraischen Umformungen
    \item Prüfen Sie alternative Berechnungswege
    \item Verwenden Sie Taylorentwicklungen für kleine Werte
\end{enumerate}

Beispiele für bessere Formeln:
    \begin{itemize}
        \item $\sqrt{1+x^2}-1 \rightarrow \frac{x^2}{\sqrt{1+x^2}+1}$
        \item $1-\cos(x) \rightarrow 2\sin^2(x/2)$
        \item $\ln(1+x) \rightarrow x-\frac{x^2}{2}$ für kleine $x$
    \end{itemize}
\end{KR}

\begin{example2}{Auslöschung} Kritische Berechnungen für kleine x (Auslöschung):
\begin{enumerate}
    \item $\sqrt{1 + x^2} - 1$: \textbf{Besser}: $\frac{x^2}{\sqrt{1 + x^2} + 1}$
    \item $1 - \cos(x)$: \textbf{Besser}: $2\sin^2(x/2)$
\end{enumerate}
\end{example2}

\begin{remark2}{Auslöschung}
    Bei der Subtraktion fast gleich großer Zahlen können signifikante Stellen verloren gehen. Beispiel:
    \begin{itemize}
        \item $1.234567 - 1.234566 = 0.000001$
        \item Aus 7 signifikanten Stellen wird 1 signifikante Stelle
    \end{itemize}
\end{remark2}


