\section{Deskriptive Statistik (mehrere Merkmale)}

\subsection{Multivariate Daten}

\begin{definition}{Multivariate Daten}
\begin{itemize}
    \item \textbf{Bivariate Daten:} Zwei Merkmale pro Merkmalsträger
    \item \textbf{Multivariate Daten:} Mehrere Merkmale pro Merkmalsträger
\end{itemize}
\end{definition}

\subsubsection{Grafische Darstellung}

\begin{concept}{Darstellungsformen nach Merkmalstypen (Bivariate Daten)}
\begin{itemize}
    \item \textbf{Zwei kategorielle Merkmale:} Kontingenztabelle + Mosaikplot
    \item \textbf{Ein kategorielles + ein metrisches Merkmal:} Boxplot oder Stripchart
    \begin{itemize}
        \item Kennwerte pro Kategorie
    \end{itemize}
    \item \textbf{Zwei metrische Merkmale:} Streudiagramm (Scatterplot)
    \begin{itemize}
        \item Punktwolke in der (x,y)-Ebene
    \end{itemize}
\end{itemize}
\end{concept}

\begin{example2}{Kontingenztabelle}
Studierende nach Studiengang und Geschlecht:
\begin{center}
\begin{tabular}{|l|c|c|c|}
\hline
 & Männlich & Weiblich & Total \\
\hline
Informatik & 120 & 30 & 150 \\
Wirtschaft & 80 & 70 & 150 \\
\hline
Total & 200 & 100 & 300 \\
\hline
\end{tabular}
\end{center}
\end{example2}

\begin{KR}{Analyse von Streudiagrammen}
\begin{enumerate}
    \item Untersuche die \textbf{Form} des Zusammenhangs:
    \begin{itemize}
        \item Linear: Punkte streuen um Gerade
        \item Gekrümmt: Punkte folgen einer Kurve
        \item Mehrere Punktwolken vorhanden?
    \end{itemize}
    \item Bestimme die \textbf{Richtung}:
    \begin{itemize}
        \item Positiv: y-Werte steigen mit x-Werten
        \item Negativ: y-Werte fallen mit x-Werten
        \item Kein Trend erkennbar
    \end{itemize}
    \item Beurteile die \textbf{Stärke}:
    \begin{itemize}
        \item Wenig Streuung: starker Zusammenhang \\(Punkte nahe an Gerade)
        \item Große Streuung: schwacher Zusammenhang
        \item Auf Ausreisser achten
    \end{itemize}
\end{enumerate}
\end{KR}

\begin{concept}{Darstellung multivariater Daten}
\begin{itemize}
    \item \textbf{Kategorielle Merkmale:}
    \begin{itemize}
        \item Mehrdimensionale Kontingenztabellen
        \item Farbliche Codierung zusätzlicher Dimensionen
    \end{itemize}
    \item \textbf{Metrische Merkmale:}
    \begin{itemize}
        \item Matrix von Streudiagrammen
        \item Korrelationsmatrix
    \end{itemize}
\end{itemize}
\end{concept}

\subsubsection{Varianz und Kovarianz}

\begin{concept}{Abkürzungen}

\begin{minipage}[t]{0.3\linewidth}
Mittelwert x-Werte:\\
$\bar{x} = \frac{1}{n}\sum_{i=1}^{n} x_i$
\end{minipage}
\begin{minipage}[t]{0.3\linewidth}
Mittelwert y-Werte:\\
$\bar{y} = \frac{1}{n}\sum_{i=1}^{n} y_i$
\end{minipage}
\begin{minipage}[t]{0.3\linewidth}
Mittelwert Produkte:\\
$\overline{xy} = \frac{1}{n}\sum_{i=1}^{n} x_i \cdot y_i$
\end{minipage}
\end{concept}

\begin{corollary}{Varianz und Kovarianz}\\
Die \textbf{Varianz} ist ein Maß für die Streuung eines Merkmals:
\vspace{-2mm}\\
$$(s_x)^2 = \overline{x^2} - \bar{x}^2, \quad (s_y)^2 = \overline{y^2} - \bar{y}^2$$

Die \textbf{Kovarianz} ist ein Maß für den linearen Zusammenhang:
\vspace{-2mm}\\
$$s_{xy} = \frac{1}{n}\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y}) = \overline{xy} - \bar{x}\bar{y}$$
\end{corollary}

\begin{KR}{Berechnung der Kovarianz}
\begin{enumerate}
    \item Methode (direkte Formel):
        \begin{itemize}
            \item Berechne Mittelwerte $\bar{x}$ und $\bar{y}$
            \item Für jedes Paar $(x_i,y_i)$: Berechne $(x_i - \bar{x})(y_i - \bar{y})$
            \item Summiere alle Produkte und teile durch $n$
        \end{itemize}
    \item Methode (schnellere Berechnung):
        \begin{itemize}
            \item Berechne $\overline{xy}$ (Mittelwert der Produkte) und $\bar{x} \cdot \bar{y}$
            \item Kovarianz = $\overline{xy} - \bar{x} \cdot \bar{y}$
        \end{itemize}
\end{enumerate}
\end{KR}

\begin{definition}{Rang}
$rg(x_i)$ des Stichprobenwertes $x_i$ ist definiert als der Index von $x_i$ in der nach der Grösse geordneten Stichprobe.
\vspace{-4mm}\\
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
$i$ & 1 & 2 & 3 & 4 & 5 & 6 \\
\hline
$x_i$ & 23 & 27 & 35 & 35 & 42 & 59 \\
\hline
$rg(x_i)$ & 1 & 2 & 3.5 & 3.5 & 5 & 6 \\
\hline
\end{tabular}
\end{center}
\end{definition}

\begin{corollary}{Rang-Varianz und Kovarianz}\\
\textbf{Varianz (Ränge) $(s_{rg(x)})^2, (s_{rg(y)})^2$}:
\vspace{-1mm}\\
$$(s_{rg(x)})^2 = \overline{rg(x)^2} - (\overline{rg(x)})^2, \quad (s_{rg(y)})^2 = \overline{rg(y)^2} - (\overline{rg(y)})^2$$

\textbf{Kovarianz (Ränge) $s_{rg(xy)}$}:
\vspace{-2mm}\\
$$s_{rg(xy)} = \overline{rg(xy)} - \overline{rg(x)} \cdot \overline{rg(y)} = \overline{rg(xy)} - \frac{(n+1)^2}{4}$$
\end{corollary}

\begin{KR}{Rangberechnung und Bindungen}
\begin{enumerate}
    \item Sortiere die Werte aufsteigend
    \item Ränge zuweisen: Kleinster Wert: Rang 1, Zweitkleinster: Rang 2, ...
    \item Bei Bindungen (gleiche Werte):
        \begin{itemize}
            \item Identifiziere gleiche Werte
            \item Berechne Durchschnittsrang: $\frac{\text{Summe der Rangplätze}}{\text{Anzahl gebundener Werte}}$
            \item Weise allen gleichen Werten diesen Rang zu
        \end{itemize}
\end{enumerate}
\end{KR}

\begin{example2}{Rangberechnung mit Bindungen}
Datenreihe: 3, 7, 7, 4, 9, 7, 2

\textbf{Schritt 1:} Sortieren:
$2, 3, 4, 7, 7, 7, 9$

\textbf{Schritt 2:} Ränge zuweisen:
\begin{itemize}
    \item 2: Rang 1
    \item 3: Rang 2
    \item 4: Rang 3
    \item 7: Durchschnittsrang $\frac{4+5+6}{3} = 5$
    \item 9: Rang 7
\end{itemize}

\textbf{Schritt 3:} Finale Rangzuordnung:
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|}
\hline
Wert & 3 & 7 & 7 & 4 & 9 & 7 & 2 \\
\hline
Rang & 2 & 5 & 5 & 3 & 7 & 5 & 1 \\
\hline
\end{tabular}
\end{center}
\end{example2}

\subsubsection{Korrelation}

\begin{corollary}{Korrelationskoeffizient nach Pearson}
normiert die Kovarianz:
$$r_{xy} = \frac{s_{xy}}{s_x \cdot s_y} = \frac{\overline{xy} - \bar{x} \cdot \bar{y}}{\sqrt{\overline{x^2} - \bar{x}^2} \cdot \sqrt{\overline{y^2} - \bar{y}^2}}$$
\vspace{-5mm}\\
Eigenschaften:
\begin{itemize}
    \item $-1 \leq r_{xy} \leq 1$
    \item $r_{xy} \approx 1$: starker positiver linearer Zusammenhang
    \item $r_{xy} \approx -1$: starker negativer linearer Zusammenhang
    \item $r_{xy} \approx 0$: kein linearer Zusammenhang
\end{itemize}
\end{corollary}


\begin{example2}{Interpretation des Korrelationskoeffizienten}\\
Verschiedene Datensätze mit jeweils 20 $(x,y)$-Paaren:

\textbf{Fall A:} $r_{xy} = 0.95 \rightarrow$ Starker positiver linearer Zusammenhang
\begin{itemize}
    \item $y$ steigt fast proportional mit $x$
    \item Nur geringe Streuung um die Regressionsgerade
\end{itemize}

\textbf{Fall B:} $r_{xy} = -0.82 \rightarrow$ Starker negativer linearer Zusammenhang
\begin{itemize}
    \item $y$ sinkt mit steigendem $x$
    \item Moderate Streuung vorhanden
\end{itemize}

\textbf{Fall C:} $r_{xy} = 0.12 \rightarrow$ Kaum linearer Zusammenhang
\begin{itemize}
    \item Starke Streuung der Punkte
    \item Möglicherweise nichtlinearer Zusammenhang
\end{itemize}
\end{example2}

\begin{corollary}{Rangkorrelationskoeffizient nach Spearman}\\
Für monotone Zusammenhänge:
$$r_{sp} = \frac{s_{rg(xy)}}{s_{rg(x)} \cdot s_{rg(y)}} = \frac{\overline{rg(xy)} - \overline{rg(x)} \cdot \overline{rg(y)}}{\sqrt{\overline{rg(x)^2} - (\overline{rg(x)})^2} \cdot \sqrt{\overline{rg(y)^2} - (\overline{rg(y)})^2}}$$
Vereinfachte Formel, sofern \emph{alle Ränge unterschiedlich} sind:
$$r_{sp} = 1 - \frac{6 \cdot \sum_{i=1}^n d_i^2}{n \cdot (n^2 - 1)}$$
mit $d_i = rg(x_i) - rg(y_i)$ (Rangdifferenzen)
\end{corollary}

\begin{KR}{Berechnung des Spearman-Korrelationskoeffizienten}
\begin{enumerate}
    \item Weise beiden Merkmalen Ränge zu:
        \begin{itemize}
            \item Sortiere x-Werte, vergebe Ränge (ebenfalls für y-Werte)
            \item Bei Bindungen: Durchschnittsränge
        \end{itemize}
    \item Falls keine Bindungen vorhanden:
        \begin{itemize}
            \item Berechne Rangdifferenzen $d_i$
            \item Quadriere Differenzen $d_i^2$ und summiere sie
            \item Verwende vereinfachte Formel für $r_{sp}$
        \end{itemize}
    \item Bei Bindungen:
        \begin{itemize}
            \item Berechne Rangmittelwerte
            \item Berechne Rangvarianzen und -kovarianz
            \item Verwende allgemeine Formel
        \end{itemize}
\end{enumerate}
\end{KR}

\begin{concept}{Unterschied Pearson und Spearman}
\begin{itemize}
    \item \textbf{Pearson:}
    \begin{itemize}
        \item Misst linearen Zusammenhang
        \item Empfindlich gegen Ausreißer
        \item Für metrische Daten
    \end{itemize}
    \item \textbf{Spearman:}
    \begin{itemize}
        \item Misst (nichtlinearen) monotonen Zusammenhang
        \item Robust gegen Ausreißer
        \item Auch für ordinale Daten
    \end{itemize}
\end{itemize}
\end{concept}

\begin{example2}{Vergleich Pearson und Spearman}\\
Gegeben seien die Wertepaare:
$(1,1), (2,4), (3,9), (4,16), (5,25)$
\vspace{2mm}\\
\textbf{Pearson-Korrelation:} $r_{xy} = 0.975$
\begin{itemize}
    \item Zeigt starken linearen Zusammenhang
\end{itemize}
\vspace{2mm}
\textbf{Spearman-Korrelation:} $r_{sp} = 1.000$
\begin{itemize}
    \item Perfekter monotoner Zusammenhang
\end{itemize}
\vspace{2mm}
\textbf{Vergleich:}
\begin{itemize}
    \item Pearson erfasst nur linearen Zusammenhang
    \item Spearman erfasst jeden monotonen Zusammenhang
    \item Hier: Quadratischer Zusammenhang
    \item Spearman robuster gegen Ausreißer
\end{itemize}
\end{example2}


\begin{example2}{Berechnung von Kovarianz und Korrelation}\\
Gegeben seien die Wertepaare:
$(1,2), (2,4), (3,5), (4,8)$
\vspace{2mm}\\
\textbf{Schritt 1:} Mittelwerte berechnen:
$$\bar{x} = \frac{1+2+3+4}{4} = 2.5, \quad \bar{y} = \frac{2+4+5+8}{4} = 4.75$$

\textbf{Schritt 2:} Kovarianz berechnen: $s_{xy} = 14.25 - 11.875 = 2.375$
$$\overline{xy} = \frac{2+8+15+32}{4} = 14.25,\quad \bar{x} \cdot \bar{y} = 2.5 \cdot 4.75 = 11.875$$

\textbf{Schritt 3:} Korrelationskoeffizient berechnen
\vspace{2mm}\\
\resizebox{\textwidth}{!}{
$s_x^2 = \frac{1+4+9+16}{4} - 2.5^2 = 1.25, \quad s_y^2 = \frac{4+16+25+64}{4} - 4.75^2 = 5.6875$}
$$r_{xy} = \frac{2.375}{\sqrt{1.25} \cdot \sqrt{5.6875}} = 0.894$$
\end{example2}

\subsubsection{Grenzen der Korrelation}

\begin{definition}{Scheinkorrelation}
Eine Korrelation zwischen zwei Merkmalen bedeutet nicht automatisch einen kausalen Zusammenhang:
\begin{itemize}
    \item Ein drittes Merkmal könnte beide beeinflussen
    \item Der Zusammenhang könnte zufällig sein
    \item Ausreißer können das Ergebnis verzerren
    \item Nichtlinearer Zusammenhang möglich
\end{itemize}
\end{definition}

\begin{KR}{Prüfung auf Scheinkorrelation}
\begin{enumerate}
    \item Betrachte die Datenpunkte im Streudiagramm:
        \begin{itemize}
            \item Gibt es Ausreißer?
            \item Ist der Zusammenhang wirklich linear?
        \end{itemize}
    \item Überlege fachlich:
        \begin{itemize}
            \item Gibt es plausible Kausalität?
            \item Könnte ein drittes Merkmal beide beeinflussen?
        \end{itemize}
    \item Prüfe Teilstichproben:
        \begin{itemize}
            \item Bleibt Korrelation in Untergruppen bestehen?
            \item Ändert sich die Stärke deutlich?
        \end{itemize}
    \item Bei Zweifeln:
        \begin{itemize}
            \item Spearman-Korrelation prüfen und weitere Merkmale einbeziehen
            \item Fachexperten konsultieren (sure, eifach Dozent frage wäred de Prüefig)
        \end{itemize}
\end{enumerate}
\end{KR}

\columnbreak




