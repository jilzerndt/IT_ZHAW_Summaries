\section{Elementare Wahrscheinlichkeitsrechnung}

\subsection{Diskrete Wahrscheinlichkeitsräume}

\begin{definition}{Ergebnisraum und Zähldichte}
Ein Zufallsexperiment ist ein Vorgang, bei dem folgende Bedingungen erfüllt sind:
\begin{itemize}
    \item Der Vorgang lässt sich unter den gleichen äußeren Bedingungen beliebig oft wiederholen
    \item Es sind mehrere sich gegenseitig ausschließende Ergebnisse möglich
    \item Das Ergebnis lässt sich nicht mit Sicherheit voraussagen, sondern ist zufallsbedingt
\end{itemize}

Der \textbf{Ergebnisraum} $\Omega$ ist die Menge aller möglichen Ergebnisse des Zufallsexperiments. 

Die \textbf{Zähldichte} $\rho: \Omega \rightarrow[0,1]$ ordnet jedem Ergebnis $\omega \in \Omega$ seine Wahrscheinlichkeit zu, wobei $\sum_{\omega \in \Omega} \rho(\omega) = 1$ gilt.
\end{definition}

\begin{definition}{Ereignisse und Wahrscheinlichkeitsraum}
Ein \textbf{Ereignis} ist eine Teilmenge des Ergebnisraums $\Omega$. Der \textbf{Ereignisraum} $2^\Omega$ ist die Menge aller möglichen Ereignisse (Potenzmenge von $\Omega$).

Das \textbf{Wahrscheinlichkeitsmaß} $P: 2^\Omega \rightarrow [0,1]$ ist definiert durch:
$$P(M) = \sum_{\omega \in M} \rho(\omega) \text{ für } M \subseteq \Omega$$

Ein \textbf{Laplace-Raum} liegt vor, wenn alle Elementarereignisse gleich wahrscheinlich sind:
$$P(M)=\frac{|M|}{|\Omega|}$$
\end{definition}

\begin{theorem}{Eigenschaften von Wahrscheinlichkeitsräumen}
Für einen diskreten Wahrscheinlichkeitsraum $(\Omega,P)$ gelten:
\begin{itemize}
    \item $(A1)$ Unmögliches Ereignis: $P(\emptyset) = 0$
    \item $(A2)$ Sicheres Ereignis: $P(\Omega) = 1$
    \item $(A3)$ Komplementäres Ereignis: $P(\Omega \setminus A) = 1 - P(A)$
    \item $(A4)$ Vereinigung: $P(A \cup B) = P(A) + P(B) - P(A \cap B)$
    \item $(A5)$ Sigma-Additivität: Für paarweise disjunkte Ereignisse gilt:\\
    $P(A_1 \cup A_2 \cup A_3 \cup ...) = P(A_1) + P(A_2) + P(A_3) + ...$
\end{itemize}
\end{theorem}

\subsection{Zufallsvariablen}

\begin{definition}{Zufallsvariablen}
Eine \textbf{Zufallsvariable} $X$ ist eine Funktion $X: \Omega \rightarrow \mathbb{R}$, die jedem Ergebnis eine reelle Zahl zuordnet.

Die \textbf{Wahrscheinlichkeitsfunktion} (PMF) ist definiert durch:
$$f(x) = P(X = x) = P(\{\omega \in \Omega : X(\omega) = x\})$$

Die \textbf{Verteilungsfunktion} (CDF) ist definiert durch:
$$F(x) = P(X \leq x) = \sum_{t \leq x} f(t)$$
\end{definition}

\begin{theorem}{Eigenschaften von PMF und CDF}
\begin{itemize}
    \item $\sum_{x \in \mathbb{R}} f(x) = 1$ und $F(x) = \sum_{t \leq x} f(t)$
    \item $\lim_{x \to \infty} F(x) = 1$ und $\lim_{x \to -\infty} F(x) = 0$
    \item Monotonie: $x \leq y \Rightarrow F(x) \leq F(y)$
    \item $P(a < X \leq b) = F(b) - F(a)$
\end{itemize}
\end{theorem}

\subsection{Kenngrössen}

\begin{definition}{Erwartungswert und Varianz}
Für eine diskrete Zufallsvariable $X$ sind definiert:

\textbf{Erwartungswert:}
$$E(X) = \sum_{x \in \mathbb{R}} x \cdot f(x)$$

\textbf{Varianz:}
$$V(X) = E((X-E(X))^2) = \sum_{x \in \mathbb{R}} (x-E(X))^2 \cdot f(x)$$

\textbf{Standardabweichung:}
$$S(X) = \sqrt{V(X)}$$
\end{definition}

\begin{theorem}{Rechenregeln für Erwartungswert und Varianz}
\begin{itemize}
    \item Linearität: $E(aX + b) = aE(X) + b$
    \item Verschiebungssatz: $V(X) = E(X^2) - (E(X))^2$
    \item Lineare Transformation: $V(aX + b) = a^2V(X)$
\end{itemize}
\end{theorem}

\subsection{Bedingte Wahrscheinlichkeit}

\begin{definition}{Bedingte Wahrscheinlichkeit}
Die \textbf{bedingte Wahrscheinlichkeit} von $B$ unter der Bedingung $A$ ist:
$$P(B|A) = \frac{P(A \cap B)}{P(A)} \quad \text{für } P(A) > 0$$
\end{definition}

\begin{theorem}{Multiplikationssatz}
$$P(A \cap B) = P(A) \cdot P(B|A) = P(B) \cdot P(A|B)$$
\end{theorem}

\begin{theorem}{Satz von der totalen Wahrscheinlichkeit}
$$P(B) = P(A) \cdot P(B|A) + P(\bar{A}) \cdot P(B|\bar{A})$$
\end{theorem}

\begin{theorem}{Satz von Bayes}
$$P(A|B) = \frac{P(A) \cdot P(B|A)}{P(B)}$$
\end{theorem}

\begin{KR}{Ereignisbäume}
1. \textbf{Aufbau}
   \begin{itemize}
   \item Von links nach rechts zeichnen
   \item Alle Verzweigungen vollständig angeben
   \item Übergangswahrscheinlichkeiten an Äste schreiben
   \end{itemize}

2. \textbf{Pfadwahrscheinlichkeiten}
   \begin{itemize}
   \item Multiplikation entlang des Pfades
   \item Für jedes Endereignis alle Pfade addieren
   \item Summe aller Pfadwahrscheinlichkeiten = 1
   \end{itemize}
\end{KR}

\subsection{Stochastische Unabhängigkeit}

\begin{definition}{Stochastische Unabhängigkeit}
Zwei Ereignisse $A$ und $B$ heißen \textbf{stochastisch unabhängig}, falls:
$$P(A \cap B) = P(A) \cdot P(B)$$

Zwei Zufallsvariablen $X$ und $Y$ heißen \textbf{stochastisch unabhängig}, falls für alle $x,y \in \mathbb{R}$:
$$P(X=x, Y=y) = P(X=x) \cdot P(Y=y)$$
\end{definition}

\begin{theorem}{Eigenschaften der stochastischen Unabhängigkeit}
Für unabhängige Ereignisse $A$ und $B$ gilt:
\begin{itemize}
    \item $A$ und $\Omega \setminus B$ sind unabhängig
    \item $\Omega \setminus A$ und $\Omega \setminus B$ sind unabhängig
    \item $P(A|B) = P(A)$ falls $P(B) > 0$
\end{itemize}

Für unabhängige Zufallsvariablen $X$ und $Y$ gilt:
\begin{itemize}
    \item $E(X \cdot Y) = E(X) \cdot E(Y)$
    \item $V(X + Y) = V(X) + V(Y)$
\end{itemize}
\end{theorem}