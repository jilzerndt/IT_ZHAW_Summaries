\section{Spezielle Verteilungen} 

\subsection{Diskrete und Stetige Zufallsvariablen}

\begin{definition}{Diskrete und Stetige Zufallsvariablen}
Bei einer \textbf{diskreten Zufallsvariable} gibt es immer Lücken zwischen den Werten; sie kann nur bestimmte Werte annehmen.

Eine \textbf{stetige Zufallsvariable} hat ein kontinuierliches Spektrum von möglichen Werten.

\textbf{Berechnung von Wahrscheinlichkeiten:}
\begin{itemize}
    \item Diskret: $P(X=x) = f(x)$ (PMF)
    \item Stetig: $P(X \leq x) = \int_{-\infty}^x f(t)dt$ (CDF)
\end{itemize}
\end{definition}

\begin{concept}{Gegenüberstellung von diskreten und stetigen Zufallsvariablen}

\textbf{Diskrete Zufallsvariable:}
\begin{itemize}
    \item Dichtefunktion: $f(x) = P(X=x)$
    \item Verteilungsfunktion: $F(x) = \sum_{x \leq X} f(x)$
    \item Wahrscheinlichkeiten: $P(a \leq X \leq b) = \sum_{a \leq x \leq b} f(x)$
    \item Erwartungswert: $E(X) = \sum_{x \in \mathbb{R}} x \cdot f(x)$
    \item Varianz: $V(X) = \sum_{x \in \mathbb{R}} (x-E(X))^2 \cdot f(x)$
\end{itemize}

\textbf{Stetige Zufallsvariable:}
\begin{itemize}
    \item Dichtefunktion: $f(x) = F'(x) \neq P(X=x)$
    \item Verteilungsfunktion: $F(x) = \int_{-\infty}^x f(t)dt$
    \item Wahrscheinlichkeiten: $P(a \leq X \leq b) = \int_a^b f(x)dx$
    \item Erwartungswert: $E(X) = \int_{-\infty}^{\infty} x \cdot f(x)dx$
    \item Varianz: $V(X) = \int_{-\infty}^{\infty} (x-E(X))^2 \cdot f(x)dx$
\end{itemize}
\end{concept}

%TODO: add missing information about Intervallwahrscheinlichkeiten

\subsection{Diskrete Verteilungen}

\begin{theorem}{Übersicht der diskreten Verteilungen}
    
1. \textbf{Hypergeometrische Verteilung:} Ziehen ohne Zurücklegen
   \begin{itemize}
   \item Endliche Grundgesamtheit, Veränderliche Wahrscheinlichkeiten
   \end{itemize}
2. \textbf{Bernoulli-Verteilung:} Genau zwei mögliche Ausgänge
   \begin{itemize}
   \item Ein einzelner Versuch, Konstante Erfolgswahrscheinlichkeit
   \end{itemize}
3. \textbf{Binomial-Verteilung:} Mehrere unabhängige Versuche (fixe Anzahl)
   \begin{itemize}
   \item Mit Zurücklegen/große Grundgesamtheit
   \item Konstante Erfolgswahrscheinlichkeit
   \end{itemize}
4. \textbf{Poisson-Verteilung:} Seltene Ereignisse
   \begin{itemize}
   \item Festes Zeitintervall/Raumbereich, Rate $\lambda$ bekannt
   \end{itemize}
\end{theorem}

\begin{KR}{Wahl der richtigen Verteilung}\\
1. \textbf{Prüfe Ziehungsart}
   \begin{itemize}
   \item Mit Zurücklegen → Binomialverteilung
   \item Ohne Zurücklegen → Hypergeometrische Verteilung
   \item Seltene Ereignisse → Poisson-Verteilung
   \end{itemize}

2. \textbf{Prüfe Grundgesamtheit}
   \begin{itemize}
   \item Endlich, klein → Hypergeometrische Verteilung
   \item Sehr groß/unendlich → Binomialverteilung
   \item Zeitlich/räumlich kontinuierlich → Poisson-Verteilung
   \end{itemize}

3. \textbf{Beachte Approximationen}
   \begin{itemize}
   \item Binomial → Poisson für $n \to \infty$, $p \to 0$, $np = \lambda$
   \item Hypergeometrisch → Binomial für $\frac{n}{N} \leq 0.05$
   \end{itemize}
\end{KR}


\begin{definition}{Hypergeometrische Verteilung}\\
Ziehen \textbf{ohne Zurücklegen} aus einer endlichen Grundgesamtheit.
\vspace{-2mm}\\
$$\text{\textbf{Wahrscheinlichkeitsfunktion: }}P(X=k) = \frac{\binom{M}{k} \cdot \binom{N-M}{n-k}}{\binom{N}{n}}$$
\vspace{-4mm}\\
\textbf{Notation:} $X \sim H(N,M,n)$

\begin{minipage}[t]{0.5\textwidth}
\textbf{Parameter:}
\begin{itemize}
    \item $N$: Grundgesamtheit
    \item $M$: Anzahl Merkmalsträger
    \item $n$: Stichprobenumfang
\end{itemize}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\textbf{Kenngrößen:}
\begin{itemize}
    \item $E(X) = n \cdot \frac{M}{N}$
    \item $V(X) = n \cdot \frac{M}{N} \cdot (1-\frac{M}{N}) \cdot \frac{N-n}{N-1}$
\end{itemize}
\end{minipage}
\end{definition}

\begin{definition}{Bernoulli-Verteilung}
Experiment mit genau zwei möglichen Ausgängen (Erfolg/Misserfolg bzw 1/0)
\vspace{-2mm}\\
$$P(X=1) = p, \quad P(X=0) = 1-p = q$$
\textbf{Notation:} $X \sim B(1,p)$

\begin{minipage}[t]{0.5\textwidth}
\textbf{Parameter:}
\begin{itemize}
    \item $p$ = Erfolgswahrscheinlichkeit
    \item $q = 1-p$ = Gegenwahrscheinlichkeit
\end{itemize}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\textbf{Kenngrößen:}
\begin{itemize}
    \item $E(X)=E(X^2)=p$
    \item $V(X)=p \cdot(1-p)=pq$
\end{itemize}
\end{minipage}
\end{definition}

\begin{remark}
Voraussetzungen für die Bernoulli-Verteilung: Genau zwei mögliche Ausgänge, unabhängige Wiederholungen, konstante Erfolgswahrscheinlichkeit.
\end{remark}


\begin{definition}{Binomialverteilung}
$n$-malige \textbf{unabhängige Wiederholung} von Bernoulli
\vspace{-2mm}\\
$$\text{\textbf{Wahrscheinlichkeitsfunktion: }}P(X=k) = \binom{n}{k} \cdot p^k \cdot q^{n-k}$$
\vspace{-4mm}\\
\textbf{Notation:} $X \sim B(n,p)$

\begin{minipage}[t]{0.6\textwidth}
\textbf{Parameter:}
\begin{itemize}
    \item $n$: Anzahl Versuche
    \item $p$: Erfolgswahrscheinlichkeit
    \item $q = 1-p$: Gegenwahrscheinlichkeit
\end{itemize}
\end{minipage}
\begin{minipage}[t]{0.35\textwidth}
\textbf{Kenngrößen:}
\begin{itemize}
    \item $E(X) = n \cdot p$
    \item $V(X) = n \cdot p \cdot q$
\end{itemize}
\end{minipage}
\end{definition}

\begin{definition}{Poissonverteilung}
Modelliert \textbf{seltene Ereignisse} in festem Intervall.
\vspace{-2mm}\\
$$\text{\textbf{Wahrscheinlichkeitsfunktion: }}P(X=k) = \frac{\lambda^k}{k!} \cdot e^{-\lambda}, \quad \lambda > 0$$
\vspace{-2mm}\\
\begin{minipage}[t]{0.6\textwidth}
\textbf{Notation:} $X \sim Poi(\lambda)$

\textbf{Parameter:}
\begin{itemize}
    \item $\lambda$: Rate/Erwartungswert pro Intervall
\end{itemize}
\end{minipage}
\begin{minipage}[t]{0.38\textwidth}
\textbf{Kenngrößen:}
\begin{itemize}
    \item $E(X) = \lambda$
    \item $V(X) = \lambda$
\end{itemize}
\end{minipage}
\end{definition}


\subsection{Stetige Verteilungen}

\begin{concept}{Erwartungswert und Varianz der Normalverteilung}\\
Für eine Zufallsvariable $X \sim N(\mu;\sigma)$ gilt:
\vspace{-2mm}\\
$$
E(X) = \mu, \quad V(X) = \sigma^2
$$
\vspace{-7mm}\\
\textbf{Parameter:}\\
$\mu$ = Erwartungswert (Lage)\\
$\sigma^2$ = Varianz, $\sigma$ = Standardabweichung (Streuung)
\end{concept}

\begin{definition}{Gauss-Verteilung/Normalverteilung}
Die stetige Zufallsvariable $X$ folgt der Normalverteilung mit den Parametern $\mu, \sigma \in \mathbb{R}, \sigma>0$:
\vspace{-2mm}\\
$$
\text{Dichtefunktion der Normalverteilung: }\varphi_{\mu,\sigma}(x)=\frac{1}{\sqrt{2\pi} \cdot \sigma} \cdot e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2}
$$
\vspace{-5mm}\\
\textbf{Notation:} $X \sim N(\mu,\sigma)$
\vspace{2mm}\\
\textcolor{blue}{Standardnormalverteilung} ($\mu=0$ und $\sigma=1$):
\vspace{-3mm}\\
$$
\text{Dichtefunktion der Standardnormalverteilung: }\varphi(x)=\frac{1}{\sqrt{2\pi}} \cdot e^{-\frac{1}{2}x^2}
$$
\vspace{-5mm}\\
\textbf{Notation:} $X \sim N(0,1)$
\end{definition}

\begin{theorem}{Eigenschaften der Normalverteilung}
    \begin{itemize}
        \item Symmetrisch bzgl. der Geraden $x$ = $\mu$, Wendepunkte bei $\mu \pm \sigma$
        \item Änderung $\mu$ schiebt in $x$-Richtung,
        je grösser $\sigma$, desto breiter/flacher
        \item \textbf{normiert}: $\int_{-\infty}^{\infty} \varphi_{\mu,\sigma}(x)dx = 1$.
    \end{itemize}
\end{theorem}

\begin{definition}{Die Verteilungsfunktion der Normalverteilung}\\
Die kumulative Verteilungsfunktion (CDF) von $\varphi_{\mu,\sigma}(x)$ wird mit $\phi_{\mu,\sigma}(x)$ bezeichnet. Sie ist definiert durch:
\vspace{-2mm}\\
$$
\phi_{\mu,\sigma}(x) = P(X \leq x) = \int_{-\infty}^x \varphi_{\mu,\sigma}(t)dt = \frac{1}{\sqrt{2\pi} \cdot \sigma} \cdot \int_{-\infty}^x e^{-\frac{1}{2}(\frac{t-\mu}{\sigma})^2} dt
$$
\end{definition}

\begin{concept}{Standardisierung der Normalverteilung} \\
Liegt eine beliebige Normalverteilung $N(\mu,\sigma)$ vor, muss standardisiert werden. Statt ursprünglichen Zufallsvariablen $X$ betrachtet man die Zufallsvariable:
\vspace{-4mm}\\
$$
U = \frac{X-\mu}{\sigma}
$$
\vspace{-2mm}\\
Diese Zufallsvariable $U$ ist standardnormalverteilt $N(0,1)$.
\end{concept}

\begin{KR}{Arbeiten mit der Normalverteilung}\\
1. \textbf{Standardisierung}
   \begin{itemize}
   \item $Z = \frac{X-\mu}{\sigma}$ transformiert zu N(0,1)
   \item Benutze Tabelle der Standardnormalverteilung
   \item Beachte: $\phi(z) = 1 - \phi(-z)$
   \end{itemize}

2. \textbf{Stetigkeitskorrektur}
   \begin{itemize}
   \item Bei Approximation diskreter Verteilungen
   \item Untere Grenze: $a - 0.5$
   \item Obere Grenze: $b + 0.5$
   \end{itemize}

3. \textbf{Faustregel für Intervalle}
   \begin{itemize}
   \item $\mu \pm \sigma$: ca. 68\% der Werte
   \item $\mu \pm 2\sigma$: ca. 95\% der Werte
   \item $\mu \pm 3\sigma$: ca. 99.7\% der Werte
   \end{itemize}
\end{KR}

\subsection{Zentraler Grenzwertsatz und Approximationen}

\begin{corollary}{Erwartungswert und Varianz für Zufallsvariablen}\\
Für $n$ unabhängige Zufallsvariablen $X_1, X_2, \ldots, X_n$ definieren wir:
$$n\text{-te Summe } S_n = X_1 + ... + X_n = \sum_{i=1}^n X_i$$
$$\text{arithmetische Mittel der Zufallsvariablen: } \bar{X}_n = \frac{S_n}{n}$$
Für diese beiden neuen Zufallsvariablen gilt:
\begin{itemize}
    \item $E(S_n) = E(X_1) + ... + E(X_n) = E(X_1 + ... + X_n)$
    \item $E(\bar{X}_n) = \frac{1}{n}(E(X_1) + ... + E(X_n)) = E(\frac{1}{n}(X_1 + ... + X_n))$
\end{itemize}
\vspace{1mm}
Sind die Zufallsvariablen paarweise stochastisch unabhängig gilt:
\begin{itemize}
    \item $V(S_n) = V(X_1) + ... + V(X_n) = V(X_1 + ... + X_n)$
    \item $V(\bar{X}_n) = \frac{1}{n^2}(V(X_1) + ... + V(X_n)) = V(\frac{1}{n}(X_1 + ... + X_n))$
\end{itemize}
\end{corollary}

\begin{theorem}{Zentraler Grenzwertsatz}\\
Für eine Folge von Zufallsvariablen $X_1, X_2, \ldots, X_n$ mit gleichem Erwartungswert $\mu$ und gleicher Varianz $\sigma^2$ gilt:
$$
E(S_n)=n \cdot \mu, \quad V(S_n)=n \cdot \sigma^2
$$
$$
E(\bar{X}_n)=\mu, \quad V(\bar{X}_n)=\frac{\sigma^2}{n}=\frac{1}{n^2} \cdot V(S_n)
$$
Die standardisierte Zufallsvariable:
$$
U_n=\frac{((X_1+X_2+\cdots+X_n)-n\mu)}{\sqrt{n} \cdot \sigma}=\frac{(\bar{X}-\mu)}{\frac{\sigma}{\sqrt{n}}}
$$

Sind die Zufallsvariablen alle identisch $N(\mu,\sigma)$ verteilt, so sind die Summe $S_n$ und das arithmetische Mittel $\bar{X}_n$ wieder normalverteilt mit:
\begin{itemize}
  \item $S_n: \quad N(n \cdot \mu, \sqrt{n} \cdot \sigma)$
  \item $\bar{X}_n: \quad N(\mu, \frac{\sigma}{\sqrt{n}})$
\end{itemize}
\vspace{3mm}
Verteilungsfunktion $F_n(u)$ konvergiert für $n \to \infty$ gegen die Verteilungsfunktion $\phi(u)$ der Standardnormalverteilung:
$$
\lim_{n\to\infty} F_n(u) = \phi(u) = \frac{1}{\sqrt{2\pi}} \cdot \int_{-\infty}^u e^{-\frac{1}{2}t^2} dt
$$
\end{theorem}



\begin{KR}{Anwendung des Zentralen Grenzwertsatzes}\\
1. \textbf{Prüfe Voraussetzungen}
   \begin{itemize}
   \item Unabhängige Zufallsvariablen
   \item Identische Verteilung
   \item Endliche Varianz
   \item Genügend große Stichprobe (n $\geq$ 30)
   \end{itemize}

2. \textbf{Berechne Parameter}
   \begin{itemize}
   \item $\mu_{S_n} = n\mu$
   \item $\sigma_{S_n} = \sqrt{n}\sigma$
   \item $\mu_{\bar{X}} = \mu$
   \item $\sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}}$
   \end{itemize}

3. \textbf{Standardisiere}
   \begin{itemize}
   \item Transformiere zu $Z = \frac{X-\mu}{\sigma}$
   \item Verwende Tabelle der Standardnormalverteilung
   \end{itemize}
\end{KR}

\subsubsection{Approximationen}

\begin{concept}{Approximation durch die Normalverteilung}
\begin{itemize}
  \item Binomialverteilung: $\quad \mu=np, \sigma^2=npq$
  \item Poissonverteilung: $\quad \mu=\lambda, \sigma^2=\lambda$
\end{itemize}
$$
P(a \leq X \leq b)=\sum_{x=a}^{b} P(X=x) \approx \phi_{\mu,\sigma}(b+\frac{1}{2})-\phi_{\mu,\sigma}(a-\frac{1}{2})
$$
$P(a \leq X \leq b)$ = Wahrscheinlichkeit dass $X$ zwischen $a$ und $b$ liegt\\
$\phi_{\mu,\sigma}$ = Verteilungsfunktion der Normalverteilung\\
$a, b$ = Untere und obere Grenze\\
\end{concept}

\begin{theorem}{Approximationsregeln}\\
\textbf{Binomialverteilung $\rightarrow$ Normalverteilung:}
\begin{itemize}
    \item Bedingung: $npq > 9$
    \item Parameter: $\mu = np$, $\sigma^2 = npq$
    \item $B(n,p) \approx N(np, \sqrt{npq})$
    \item Stetigkeitskorrektur beachten!
\end{itemize}

\textbf{Binomialverteilung $\rightarrow$ Poissonverteilung:}
\begin{itemize}
    \item Bedingung: $n \geq 50$ und $p \leq 0.1$
    \item $B(n,p) \approx Poi(np)$
\end{itemize}

\textbf{Hypergeometrisch $\rightarrow$ Binomialverteilung:}
\begin{itemize}
    \item Bedingung: $n \leq \frac{N}{20}$
    \item $H(N,M,n) \approx B(n,\frac{M}{N})$
\end{itemize}
\end{theorem}

\begin{corollary}{Faustregeln für Approximationen}
\begin{itemize}
  \item Die Approximation (Binomialverteilung) kann verwendet werden, wenn $npq > 9$
  \item Für grosses $n(n \geq 50)$ und kleines $p(p \leq 0.1)$ kann die Binomial- durch die Poisson-Verteilung approximiert werden:
  $$
  B(n,p) \approx \text{Poi}(n \cdot p)
  $$
  
  \item Eine Hypergeometrische Verteilung kann durch eine Binomialverteilung angenähert werden, wenn $n \leq \frac{N}{20}$:
  $$
  H(N,M,n) \approx B(n,\frac{M}{N})
  $$
\end{itemize}
\end{corollary}

\begin{remark}
    $H(N,M,n)$ = Hypergeometrische Verteilung\\
    $B(n,p)$ = Binomialverteilung\\
    $\text{Poi}(\lambda)$ = Poissonverteilung mit Parameter $\lambda = n \cdot p$\\
    $N$ = Grundgesamtheit\\
    $M$ = Anzahl der Erfolge in der Grundgesamtheit\\
    $n$ = Stichprobengröße
\end{remark}

\begin{KR}{Wahl der richtigen Verteilung}\\
1. \textbf{Diskrete Verteilungen:}
   \begin{itemize}
   \item Ziehen ohne Zurücklegen: Hypergeometrisch
   \item Unabhängige Versuche: Binomial
   \item Seltene Ereignisse: Poisson
   \end{itemize}

2. \textbf{Approximationen prüfen:}
   \begin{itemize}
   \item $npq > 9$: Normal-Approximation möglich
   \item $n \geq 50, p \leq 0.1$: Poisson-Approximation möglich
   \item $n \leq \frac{N}{20}$: Binomial-Approximation möglich
   \end{itemize}

3. \textbf{Stetigkeitskorrektur:}
   \begin{itemize}
   \item Bei Normal-Approximation: $\pm 0.5$ an den Grenzen
   \item $P(X \leq k) \approx P(X \leq k + 0.5)$
   \item $P(X = k) \approx P(k - 0.5 \leq X \leq k + 0.5)$
   \end{itemize}
\end{KR}

\begin{KR}{Entscheidung über Approximationen}\\
1. \textbf{Prüfe Stichprobenumfang}
   \begin{itemize}
   \item Klein (n < 30): Exakte Verteilung
   \item Mittel (30 $\leq$ n < 50): Je nach p
   \item Groß (n $\geq$ 50): Approximation möglich
   \end{itemize}

2. \textbf{Prüfe Wahrscheinlichkeit}
   \begin{itemize}
   \item p $\leq$ 0.1: Poisson möglich
   \item 0.1 < p < 0.9: Normal möglich
   \item npq > 9: Normal empfohlen
   \end{itemize}

3. \textbf{Wähle Approximation}
   \begin{itemize}
   \item Binomial → Normal: Große Stichproben, mittleres p
   \item Binomial → Poisson: Große n, kleines p
   \item Hypergeometrisch → Binomial: Kleine Stichprobe relativ zur Grundgesamtheit
   \end{itemize}

4. \textbf{Beachte}
   \begin{itemize}
   \item Stetigkeitskorrektur bei Normal
   \item Rundungsregeln bei Grenzen
   \item Vergleich mit exakter Lösung wenn möglich
   \end{itemize}
\end{KR}

\begin{example2}{Approximation der Binomialverteilung}\\
\textbf{Aufgabe:} Eine Produktionsanlage produziert mit Ausschusswahrscheinlichkeit 5\%. In einer Charge von 200 Teilen:
\begin{itemize}
\item Wie groß ist die Wahrscheinlichkeit für 15 oder mehr defekte Teile?
\end{itemize}

\textbf{Lösung:}
\begin{enumerate}
\item \textbf{Prüfung Approximationsbedingung:}
   \begin{itemize}
   \item $npq = 200 \cdot 0.05 \cdot 0.95 = 9.5 > 9$
   \item Normalapproximation ist zulässig
   \end{itemize}

\item \textbf{Parameter der Normalverteilung:}
   \begin{itemize}
   \item $\mu = np = 200 \cdot 0.05 = 10$
   \item $\sigma = \sqrt{npq} = \sqrt{9.5} \approx 3.08$
   \end{itemize}

\item \textbf{Berechnung mit Stetigkeitskorrektur:}
   \begin{align*}
   P(X \geq 15) &= 1 - P(X \leq 14) \\
   &= 1 - P(X \leq 14.5) \\
   &= 1 - \phi(\frac{14.5-10}{3.08}) \\
   &= 1 - \phi(1.46) \\
   &\approx 0.0721
   \end{align*}
\end{enumerate}
\end{example2}

\begin{example2}{Approximation durch Poissonverteilung}\\
\textbf{Aufgabe:} Ein seltener Gendefekt tritt mit Wahrscheinlichkeit p = 0.001 auf. In einer Gruppe von 2000 Menschen:
\begin{itemize}
\item Wie groß ist die Wahrscheinlichkeit für genau 3 Betroffene?
\end{itemize}

\textbf{Lösung:}
\begin{enumerate}
\item \textbf{Prüfung Approximationsbedingung:}
   \begin{itemize}
   \item $n = 2000 \geq 50$ und $p = 0.001 \leq 0.1$
   \item Poissonapproximation ist zulässig
   \end{itemize}

\item \textbf{Parameter:}
   \begin{itemize}
   \item $\lambda = np = 2000 \cdot 0.001 = 2$
   \end{itemize}

\item \textbf{Berechnung:}
   $$P(X = 3) = \frac{2^3}{3!} \cdot e^{-2} \approx 0.180$$

\item \textbf{Vergleich mit Binomialverteilung:}
   $$P_{Bin}(X = 3) = \binom{2000}{3} \cdot 0.001^3 \cdot 0.999^{1997} \approx 0.180$$
\end{enumerate}
\end{example2}

