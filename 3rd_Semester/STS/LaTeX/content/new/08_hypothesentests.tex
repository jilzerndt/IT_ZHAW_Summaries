\section{Schliessende Statistik -- Hypothesentests}

\subsection{Einführung}

\begin{concept}{Problemstellung}\\
Ein statistisches Verfahren zur Überprüfung einer Behauptung bzw. Hypothese auf Basis einer Stichprobe.

Die zentrale Frage lautet: Ist es plausibel, die in der Stichprobe beobachteten Abweichungen von der Behauptung als zufällig zu betrachten? Liegen sie 'im Rahmen'?

Typische Anwendungen:
\begin{itemize}
  \item Überprüfung von Herstellerangaben (z.B. mittlerer Benzinverbrauch)
  \item Vergleich von Verfahren oder Methoden
  \item Qualitätskontrolle
  \item Wirksamkeitsanalysen
\end{itemize}
\end{concept}

\subsection{Vorgehen bei einem Hypothesentest}

\begin{KR}{Ablauf eines Hypothesentests}\\
1. Nullhypothese $H_0$ formulieren:
   \begin{itemize}
     \item Zu überprüfende Behauptung
     \item Im Zweifelsfall wird $H_0$ bevorzugt ("Im Zweifel für den Angeklagten")
   \end{itemize}

2. Alternativhypothese $H_A$ formulieren:
   \begin{itemize}
     \item Einseitig: $\mu > \mu_0$ oder $\mu < \mu_0$
     \item Zweiseitig: $\mu \neq \mu_0$
   \end{itemize}

3. Testvariable definieren:
   \begin{itemize}
     \item Standardisierte Form wählen
     \item Passende Zeile aus Tabelle wählen
   \end{itemize}

4. Wahrscheinlichkeitsverteilung bestimmen:
   \begin{itemize}
     \item Normalverteilung, t-Verteilung oder $\chi^2$-Verteilung
     \item Freiheitsgrade beachten
   \end{itemize}

5. Signifikanzniveau $\alpha$ festlegen:
   \begin{itemize}
     \item Üblich: $\alpha = 5\%$ oder $1\%$
   \end{itemize}

6. Kritische Grenzen bestimmen:
   \begin{itemize}
     \item Einseitig: ein Wert $c$
     \item Zweiseitig: zwei Werte $c_u$ und $c_o$
   \end{itemize}

7. Testwert berechnen:
   \begin{itemize}
     \item Stichprobenwerte einsetzen
     \item Standardisierung durchführen
   \end{itemize}

8. Testentscheidung treffen:
   \begin{itemize}
     \item Im Annahmebereich: $H_0$ wird angenommen
     \item Im kritischen Bereich: $H_0$ wird abgelehnt
   \end{itemize}
\end{KR}

\begin{theorem}{Übersicht über verschiedene Parametertests}\\
\begin{center}
\begin{tabular}{|l|l|l|l|}
\hline
Fall & Verteilung & Testvariable & Verteilung unter $H_0$ \\
\hline
$\mu=\mu_0$ & Normal & $U=\frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}}$ & Standard- \\
$\sigma^2$ bekannt & & & normalverteilung \\
\hline
$\mu=\mu_0$ & Normal & $T=\frac{\bar{X}-\mu_0}{S/\sqrt{n}}$ & t-Verteilung \\
$\sigma^2$ unbekannt & & & $f=n-1$ \\
\hline
$\sigma^2=\sigma_0^2$ & Normal & $Z=\frac{(n-1)S^2}{\sigma_0^2}$ & $\chi^2$-Verteilung \\
& & & $f=n-1$ \\
\hline
$p=p_0$ & Bernoulli & $U=\frac{\bar{X}-p_0}{\sqrt{p_0(1-p_0)/n}}$ & Standard- \\
& & & normalverteilung \\
\hline
\end{tabular}
\end{center}
\end{theorem}

\subsection{Hypothesentests für die Gleichheit der unbekannten Mittelwerte}

\begin{definition}{Abhängige Stichproben}\\
Zwei Stichproben heissen voneinander abhängig, wenn:
\begin{itemize}
  \item Die Stichproben den gleichen Umfang haben
  \item Jedem Wert der einen Stichprobe genau ein Wert der anderen Stichprobe entspricht und umgekehrt
\end{itemize}

Beispiele:
\begin{itemize}
  \item Vorher-Nachher-Messungen
  \item Paarweise Vergleiche
  \item Messungen am gleichen Objekt
\end{itemize}
\end{definition}

\begin{concept}{Testverfahren für zwei Stichproben}\\
1. Abhängige Stichproben:
   \begin{itemize}
     \item Differenzen bilden: $D_i = X_i - Y_i$
     \item Test auf Mittelwert der Differenzen
     \item t-Test für eine Stichprobe
   \end{itemize}

2. Unabhängige Stichproben:
   \begin{itemize}
     \item Beide Stichproben separat betrachten
     \item Varianzen gleich oder verschieden?
     \item Zweistichproben-t-Test
   \end{itemize}
\end{concept}

\subsection{Mögliche Fehlerquellen}

\begin{concept}{Fehlerarten}\\
\begin{center}
\begin{tabular}{|l|c|c|}
\hline
& $H_0$ annehmen & $H_0$ ablehnen \\
\hline
$H_0$ wahr & Richtige & Fehler 1. Art \\
& Entscheidung & ($\alpha$) \\
\hline
$H_0$ falsch & Fehler 2. Art & Richtige \\
& ($\beta$) & Entscheidung \\
\hline
\end{tabular}
\end{center}

Fehler 1. Art (Produzentenrisiko):
\begin{itemize}
  \item $H_0$ wird abgelehnt, obwohl sie wahr ist
  \item Wahrscheinlichkeit = $\alpha$ (Signifikanzniveau)
\end{itemize}

Fehler 2. Art (Konsumentenrisiko):
\begin{itemize}
  \item $H_0$ wird angenommen, obwohl sie falsch ist
  \item Wahrscheinlichkeit = $\beta$ (abhängig vom wahren Wert)
\end{itemize}

Zusammenhang:
\begin{itemize}
  \item Verkleinerung von $\alpha$ führt zu Vergrößerung von $\beta$
  \item Teststärke $1-\beta$ gibt Wahrscheinlichkeit für richtige Ablehnung an
\end{itemize}
\end{concept}

\subsection{Allgemeine Bemerkungen}

\begin{concept}{p-Wert}\\
Der p-Wert ist die Wahrscheinlichkeit, einen mindestens so extremen Testwert zu erhalten wenn $H_0$ wahr ist.

Interpretation:
\begin{itemize}
  \item $p \geq \alpha$: $H_0$ wird angenommen
  \item $p < \alpha$: $H_0$ wird abgelehnt
  \item Je kleiner p, desto stärker die Evidenz gegen $H_0$
\end{itemize}
\end{concept}

\begin{KR}{Wichtige Hinweise für Hypothesentests}\\
1. "Signifikant" heißt "nicht zufallsbedingt":
   \begin{itemize}
     \item Signifikante Unterschiede müssen nicht relevant sein
     \item Bei großen Stichproben können kleine Unterschiede signifikant sein
   \end{itemize}

2. Hypothesentests erklären keine Unterschiede:
   \begin{itemize}
     \item Nur Feststellung der Signifikanz
     \item Keine Erklärung der Ursachen
     \item Keine Kontrolle des Studiendesigns
   \end{itemize}

3. Zufallsstichproben sind essentiell:
   \begin{itemize}
     \item Repräsentativität wichtig
     \item "Praktische" Stichproben können verzerren
   \end{itemize}

4. Vergleich zu Vertrauensintervallen:
   \begin{itemize}
     \item Tests: Ausgangspunkt ist behaupteter Wert
     \item Intervalle: Ausgangspunkt ist Schätzwert
   \end{itemize}
\end{KR}