\section{Scheduling}

\subsection{Scheduling Fundamentals}

\begin{definition}{Scheduling Problem Domain}\\
    Scheduling is a resource-time management activity:
    \begin{itemize}
        \item Focuses on managing CPU time allocation among processes
        \item Requirements vary by platform (mobile vs. supercomputer)
        \item Requirements vary by application type (batch processing vs. real-time)
    \end{itemize}
    
    Processes can be categorized by behavior:
    \begin{itemize}
        \item \textbf{CPU-bound}: Computationally intensive tasks (e.g., image processing)
        \item \textbf{I/O-bound}: Tasks that frequently wait for I/O operations (e.g., interactive applications)
    \end{itemize}
\end{definition}

\begin{definition}{Queueing Theory}\\
    Scheduling is based on queueing theory principles:
    \begin{itemize}
        \item Deals with waiting for and dispatching resources
        \item Aims to provide sufficient resources to avoid under-capacity
        \item Ensures urgent tasks are not kept waiting
    \end{itemize}
\end{definition}

\begin{definition}{Scheduling Queues}\\
    The scheduler manages several types of queues:
    \begin{itemize}
        \item \textbf{Ready queue}: Processes waiting to be executed
        \item \textbf{Device queues}: Processes waiting for specific devices
        \item \textbf{Job queue}: All processes in the system
    \end{itemize}
    
    The scheduler sorts the ready queue according to policy, and the dispatcher moves the process from the head of the queue to the CPU.
\end{definition}

\begin{definition}{Scheduling Metrics}\\
    Scheduling policies can be evaluated using various metrics:
    \begin{itemize}
        \item \textbf{CPU utilization}: Keeping the CPU as busy as possible
        \item \textbf{Throughput}: Number of processes completed per time unit
        \item \textbf{Turnaround time}: Time from submission to completion
        \item \textbf{Waiting time}: Time spent in the ready queue
        \item \textbf{Response time}: Time from request to first response
        \item \textbf{Fairness}: Equal distribution of CPU time
    \end{itemize}
\end{definition}

\begin{definition}{When to Schedule}\\
    Scheduling decisions are made in several situations:
    \begin{itemize}
        \item When a new process is created
        \item When a process exits
        \item When a process blocks on I/O
        \item When an I/O interrupt occurs
        \item Regularly on a timer
    \end{itemize}
    
    Based on when scheduling occurs, schedulers can be:
    \begin{itemize}
        \item \textbf{Non-preemptive}: Only schedules when a process blocks or terminates
        \item \textbf{Preemptive}: Can interrupt a running process and schedule another
    \end{itemize}
\end{definition}

\subsection{Scheduling Algorithms}

\begin{definition}{Simple Schedulers}\\
    Simple scheduling approaches:
    \begin{itemize}
        \item \textbf{Uniprocessing}: One machine, one task - no scheduler required
        \item \textbf{Multiprocessing}: Single task running at one time with job control
        \item \textbf{Multitasking}: Multiple tasks running with scheduler
    \end{itemize}
\end{definition}

\begin{definition}{First-In-First-Out (FIFO) / First-Come-First-Served (FCFS)}\\
    FIFO is a basic scheduling algorithm:
    \begin{itemize}
        \item Processes are executed in the order they arrive
        \item Single queue, no preemption
        \item Processes run to completion
        \item Simple to implement
        \item Non-preemptive
        \item No awareness of process type (interactive vs. batch)
    \end{itemize}
\end{definition}

\begin{definition}{Round Robin (RR)}\\
    Round Robin is a time-sharing algorithm:
    \begin{itemize}
        \item Each process runs for a fixed time slice (quantum)
        \item After quantum expires, process is moved to the end of the queue
        \item Preemptive, as running tasks are interrupted after quantum
        \item Arriving tasks have priority over adjourned tasks (by convention)
        \item No starvation, as all processes eventually get CPU time
        \item Performance depends on quantum size
            \begin{itemize}
                \item Too large: approaches FIFO
                \item Too small: too much context switching overhead
            \end{itemize}
    \end{itemize}
\end{definition}

\begin{definition}{Multi-level Scheduling}\\
    Multi-level schedulers address priority needs:
    \begin{itemize}
        \item Multiple queues with different priorities
        \item Round Robin within each queue
        \item Challenge: High-priority tasks can cause starvation of low-priority tasks
    \end{itemize}
\end{definition}

\begin{definition}{Multi-level Feedback Queue}\\
    Addresses starvation in multi-level queues:
    \begin{itemize}
        \item Task priority sinks after each execution interval
        \item Low-priority queues may get larger time quantum
        \item Balances responsiveness with throughput
    \end{itemize}
\end{definition}

\begin{definition}{Fair Share Scheduling}\\
    Fair Share approaches aim for equal CPU time:
    \begin{itemize}
        \item Maintains a running clock of CPU time used per process
        \item Uses a Virtual Clock (VC) to track usage
        \item Ensures average run-time is roughly equal for all tasks
        \item Better balance between CPU-bound and I/O-bound tasks
    \end{itemize}
\end{definition}

\subsection{Real-Time Schedulers}

\begin{definition}{Real-Time Systems}\\
    Real-time systems have specific scheduling needs:
    \begin{itemize}
        \item Need responsiveness to I/O
        \item Must fulfill deadlines (hard or soft)
        \item Hard deadlines MUST be met, soft deadlines can occasionally be missed
        \item Deadlines may be in milliseconds, seconds, or hours
    \end{itemize}
    
    A Real-Time Operating System (RTOS):
    \begin{itemize}
        \item Completes system calls in deterministic time
        \item Schedules user tasks to meet deadlines
        \item Facilitates hard real-time requirements
    \end{itemize}
\end{definition}

\begin{definition}{Rate Monotonic Scheduling}\\
    A static-priority scheduling algorithm for real-time systems:
    \begin{itemize}
        \item Assigns higher priority to tasks with higher repetition rates
        \item Guaranteed schedule if utilization meets criteria:
            \begin{itemize}
                \item $U = \sum_{i=1}^{n} \frac{C_e}{T_r} \leq n(2^{1/n} - 1)$
                \item Where $C_e$ is execution time and $T_r$ is period
            \end{itemize}
        \item Maximum guaranteed utilization converges to ~69\%
        \item Schedule determined at compile-time, not run-time
    \end{itemize}
\end{definition}

\begin{definition}{Earliest Deadline First (EDF)}\\
    A dynamic scheduling algorithm for real-time systems:
    \begin{itemize}
        \item Scheduler determines the task with the next deadline
        \item Task with the earliest deadline gets highest priority
        \item Schedule is achievable if utilization does not exceed 100\%
        \item Can achieve full CPU utilization
        \item Schedule determined at run-time, not compile-time
    \end{itemize}
\end{definition}

\subsection{Linux Scheduling}

\begin{definition}{Linux Scheduling Policies}\\
    Linux supports two general scheduling policies:
    \begin{itemize}
        \item \textbf{Real-Time Policy}: For time-critical tasks
            \begin{itemize}
                \item SCHED\_DEADLINE: Earliest Deadline First + Constant Bandwidth Server
                \item SCHED\_FIFO: First-In-First-Out real-time scheduling
                \item SCHED\_RR: Round Robin real-time scheduling
            \end{itemize}
        \item \textbf{Normal Policy}: For regular tasks
            \begin{itemize}
                \item SCHED\_OTHER: Default Linux scheduling policy (Completely Fair Scheduler)
                \item SCHED\_BATCH: For batch processing tasks
                \item SCHED\_IDLE: For extremely low priority background tasks
            \end{itemize}
    \end{itemize}
\end{definition}

\begin{definition}{Linux Priority System}\\
    Linux priority representation varies between kernel and user space:
    \begin{itemize}
        \item \textbf{Kernel space}: Priorities from high to low
            \begin{itemize}
                \item RT: 0-99
                \item Normal: 100-139
            \end{itemize}
        \item \textbf{User space}: "nice" values from -20 (high) to +19 (low)
            \begin{itemize}
                \item Maps to kernel priorities: nice + 20 = kernel priority - 100
                \item Not used in RT policies
            \end{itemize}
    \end{itemize}
\end{definition}

\begin{definition}{SCHED\_DEADLINE}\\
    Highest priority scheduler in Linux:
    \begin{itemize}
        \item Implements Earliest Deadline First + Constant Bandwidth Server
        \item Takes parameters: runtime, period, and deadline
        \item Tasks scheduled with SCHED\_DEADLINE cannot fork
        \item Tasks may yield CPU time when not needed
    \end{itemize}
\end{definition}

\begin{definition}{SCHED\_FIFO}\\
    First-In-First-Out real-time scheduler:
    \begin{itemize}
        \item Uses one queue per priority level (1-99)
        \item Higher priority than SCHED\_RR at same priority level
        \item Immediately preempts any Normal policy thread
        \item Runs to completion unless:
            \begin{itemize}
                \item Preempted by a higher priority RT thread
                \item Blocked by I/O call
                \item Voluntarily yields the CPU
            \end{itemize}
    \end{itemize}
\end{definition}

\begin{definition}{SCHED\_RR}\\
    Round Robin real-time scheduler:
    \begin{itemize}
        \item Similar to SCHED\_FIFO but with time quanta
        \item When quantum expires, thread moved to end of its priority queue
        \item Quantum size configurable (default 100ms)
        \item RT bandwidth limiting prevents RT tasks from monopolizing CPU
    \end{itemize}
\end{definition}

\begin{definition}{Completely Fair Scheduler (CFS)}\\
    Default scheduler in Linux (SCHED\_OTHER):
    \begin{itemize}
        \item Uses a red-black tree sorted by execution time (O(log N) operations)
        \item Tracks virtual runtime to achieve fairness
        \item Considers "nice" values to adjust CPU share
        \item Tasks can be grouped and scheduled together
        \item Aims to model an "ideal, precise multi-tasking CPU"
        \item Time accounting managed according to configurable granularity
    \end{itemize}
\end{definition}

\begin{definition}{SCHED\_BATCH and SCHED\_IDLE}\\
    Low-priority schedulers:
    \begin{itemize}
        \item \textbf{SCHED\_BATCH}:
            \begin{itemize}
                \item Same static priority as SCHED\_OTHER
                \item Designed for batch-type, CPU-intensive tasks
                \item Applies penalty due to CPU usage
                \item SCHED\_OTHER has precedence over SCHED\_BATCH at same nice value
            \end{itemize}
        \item \textbf{SCHED\_IDLE}:
            \begin{itemize}
                \item Extremely low priority
                \item Lower than static priority 0 and nice 19
                \item Used for background tasks that should only run when system is idle
            \end{itemize}
    \end{itemize}
\end{definition}

\subsection{Multi-core Scheduling}

\begin{definition}{Load Balancing}\\
    On multicore systems, Linux implements load balancing:
    \begin{itemize}
        \item Dynamic distribution of tasks across CPU cores
        \item Applied based on scheduling policy
        \item Balances competing concerns:
            \begin{itemize}
                \item Moving tasks incurs management overhead
                \item Moving tasks incurs cache penalty (lost cache advantage)
            \end{itemize}
    \end{itemize}
\end{definition}

\begin{definition}{Cache Affinity}\\
    Cache affinity affects scheduling decisions:
    \begin{itemize}
        \item Task data may remain in CPU cache after context switch
        \item Rerunning on the same core avoids cache misses
        \item Linux considers estimated cache live-time when migrating tasks
        \item Default cache live-time: /proc/sys/kernel/sched\_migration\_cost\_ns
    \end{itemize}
\end{definition}

\begin{KR}{Analyzing Scheduling in Linux}\\
    \paragraph{Viewing scheduler information}
    \begin{itemize}
        \item Check process priorities: \texttt{ps -el} (PRI and NI columns)
        \item View real-time processes: \texttt{ps -eo pid,cls,pri,rtprio,nice,cmd | grep -E 'CLS|FIFO|RR'}
        \item Check scheduler statistics: \texttt{cat /proc/schedstat}
        \item See current I/O scheduler: \texttt{cat /sys/block/sda/queue/scheduler}
    \end{itemize}
    
    \paragraph{Modifying process priorities}
    \begin{itemize}
        \item Start process with nice value: \texttt{nice -n [value] command}
        \item Change nice value: \texttt{renice [value] -p [pid]}
        \item Set real-time priority: \texttt{chrt -f [priority] command} (SCHED\_FIFO)
        \item Set round-robin priority: \texttt{chrt -r [priority] command} (SCHED\_RR)
    \end{itemize}
    
    \paragraph{Analyzing schedule}
    \begin{itemize}
        \item Trace scheduling events: \texttt{trace-cmd record -e sched}
        \item View trace results: \texttt{trace-cmd report}
        \item Check CPU affinity: \texttt{taskset -p [pid]}
        \item Set CPU affinity: \texttt{taskset -c [cpu\_list] -p [pid]}
    \end{itemize}
\end{KR}

\begin{example2}{FIFO and RR Scheduling Comparison}\\
    Given the following task list:
    
    \begin{tabular}{|c|c|c|}
        \hline
        Task & Arrival Time & Burst Time \\
        \hline
        T1 & 0 & 10 \\
        T2 & 3 & 6 \\
        T3 & 7 & 1 \\
        T4 & 8 & 3 \\
        \hline
    \end{tabular}
    
    \tcblower
    
    \textbf{FIFO Schedule}:
    
    T1 runs from 0-10, T2 runs from 10-16, T3 runs from 16-17, T4 runs from 17-20
    
    \textbf{Round Robin Schedule} (quantum = 2):
    
    T1(0-2), T1(2-4), T2(4-6), T1(6-8), T2(8-10), T3(10-11), T4(11-13), T1(13-15), T2(15-17), T1(17-19), T1(19-20)
    
    RR provides better response time but potentially longer turnaround time due to context switches.
\end{example2}

\begin{example2}{Rate Monotonic Scheduling}\\
    Given tasks with the following characteristics:
    
    \begin{tabular}{|c|c|c|}
        \hline
        Task & WCET (C) & Period (T) \\
        \hline
        T1 & 10 & 20 \\
        T2 & 10 & 50 \\
        T3 & 5 & 30 \\
        \hline
    \end{tabular}
    
    \tcblower
    
    \textbf{Analysis}:
    
    1. T1 has the highest priority (shortest period)
    2. Utilization: $U = \frac{10}{20} + \frac{10}{50} + \frac{5}{30} = 0.5 + 0.2 + 0.167 = 0.867$
    3. Maximum utilization for 3 tasks: $3(2^{1/3} - 1) \approx 0.779$
    4. Since $0.867 > 0.779$, there is no guaranteed schedule
    
    However, a feasible schedule might still exist. Testing would be required to confirm.
\end{example2}