\section{Data Preprocessing}

\begin{remark}
    Learning Objectives:
    \begin{itemize}
        \item Understand fundamental importance of data preprocessing
        \item Know basic algorithms for data cleaning, (near) duplicate detection and filling missing values
    \end{itemize}
\end{remark}

\subsection{Data-Driven Projects}

\mult{2}

\begin{concept}{Typical Data Driven Project}\\
    \includegraphics[width=\linewidth]{typical_data_driven_project.png}
\end{concept}

\subsection{Data Types}

\begin{theorem}{Data Types}\\
    \includegraphics[width=\linewidth]{data_types.png}
\end{theorem}

\begin{concept}{Overview Data Types}

    \textbf{Categorical Data}
    \begin{itemize}
        \item Nominal: no order, Scale (''labels'') $\rightarrow$ e.g. hair colour, gender
        \item Ordinal: ordered $\rightarrow$ e.g. military rank, star rating
    \end{itemize}

    \textbf{Numerical Data} (ordered)
    \begin{itemize}
        \item Discrete: countable, ratio $\rightarrow$ e.g. number of persons in a room
        \item Continuous: interval, numeric scale $\rightarrow$ e.g. temperature, weight
    \end{itemize}
\end{concept}

\begin{definition}{Data} has many sources, e.g.: 
    sensor, survey, simulation, social media, textual, financial, multimedia, ERP systems data, etc.
    
    Independent of the data source, each data point has a data type
\end{definition}

\begin{corollary}{Nominal Data}
    \begin{itemize}
        \item Nominal scales are used for \textbf{labelling} variables, without any quantitative value
        \item No numerical significance
        \item Nominal data has no order
        \item Scales could simply be called labels
        \item Examples: gender, hair colour, race, marital status
    \end{itemize}
\end{corollary}

\begin{corollary}{Ordinal Data}
    \begin{itemize}
        \item Represents \textbf{discrete and ordered} units
        \item Nearly the same as nominal data, but \textbf{order matters}
        \item No distance between the different categories
        \item Examples: military rank, star rating, education level
    \end{itemize}
\end{corollary}

\begin{corollary}{Discrete Numeric Data}
    \begin{itemize}
        \item Represents items that can be \textbf{counted}
        \item Values may go from 0, 1, 2, on to infinity (making it countably infinite)
        \item Examples: number of persons in a room, number of ''heads'' in 60 coin flips, time elapsed in minutes
    \end{itemize}
\end{corollary}

\begin{corollary}{Continuous Numeric Data}
    \begin{itemize}
        \item Also known as \textbf{interval data}
        \item Often measurements
        \item Possible values \textbf{cannot be counted} and can only be described using intervals on the real number line
        \item Examples: temperature, weight, height, time, ...
    \end{itemize}
\end{corollary}

\multend

\raggedcolumns
\columnbreak

\subsection{Data Quality}

\begin{formula}{Standard Error Measure}
    $$
    \begin{gathered}
    E=\frac{1}{N} \sum_{i=1}^N\left(1-\text { id }\left(\hat{y}_i, y_i\right)\right), \quad \text { id }(a, b)= \begin{cases}1 & \text { if } a=b \\
    0 & \text { else }\end{cases} \\
    \text { data } a_{\text {size }}=9, \quad \text { correct }=6, \quad \text { wrong }=3 \\
    E=\frac{1}{9} \cdot 3=0.33
    \end{gathered}
    $$
\end{formula}

\subsection{Data Cleaning}



\begin{definition}{Data Cleaning}\\
    is the process of improving the data quality by removing or improving incorrect or improperly formatted data.
    \vspace{1mm}\\
    \textbf{(near) duplicate detection} is the process of identifying and removing or merging duplicate data points.
    \begin{itemize}
        \item compare attributes of the tuple
        \item compare content of the attributes
    \end{itemize}
    \vspace{1mm}
    \textbf{Filling missing values} is the process of replacing missing values with substituted values.
    \begin{itemize}
        \item ignore tuple
        \item fill in missing value manually
        \item use global constant such as ''unknown'' or ''-1''
        \item use attribute mean, median, mode
        \item use most probable value
    \end{itemize}
    \vspace{1mm}
    \textbf{Noisy data} is data with errors or outliers.
    \begin{itemize}
        \item Binning: divide the range of attribute values into bins
        \item Regression: smooth data by fitting the data into a function
        \item Clustering: detect and remove outliers
    \end{itemize}
\end{definition}

\subsection{Data Binning}

\mult{2}

\begin{formula}{Equal Width Binning}
    Divide the range into $N$ intervals of equal size (= width)
    $$width = \frac{max - min}{N}$$
    $$bin_i = [min + i \cdot width, min + (i+1) \cdot width]$$
    \includegraphics[width=\linewidth]{equal_width_ninning.png}
\end{formula}

\begin{formula}{Equal Depth/Frequency Binning}\\
    Divide the range into $N$ intervals with equal number of data points/records (= depth/frequency)
    $$depth = \frac{N}{n}$$
    $$bin_i = [data_{(i-1) \cdot depth}, data_{i \cdot depth}]$$
    \includegraphics[width=\linewidth]{equal_depth_binning.png}
\end{formula}

\multend

\subsection{Data Normalization}

\begin{definition}{Data Normalization}
    is the process of transforming values of several variables into a similar range.
    $$\text{Min-Max Normalization: } x_{norm} = \frac{x - min(x)}{max(x) - min(x)}$$
    $$\text{Z-Score Normalization: } x_{norm} = \frac{x - \bar{x}}{\sigma}$$
    Change the values of numeric columns to a common scale (e.g., between 0 and 1), without distorting differences in the ranges of values.
    $$\text{Linear Normalization: } f_{lin}(v) = \frac{v - min}{max - min}$$
    $$\text{Square Root Normalization: } f_{sq}(v) = \frac{\sqrt{v} - \sqrt{min}}{\sqrt{max} - \sqrt{min}}$$
    $$\text{Logarithmic Normalization: } f_{ln}(v) = \frac{\ln(v) - \ln(min)}{\ln(max) - \ln(min)}$$

    \includegraphics[width=\linewidth]{data_normalization1.png}

    \includegraphics[width=\linewidth]{data_normalization2.png}
\end{definition}

\subsection{Data Sampling}

\begin{definition}{Data Sampling}
    Represent large dataset by smaller subset to speed up automatic calculations.
    \vspace{1mm}\\
    \textbf{Non-Probabilistic}
    \begin{itemize}
        \item Convenience: easiest to obtain
        \item Judgement: based on experts' knowledge and judgement
        \item Snowball: purely based on referrals
        \item Quota: based on attribute values
    \end{itemize}
    \vspace{1mm}
    \textbf{Probabilistic}
    \begin{itemize}
        \item Simple Random: each item has an equal probability of being chosen
        \item Systematic: select some starting point and then select every $k$th element
        \item Stratified: divide the population into subgroups (strata) based on attributes and then draw a sample from each stratum
        \item Cluster: divide the population into clusters and then randomly select some of the clusters
    \end{itemize}
\end{definition}

\subsection{Data Partitioning}

\begin{definition}{Data Partitioning}
    is the process of dividing the dataset into two or more parts.
    \begin{itemize}
        \item Training set: used to train the model
        \item Validation set: used to tune the model
        \item Test set: used to evaluate the model
    \end{itemize}
    \vspace{1mm}
    \textcolor{pink}{\textbf{K-Fold Cross-Validation}}
    \begin{itemize}
        \item Divide the dataset into $k$ subsets (folds)
        \item Train the model $k$ times, each time using a different subset as the test set and the remaining points as the training set
        $\rightarrow$ train on k-1 folds, test on the remaining fold, repeat for each fold
        \item Average the results to get the final model $\rightarrow$ calculate average errors
    \end{itemize}
\end{definition}

\subsection{Knowledge Discovery in Databases (KDD)}

\begin{definition}{KDD}\\
Is the process of semi-automatic extraction of knowledge from databases which is...
\begin{itemize}
    \item valid, previously unknown, and potentially useful
\end{itemize}
Interactive and iterative process with continuous optimization of tasks.
\end{definition}

\includegraphics[width=\linewidth]{KDD_processing.png}
